{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T06:44:06.809211Z",
     "start_time": "2018-06-04T06:44:04.596084Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\conda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "##load packages, needed\n",
    "# encoding=utf-8\n",
    "\n",
    "import jieba\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2,mutual_info_classif,f_classif\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import KFold  \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.neighbors import KNeighborsClassifier   \n",
    "from sklearn import svm  \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "\n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T07:18:58.415844Z",
     "start_time": "2018-06-04T07:18:58.188831Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##load model, needed\n",
    "vectorizer = pickle.load(open(\"vectorizer_i.pickle\",'rb'))\n",
    "selector = pickle.load(open(\"selector_i.pickle\",'rb'))\n",
    "bst = xgb.Booster({'nthread':4}) #init model\n",
    "bst.load_model(\"model_xgb_i.model\") # load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T06:44:06.968220Z",
     "start_time": "2018-06-04T06:44:04.604Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vectorizer = pickle.load(open(\"vectorizer_0504.pickle\",'rb'))\n",
    "#selector = pickle.load(open(\"selector_b.pickle\",'rb'))\n",
    "#clf =  pickle.load(open(\"clf_b.pickle\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T06:48:13.811338Z",
     "start_time": "2018-06-04T06:48:13.773336Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '0428_bank_0_0.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c3ad381219bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcorpus_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"0428_bank_0_0.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"r+\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'UTF-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcontent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mcorpus_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '0428_bank_0_0.txt'"
     ]
    }
   ],
   "source": [
    "corpus_test = []\n",
    "f = open(\"0428_bank_0_0.txt\",\"r+\", encoding='UTF-8')\n",
    "for content in f:\n",
    "    if(len(content)>12):\n",
    "        corpus_test.append(content.strip())\n",
    "f.close()\n",
    "\n",
    "#vectorizer = CountVectorizer()\n",
    "#transformer = TfidfTransformer()\n",
    "\n",
    "X_test = vectorizer.transform(corpus_test)\n",
    "#X_test = transformer.fit_transform(vectorizer.fit_transform(corpus_test))\n",
    "#print(X_test.shape)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "#print(X_test.shape)\n",
    "res = clf.predict(X_test.toarray())\n",
    "\n",
    "print( 1-float(sum(res))/len(res),len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T07:24:16.532039Z",
     "start_time": "2018-06-04T07:24:16.412032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975 40\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "##load data and test, needed\n",
    "corpus_test = []\n",
    "f = open(\"test_0604.txt\",\"r+\", encoding='UTF-8')\n",
    "for content in f:\n",
    "    if(len(content)>0):\n",
    "        corpus_test.append(content.strip())\n",
    "f.close()\n",
    "\n",
    "#vectorizer = CountVectorizer()\n",
    "#transformer = TfidfTransformer()\n",
    "\n",
    "X_test = vectorizer.transform(corpus_test)\n",
    "#X_test = transformer.fit_transform(vectorizer.fit_transform(corpus_test))\n",
    "#print(X_test.shape)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "#print(X_test.shape)\n",
    "#res = clf.predict(X_test.toarray())\n",
    "\n",
    "res = bst.predict(xgb.DMatrix(X_test))\n",
    "\n",
    "print( 1-float(sum(res))/len(res),len(res))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T06:49:31.578786Z",
     "start_time": "2018-06-04T06:49:31.525783Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "ef = open(\"i_error_0.txt\",\"w\")\n",
    "for rs in res:\n",
    "    if rs==1:\n",
    "        ef.write(corpus_test[i]+\"\\n\")\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T07:34:51.557360Z",
     "start_time": "2018-06-04T07:34:51.546360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(res)\n",
    "print(res[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-04T07:34:56.404637Z",
     "start_time": "2018-06-04T07:34:56.389637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'关注微信公众号：推荐保 带您解锁更多新技能  “保险”，从字面意思上来解释，可以理解为保障风险，但不是保证不发生风险，而是在发生风险时，得到帮助和支持。 保险的基本原则是”我为人人，人人为我”，通过累计千千万万人的财力，结成一个共同抵御化解风险的大集体，在这个大集体中每个人都是付出者，但同时也是受益者，通过付出，在遭遇事故时，得到及时的救助，这就是保险的基本功能。“明天和意外，我们永远不知道哪一个先来临”，在日常生活中，我们面临的风险是多种多样的，随着经济的发展，国民的生活水平得到很大的提高，家家户户都买上了小车，相信大家买车时都会上保险吧，不然都不敢上路，每年花点钱买个安心，总比“裸奔”要好吧。当我们意识到要给车子买保险，那人呢，是否需要买？还是“裸奔”也无所谓，它的意义又是什么呢？其实给人买保险和车子性质一样，只不过有些人认为开车时候出现意外的风险概率高，人出事的风险概率比较低，所以宁愿给车买，也不愿意给人买，难道人还没有车子重要吗？风险概率是客观存在的，也就是说每个人都可能受到风险的“眷顾”，而且是不可预测的，它并不会因为人的高低贵贱而区别对待，如出行交通事故、摔倒磕伤、燃气泄漏、电器误操作漏电、罹患疾病等等，所有人都有可能遭遇，概率一致。所以在意外面前，人人平等。 人们常常调侃说： “什么都可以没有，不能没有钱；什么都可以有，不能有病。”如果不幸发生在身上了，不但收入减少，而且之前辛辛苦苦攒的储蓄也会像是开了阀的水池。 而这种不幸，时时刻刻都在上演，我们经常都会有听说，谁谁谁得了癌症，花了多少钱治病，把家底都掏空了，从此一蹶不振，让人唏嘘不已，但在感慨命运不幸的同时却没有意识到一个很严重的问题。假如这样的事情发生在自己身上会怎样，自己该怎么去面对，父母辛苦的把我们拉扯大，教育我们成才，谁将来可以照顾他们？结婚时面对面的承诺，有谁来履行？孩子是整个家庭的希望，又有谁可以给他更好的未来？这些都是我们的责任，风险来临时谁替我们承担？当这一切真真切切来到你面前时，你就会知道，现实就是如此！如此的残酷！ 而保险的用处大致可归结为：  生——有所准备；老——有所养；病——有所医；死——有所留；残——有所靠。  其实，买保险本不需要理由，就像生、老、病、死也没有理由，是每个人都必须面对的。就连万科董事长王石也说，买保险不需要理由，必须买！在风险面前，谁不想有个能遮风挡雨的避风港？ 如果您也认同以上观点，欢迎分享点赞。                                                                                                                           本文来自大风号，仅代表大风号自媒体观点。'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_test[9]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

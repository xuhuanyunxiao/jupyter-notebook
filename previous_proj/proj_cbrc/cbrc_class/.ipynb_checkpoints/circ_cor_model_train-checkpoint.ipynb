{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 保监会 分类模型 2 训练 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T02:21:36.825916Z",
     "start_time": "2018-07-30T02:21:32.650779Z"
    }
   },
   "outputs": [],
   "source": [
    "##load packages, needed\n",
    "# encoding=utf-8\n",
    "\n",
    "import jieba\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2,mutual_info_classif,f_classif \n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from collections import defaultdict\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pre_cor\n",
    "import dict_dbutils\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sqlalchemy import create_engine\n",
    "from pandas.io import sql\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T09:53:23.260176Z",
     "start_time": "2018-07-27T09:53:23.254124Z"
    }
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    class StatsFeatures(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "        def __init__(self):\n",
    "            self.neg = set()\n",
    "            f = open(\"corpus/neg_words.txt\",\"r+\", encoding='UTF-8')\n",
    "            for content in f:\n",
    "                self.neg.add(content)\n",
    "            f.close()\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "\n",
    "        def getcnt(self,x):        \n",
    "            return len(list(set(x)))\n",
    "\n",
    "        def getnegcnt(self,x):\n",
    "            negcnt = 0\n",
    "            words = x.split()\n",
    "            for w in words:\n",
    "                if w in self.neg:\n",
    "                    negcnt = negcnt+1\n",
    "            return negcnt\n",
    "    \n",
    "        def transform(self, X):\n",
    "            data = []\n",
    "            for x in X:\n",
    "                if len(x) == 0:\n",
    "                    length  = 1\n",
    "                else :\n",
    "                    length = len(x)\n",
    "                data.append([len(x),self.getcnt(x),self.getcnt(x)/length,\n",
    "                             self.getnegcnt(x),self.getnegcnt(x)/length])            \n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T02:21:38.973546Z",
     "start_time": "2018-07-30T02:21:38.956820Z"
    }
   },
   "outputs": [],
   "source": [
    "class StatsFeatures_cor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.neg = set()\n",
    "        f = open(\"corpus/neg_words.txt\",\"r+\", encoding='UTF-8')\n",
    "        for content in f:\n",
    "            self.neg.add(content)\n",
    "        f.close()\n",
    "        dict_org=dict_dbutils.get_dicts()\n",
    "        self.org=set(dict_org.keys())\n",
    "        \n",
    "        \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def getcnt(self,x):        \n",
    "        return len(list(set(x)))\n",
    "\n",
    "    def getnegcnt(self,x):\n",
    "        negcnt = 0\n",
    "        words = x.split()\n",
    "        for w in words:\n",
    "            if w in self.neg:\n",
    "                negcnt = negcnt+1\n",
    "        return negcnt\n",
    "    def getorgcnttf(self,x):\n",
    "        orgcnt=0\n",
    "        orgtf=0\n",
    "        words = x.split()\n",
    "        for w in words:\n",
    "            if w in self.org:\n",
    "                orgcnt = orgcnt+1\n",
    "                orgtf=orgtf+words.count(w)\n",
    "        if(orgcnt>0):\n",
    "            return orgcnt,orgtf\n",
    "        else:\n",
    "            return orgcnt,orgtf\n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "        data = []\n",
    "        for x in X:\n",
    "            if len(x) == 0:\n",
    "                length  = 1\n",
    "            else :\n",
    "                length = len(x)\n",
    "            orgcnt,orgtf=self.getorgcnttf(x)\n",
    "            data.append([len(x),self.getcnt(x),self.getcnt(x)/length,\n",
    "                         self.getnegcnt(x),self.getnegcnt(x)/length,\n",
    "                         orgcnt,orgtf])            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上一版模型读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T02:42:59.136881Z",
     "start_time": "2018-07-19T02:42:53.723420Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 上一版模型\n",
    "# from sklearn.externals import joblib\n",
    "# pipeline_old = joblib.load( \"model/circ_cor_0625.pkl.z\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T02:21:43.710157Z",
     "start_time": "2018-07-30T02:21:43.515358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7644\n"
     ]
    }
   ],
   "source": [
    "title_content = []\n",
    "filename = 'data/result/all_titles+contents_pre.txt'\n",
    "fid = open(filename, \"r+\", encoding='UTF-8')\n",
    "for f in fid:\n",
    "    title_content.append(f.strip())\n",
    "fid.close()\n",
    "print(len(title_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T02:21:47.376704Z",
     "start_time": "2018-07-30T02:21:47.133193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7644\n"
     ]
    }
   ],
   "source": [
    "content = []\n",
    "filename = 'data/result/all_contents_pre.txt'\n",
    "fid = open(filename, \"r+\", encoding='UTF-8')\n",
    "for f in fid:\n",
    "    content.append(f.strip())\n",
    "fid.close()\n",
    "print(len(title_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T02:21:49.703745Z",
     "start_time": "2018-07-30T02:21:49.699381Z"
    }
   },
   "outputs": [],
   "source": [
    "label_dic={'监管':1,'行业':2,'产品销售':3,'资本市场':4,'公司内部管理':5,'消费服务':6,'其他相关报道':7,'噪音':8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T02:21:51.270401Z",
     "start_time": "2018-07-30T02:21:51.255319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7644\n"
     ]
    }
   ],
   "source": [
    "label = []\n",
    "filename = 'data/result/all_labels_pre.txt'\n",
    "fid = open(filename, \"r+\", encoding='UTF-8')\n",
    "for f in fid:\n",
    "    label.append(f.strip())\n",
    "fid.close()\n",
    "label=[label_dic[x.strip()] for x in label]\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T02:21:53.027080Z",
     "start_time": "2018-07-30T02:21:53.011219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7644\n"
     ]
    }
   ],
   "source": [
    "title = []\n",
    "filename = 'data/result/all_titles_pre.txt'\n",
    "fid = open(filename, \"r+\", encoding='UTF-8')\n",
    "for f in fid:\n",
    "    title.append(f.strip())\n",
    "fid.close()\n",
    "print(len(title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分割训练集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T02:21:55.904724Z",
     "start_time": "2018-07-30T02:21:55.880794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集： 6879\n",
      "训练集-各类数量： Counter({8: 3092, 1: 1363, 7: 615, 5: 528, 4: 422, 3: 307, 2: 299, 6: 253})\n",
      "测试集： 765\n",
      "测试集-各类数量： Counter({8: 335, 1: 147, 7: 75, 5: 66, 4: 50, 6: 32, 3: 32, 2: 28})\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(title_content, label, test_size=0.1, random_state=42)\n",
    "print('训练集：',len(y_train))\n",
    "print('训练集-各类数量：',Counter(y_train))\n",
    "print('测试集：',len(y_test))\n",
    "print('测试集-各类数量：',Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T02:28:52.618777Z",
     "start_time": "2018-07-30T02:21:58.744259Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('tf_idf', Pipeline(memory=None,\n",
       "     steps=[('counts', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0...tate=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('tf_idf', Pipeline([\n",
    "            ('counts', CountVectorizer()),\n",
    "            ('tf_idf', TfidfTransformer()),\n",
    "            ('chi', SelectKBest(chi2, k=20000))\n",
    "        ])),\n",
    "        ('len_stats', StatsFeatures_cor())\n",
    "    ])),\n",
    "    ('classifier', XGBClassifier(max_depth=7,objective='multi:softmax', num_class=8))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T02:32:08.633276Z",
     "start_time": "2018-07-30T02:31:54.780959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9943305713039686\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T02:32:13.054982Z",
     "start_time": "2018-07-30T02:32:11.622019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.8339869281045752\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.90      0.85       147\n",
      "          2       0.70      0.25      0.37        28\n",
      "          3       0.71      0.62      0.67        32\n",
      "          4       0.82      0.80      0.81        50\n",
      "          5       0.80      0.67      0.73        66\n",
      "          6       0.81      0.53      0.64        32\n",
      "          7       0.86      0.84      0.85        75\n",
      "          8       0.87      0.94      0.90       335\n",
      "\n",
      "avg / total       0.83      0.83      0.82       765\n",
      "\n",
      "confusion_matrix: \n",
      "[[132   2   1   2   1   0   0   9]\n",
      " [  5   7   1   0   2   1   2  10]\n",
      " [  1   0  20   0   1   0   3   7]\n",
      " [  3   0   0  40   2   0   0   5]\n",
      " [ 10   0   3   0  44   2   2   5]\n",
      " [  1   0   0   0   0  17   3  11]\n",
      " [  3   0   3   0   3   1  63   2]\n",
      " [ 10   1   0   7   2   0   0 315]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_class = pipeline.predict(X_test)\n",
    "print('accuracy_score: ', metrics.accuracy_score(y_test, y_pred_class)) # 指所有分类正确的百分比\n",
    "print(metrics.classification_report(y_test, y_pred_class))\n",
    "print('confusion_matrix: ')\n",
    "print( metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T06:53:06.947443Z",
     "start_time": "2018-07-03T06:53:05.381974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.8652058432934927\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.89      0.88       862\n",
      "          1       0.85      0.84      0.84       644\n",
      "\n",
      "avg / total       0.87      0.87      0.87      1506\n",
      "\n",
      "confusion_matrix: \n",
      "[[764  98]\n",
      " [105 539]]\n"
     ]
    }
   ],
   "source": [
    "# 上一版模型 \n",
    "y_pred_class = pipeline_old.predict(X_test)\n",
    "print('accuracy_score: ', metrics.accuracy_score(y_test, y_pred_class)) # 指所有分类正确的百分比\n",
    "print(metrics.classification_report(y_test, y_pred_class))\n",
    "print('confusion_matrix: ')\n",
    "print( metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T09:51:12.095774Z",
     "start_time": "2018-06-13T09:51:11.751754Z"
    },
    "collapsed": true
   },
   "source": [
    "# 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-30T03:19:37.451611Z",
     "start_time": "2018-07-30T03:19:32.775395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/circ_8classifier_0730.pkl.z']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(pipeline, \"model/circ_8classifier_0730.pkl.z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存本文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T06:53:13.560161Z",
     "start_time": "2018-07-03T06:53:13.537160Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    import datetime as dt\n",
    "    \n",
    "    def output_HTML(read_file, output_file):\n",
    "        from nbconvert import HTMLExporter\n",
    "        import codecs\n",
    "        import nbformat\n",
    "        exporter = HTMLExporter()\n",
    "        # read_file is '.ipynb', output_file is '.html'\n",
    "        output_notebook = nbformat.read(read_file, as_version=4)\n",
    "        output, resources = exporter.from_notebook_node(output_notebook)\n",
    "        codecs.open(output_file, 'w', encoding='utf-8').write(output)\n",
    "\n",
    "    html_file_folder = 'html_files'\n",
    "    if not os.path.exists(html_file_folder):\n",
    "        os.makedirs(html_file_folder)\n",
    "\n",
    "    today = dt.datetime.now().strftime('%Y%m%d')\n",
    "    current_file = 'circ_cor_model_2_train.ipynb'\n",
    "    output_file = 'html_files\\%s_%s.html'%(os.path.splitext(current_file)[0], today)\n",
    "    output_HTML(current_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本文件说明\n",
    "- 数据库里导出数据，本地模型、线上模型测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:02:57.170728Z",
     "start_time": "2018-09-11T09:02:55.873654Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import requests,json\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:18:45.171951Z",
     "start_time": "2018-09-11T09:18:45.168951Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from toolkits.setup.date_time import get_day_list\n",
    "from toolkits.setup import specific_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 一些函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:02:57.640755Z",
     "start_time": "2018-09-11T09:02:57.522748Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_server_res_yjh(data, url, col_name):\n",
    "    '''\n",
    "    服务器接口测试程序\n",
    "    传入 dict, 传出 DataFrame\n",
    "    '''\n",
    "    # data = {'record':[{'id':0,'title':'ss','content':'zzz'},]}\n",
    "    # data = {\"record\":marked_human_data.iloc[:5,:3].to_dict(orient = 'records')}\n",
    "    # url \"http://47.93.77.19:10000/correlation_negative\"\n",
    "    headers={'content-type':'application/json'}\n",
    "    result = requests.post(url,\n",
    "                      data = json.dumps(data),\n",
    "                      headers=headers, allow_redirects=True)\n",
    "    # print(result.text)\n",
    "    json_data = json.loads(result.text)\n",
    "    parse_data = []\n",
    "#     elapsed_time = json_data['elapsed_time']\n",
    "    for i in range(len(json_data['docs'])):\n",
    "        parse_data.append([json_data['docs'][i]['id'],\n",
    "                          json_data['docs'][i][col_name]])\n",
    "    parse_data = pd.DataFrame(parse_data, columns = ['id', col_name])    \n",
    "    return parse_data #, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:02:57.768762Z",
     "start_time": "2018-09-11T09:02:57.647756Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_serve_data_yjh(day_list, sql_one_day, url, col_name, save_filename):    \n",
    "    chunksize = 1000\n",
    "    for day_select in day_list:\n",
    "        print('-- day_select: ', day_select)\n",
    "        mysql_data = pd.read_sql(eval(sql_one_day), engine, chunksize= chunksize)\n",
    "        num = 1\n",
    "        combined_data = pd.DataFrame()\n",
    "        for tmp_data in mysql_data:  \n",
    "            print('---- loop num: ', num, 'tmp_data: ', tmp_data.shape)\n",
    "            data = {\"record\":tmp_data.loc[:,['id', 'title' ,'content']].to_dict(orient = 'records')}\n",
    "            parse_data = get_server_res_yjh(data, url, col_name)\n",
    "\n",
    "            parse_data.columns = ['id', 'predict_label']\n",
    "            \n",
    "            parse_data['label'] = ''\n",
    "            combined_tmp = pd.merge(parse_data, tmp_data, on = 'id', how = 'inner')\n",
    "            combined_data = pd.concat([combined_tmp, combined_data])\n",
    "\n",
    "        combined_data['predict_label'] = combined_data['predict_label'].apply(lambda x:class_name_dict[x])\n",
    "        combined_data['group_id'] = combined_data['group_id'].apply(lambda x:group_dict[str(x)])\n",
    "        combined_data.to_excel(eval(save_filename), index = False)\n",
    "        print(combined_data['predict_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:02:57.857768Z",
     "start_time": "2018-09-11T09:02:57.773763Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_server_res(data, url, col_name):\n",
    "    '''\n",
    "    服务器接口测试程序\n",
    "    传入 dict, 传出 DataFrame\n",
    "    '''\n",
    "    # data = {'record':[{'id':0,'title':'ss','content':'zzz'},]}\n",
    "    # data = {\"record\":marked_human_data.iloc[:5,:3].to_dict(orient = 'records')}\n",
    "    # url \"http://47.93.77.19:10000/correlation_negative\"\n",
    "    headers={'content-type':'application/json'}\n",
    "    result = requests.post(url,\n",
    "                      data = json.dumps(data),\n",
    "                      headers=headers, allow_redirects=True)\n",
    "    # print(result.text)\n",
    "    json_data = json.loads(result.text)\n",
    "    parse_data = []\n",
    "    elapsed_time = json_data['elapsed_time']\n",
    "    for i in range(len(json_data['docs'])):\n",
    "        parse_data.append([json_data['docs'][i]['id'],\n",
    "                          json_data['docs'][i][col_name]])\n",
    "    parse_data = pd.DataFrame(parse_data, columns = ['id', col_name])    \n",
    "    return parse_data, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:02:57.995775Z",
     "start_time": "2018-09-11T09:02:57.860768Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_serve_data(day_list, sql_one_day, url, col_name):\n",
    "    combined_data = pd.DataFrame()\n",
    "    for day_select in day_list:\n",
    "        print('-- day_select: ', day_select)\n",
    "        mysql_data = pd.read_sql(eval(sql_one_day), engine)\n",
    "        print('去空值前：', mysql_data.shape)\n",
    "        mysql_data = mysql_data.drop_duplicates(subset = ['title', 'content'])\n",
    "        print('去空值后：', mysql_data.shape)\n",
    "        data = {\"record\":mysql_data.loc[:,['id', 'title' ,'content']].to_dict(orient = 'records')}\n",
    "        \n",
    "        parse_data, elapsed_time = get_server_res(data, url)\n",
    "        print('elapsed_time: ', elapsed_time)\n",
    "        \n",
    "        parse_data.columns = ['id', 'predict_label']\n",
    "        parse_data['predict_label'] = parse_data['predict_label'].apply(lambda x:class_name_dict[x])\n",
    "        parse_data['label'] = ''\n",
    "        combined_cor = pd.merge(parse_data, mysql_data, on = 'id', how = 'inner')\n",
    "        combined_data = pd.concat([combined_data, combined_cor], axis = 0)\n",
    "\n",
    "        print(combined_cor['predict_label'].value_counts())\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:02:58.120783Z",
     "start_time": "2018-09-11T09:02:57.999776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '监管',\n",
       " 2: '行业',\n",
       " 3: '产品销售',\n",
       " 4: '资本市场',\n",
       " 5: '公司内部管理',\n",
       " 6: '消费服务',\n",
       " 7: '其他相关报道',\n",
       " 8: '噪音'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dic={'监管':1,'行业':2,'产品销售':3,'资本市场':4,'公司内部管理':5,'消费服务':6,'其他相关报道':7,'噪音':8}\n",
    "class_name_dict = {v: k for k, v in label_dic.items()}\n",
    "class_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:02:58.248790Z",
     "start_time": "2018-09-11T09:02:58.125783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': '新闻',\n",
       " '11': '微信',\n",
       " '13': '新闻客户端',\n",
       " '15': '推特',\n",
       " '2': '论坛',\n",
       " '3': '博客',\n",
       " '4': '微博',\n",
       " '5': '纸媒',\n",
       " '6': '视频',\n",
       " '7': '外媒'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = '1-新闻，2-论坛，3-博客，4-微博，5-纸媒，6-视频，7-外媒，11-微信，13-新闻客户端，15-推特'\n",
    "group_dict = dict([x.split('-') for x in group.split('，')])\n",
    "group_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 保险业"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 银行业"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:17:17.654945Z",
     "start_time": "2018-09-11T09:17:17.632944Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\xh\\python_project\\tool\\toolkits\\setup\\specific_func.py\u001b[0m in \u001b[0;36mget_engine\u001b[1;34m(types)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;31m# 银监会\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[1;32mtry\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m             \u001b[0mDB_CON_STR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mysql+pymysql://atlas:WiseWeb123@47.93.77.228:5636/pom?charset=utf8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_engine' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-56819b6af957>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cbrc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\xh\\python_project\\tool\\toolkits\\setup\\specific_func.py\u001b[0m in \u001b[0;36mget_engine\u001b[1;34m(types)\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDB_CON_STR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mecho\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'show databases'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m             \u001b[0mDB_CON_STR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mysql+pymysql://atlas:WiseWeb123@10.28.205.96:5636/pom?charset=utf8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m             \u001b[0mengine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDB_CON_STR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mecho\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_engine' is not defined"
     ]
    }
   ],
   "source": [
    "engine = specific_func.get_engine('cbrc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## mysql 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:20:44.536778Z",
     "start_time": "2018-09-11T09:20:44.528778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018-09-09', '2018-09-10']\n"
     ]
    }
   ],
   "source": [
    "# day_select = '2018-09-09'\n",
    "day_list = get_day_list('2018-09-08', '2018-09-10')\n",
    "print(day_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:04:56.282541Z",
     "start_time": "2018-09-11T09:04:56.276541Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sql_circ_cor_one_day = \"select t1.id, t1.publishtime, t1.title,t2.text as content \\\n",
    "#                             from elint_web_docinfo t1, wise_web_docinfo_text t2 \\\n",
    "#                                 where t1.id = t2.doc_id \\\n",
    "#                                   and date_format(t1.publishtime, '%%Y-%%m-%%d') = '{0}'\".format('2018-08-07')\n",
    "# # 实际\n",
    "# circ_cor = pd.read_sql(sql_circ_cor_one_day, engine)\n",
    "# print(circ_cor.shape)\n",
    "# circ_cor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:47:32.920772Z",
     "start_time": "2018-09-11T09:28:37.822849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- day_select:  2018-09-09\n",
      "去重前： (20072, 5)\n",
      "去重后： (19889, 5)\n",
      "去空值后： (19889, 5)\n",
      "(19887, 7)\n",
      "行业        6061\n",
      "消费服务      4219\n",
      "监管        4073\n",
      "噪音        3718\n",
      "公司内部管理     714\n",
      "资本市场       668\n",
      "产品销售       273\n",
      "其他相关报道     161\n",
      "Name: predict_label, dtype: int64\n",
      "-- day_select:  2018-09-10\n",
      "去重前： (31001, 5)\n",
      "去重后： (30714, 5)\n",
      "去空值后： (30714, 5)\n",
      "(30690, 7)\n",
      "行业        10035\n",
      "监管         7566\n",
      "消费服务       7053\n",
      "噪音         3366\n",
      "公司内部管理     1323\n",
      "资本市场        944\n",
      "其他相关报道      227\n",
      "产品销售        176\n",
      "Name: predict_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for day_select in day_list:\n",
    "    print('-- day_select: ', day_select)\n",
    "    \n",
    "    # 获取八分类\n",
    "    sql_one_day = \"select t2.urlhash, t1.traffic_id, t2.title as title_1\\\n",
    "                        from wise_web_classify_traffic_docinfo t1, wise_web_docinfo_basic t2 \\\n",
    "                            where t1.base_id=t2.id \\\n",
    "                                  and date_format(t2.publishtime, '%%Y-%%m-%%d') = '{0}' \".format(day_select)\n",
    "    cbrc_flag = pd.read_sql(sql_one_day, engine)\n",
    "    print('cbrc_flag：', cbrc_flag.shape)\n",
    "    \n",
    "    # 相关数据\n",
    "    sql_one_day = \"select t1.urlhash, t1.title,t2.text as content, t1.group_id, t1.publishtime as publishtime \\\n",
    "                        from elint_web_docinfo t1, wise_web_docinfo_text t2 \\\n",
    "                            where t1.id=t2.doc_id \\\n",
    "                                  and date_format(t1.publishtime, '%%Y-%%m-%%d') = '{0}' \\\n",
    "                                  group by t1.titlehash\".format(day_select)\n",
    "    # titlehash 去重后\n",
    "    cbrc_cor = pd.read_sql(sql_one_day, engine) \n",
    "    print('cbrc_cor：', cbrc_cor.shape)\n",
    "    \n",
    "    sql_cbrc_uncor = \"select urlhash, title, content, group_id, publishtime \\\n",
    "                            from wise_web_docinfo_uncor \\\n",
    "                            where date_format(publishtime, '%%Y-%%m-%%d') = '{0}'\".format(day_select)\n",
    "    cbrc_uncor = pd.read_sql(sql_cbrc_uncor, engine)  \n",
    "    print('cbrc_uncor：', cbrc_uncor.shape)\n",
    "\n",
    "    cbrc_data = pd.concat([cbrc_cor, cbrc_uncor], axis = 0)\n",
    "    print('去重前：', cbrc_data.shape)\n",
    "    cbrc_data = cbrc_data.drop_duplicates(subset = ['title', 'content'])\n",
    "    print('去重后：', cbrc_data.shape)  \n",
    "    cbrc_data = cbrc_data.dropna(subset = ['title', 'content'], axis = 0)\n",
    "    print('去空值后：', cbrc_data.shape)  \n",
    "\n",
    "    cbrc_combined = pd.merge(cbrc_flag, cbrc_data, how = 'inner', on = 'urlhash')\n",
    "    cbrc_combined['predict_label'] = cbrc_combined['traffic_id'].apply(lambda x:class_name_dict[x])\n",
    "    cbrc_combined['group_id'] = cbrc_combined['group_id'].apply(lambda x:group_dict[str(x)])\n",
    "    cbrc_combined['label'] = ''\n",
    "    cbrc_combined = cbrc_combined[['urlhash', 'predict_label', 'label', 'title', 'content', 'group_id', 'publishtime']]\n",
    "    fea_filename = 'cbrc_result_class/result/cbrc_class_predict_mysql_%s.xlsx'%day_select\n",
    "    cbrc_combined.to_excel(fea_filename, index = False)\n",
    "    print(cbrc_combined.shape)\n",
    "    print(cbrc_combined['predict_label'].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:49:21.422978Z",
     "start_time": "2018-09-11T09:49:12.721481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50577, 7)\n",
      "去重前： (50577, 7)\n",
      "去重后： (50327, 7)\n",
      "去空值后： (50270, 7)\n",
      "行业        16031\n",
      "监管        11609\n",
      "消费服务      11129\n",
      "噪音         7060\n",
      "公司内部管理     2027\n",
      "资本市场       1592\n",
      "产品销售        442\n",
      "其他相关报道      380\n",
      "Name: predict_label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urlhash</th>\n",
       "      <th>predict_label</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>group_id</th>\n",
       "      <th>publishtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-313954450631131328</td>\n",
       "      <td>监管</td>\n",
       "      <td>NaN</td>\n",
       "      <td>潍坊两家保险公司因违法违规被处罚</td>\n",
       "      <td>近日，山东保监局官方网站发布的行政处罚决定中潍坊有2家保险公司被罚款！它们分别是阳光人寿保险...</td>\n",
       "      <td>新闻客户端</td>\n",
       "      <td>2018-09-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5635611554844595200</td>\n",
       "      <td>消费服务</td>\n",
       "      <td>NaN</td>\n",
       "      <td>大家好，我在16年6月办了一张中国银行visa的长城环球旅行卡，我觉得它既是一张储蓄卡也是一...</td>\n",
       "      <td>大家好，我在16年6月办了一张中国银行visa的长城环球旅行卡，我觉得它既是一张储蓄卡也是一...</td>\n",
       "      <td>新闻</td>\n",
       "      <td>2018-09-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8919826005505955840</td>\n",
       "      <td>消费服务</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#滴滴[超话]# http://t</td>\n",
       "      <td>#滴滴[超话]# http://t.cn/RsJxaBs 微信同号13311138121请务...</td>\n",
       "      <td>微博</td>\n",
       "      <td>2018-09-09 00:06:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2343908636206920192</td>\n",
       "      <td>消费服务</td>\n",
       "      <td>NaN</td>\n",
       "      <td>报警服务行业，比较偏门，接触的人，了解的人，太少</td>\n",
       "      <td>报警服务行业，比较偏门，接触的人，了解的人，太少！借此地，给大家普及一下：最早的报警，通俗地...</td>\n",
       "      <td>微博</td>\n",
       "      <td>2018-09-09 00:06:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6200572542378652672</td>\n",
       "      <td>噪音</td>\n",
       "      <td>NaN</td>\n",
       "      <td>写给2018年的信</td>\n",
       "      <td>关注秦朔朋友圈，ID：qspyq2015 \\n  \\n   这是秦朔朋友圈的第   2202...</td>\n",
       "      <td>微信</td>\n",
       "      <td>2018-09-09 00:09:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               urlhash predict_label  label  \\\n",
       "0  -313954450631131328            监管    NaN   \n",
       "1  5635611554844595200          消费服务    NaN   \n",
       "2  8919826005505955840          消费服务    NaN   \n",
       "3  2343908636206920192          消费服务    NaN   \n",
       "4 -6200572542378652672            噪音    NaN   \n",
       "\n",
       "                                               title  \\\n",
       "0                                   潍坊两家保险公司因违法违规被处罚   \n",
       "1  大家好，我在16年6月办了一张中国银行visa的长城环球旅行卡，我觉得它既是一张储蓄卡也是一...   \n",
       "2                                  #滴滴[超话]# http://t   \n",
       "3                           报警服务行业，比较偏门，接触的人，了解的人，太少   \n",
       "4                                          写给2018年的信   \n",
       "\n",
       "                                             content group_id  \\\n",
       "0  近日，山东保监局官方网站发布的行政处罚决定中潍坊有2家保险公司被罚款！它们分别是阳光人寿保险...    新闻客户端   \n",
       "1  大家好，我在16年6月办了一张中国银行visa的长城环球旅行卡，我觉得它既是一张储蓄卡也是一...       新闻   \n",
       "2  #滴滴[超话]# http://t.cn/RsJxaBs 微信同号13311138121请务...       微博   \n",
       "3  报警服务行业，比较偏门，接触的人，了解的人，太少！借此地，给大家普及一下：最早的报警，通俗地...       微博   \n",
       "4  关注秦朔朋友圈，ID：qspyq2015 \\n  \\n   这是秦朔朋友圈的第   2202...       微信   \n",
       "\n",
       "          publishtime  \n",
       "0 2018-09-09 00:00:00  \n",
       "1 2018-09-09 00:00:00  \n",
       "2 2018-09-09 00:06:32  \n",
       "3 2018-09-09 00:06:29  \n",
       "4 2018-09-09 00:09:58  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_uncor = pd.DataFrame()\n",
    "for day_select in day_list:\n",
    "    tmp_data = pd.read_excel('cbrc_result_class/result/cbrc_class_predict_mysql_%s.xlsx'%day_select)\n",
    "    combined_uncor = pd.concat([combined_uncor, tmp_data], axis = 0)\n",
    "    \n",
    "print(combined_uncor.shape)  \n",
    "print('去重前：', combined_uncor.shape)\n",
    "combined_uncor = combined_uncor.drop_duplicates(subset = ['title', 'content'])\n",
    "print('去重后：', combined_uncor.shape)  \n",
    "combined_uncor = combined_uncor.dropna(subset = ['title', 'content'], axis = 0)\n",
    "print('去空值后：', combined_uncor.shape)  \n",
    "\n",
    "print(combined_uncor['predict_label'].value_counts())\n",
    "combined_uncor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:49:33.746683Z",
     "start_time": "2018-09-11T09:49:32.579617Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fea_filename = 'cbrc_result_class/result/cbrc_class_predict_mysql_20180911(0909-0910).xlsx'\n",
    "with pd.ExcelWriter(fea_filename) as writer:\n",
    "    for label in cbrc_combined['predict_label'].unique():\n",
    "        tmp_data = cbrc_combined[cbrc_combined['predict_label'] == label]\n",
    "        if tmp_data.shape[0] > 200:\n",
    "            N = 200\n",
    "        else :\n",
    "            N = tmp_data.shape[0]\n",
    "        tmp_data.sample(n = N, axis = 0, random_state=42).to_excel(writer,label, index = False)\n",
    "    \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 本地模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线上模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:02:47.823194Z",
     "start_time": "2018-09-11T09:02:44.801Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# url = \"http://192.168.0.104:6001/judge_correlation_yjh\"\n",
    "url = \"http://47.93.77.19:6001/judge_correlation_yjh\"\n",
    "\n",
    "day_list = get_day_list('2018-09-08', '2018-09-10')\n",
    "print(day_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:02:47.826194Z",
     "start_time": "2018-09-11T09:02:44.807Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 不相关\n",
    "sql_cbrc_uncor = '''\"select id, title, content, group_id, publishtime \\\n",
    "                        from wise_web_docinfo_uncor \\\n",
    "                        where date_format(publishtime, '%%Y-%%m-%%d') = '{0}'\".format(day_select)'''\n",
    "\n",
    "save_filename = ''''cbrc_result_class/result/cbrc_uncor_predict_%s.xlsx'%day_select'''\n",
    "get_serve_data_yjh(day_list, sql_cbrc_uncor, url, 'sec', save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:02:47.828194Z",
     "start_time": "2018-09-11T09:02:44.811Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 相关\n",
    "sql_cbrc_cor = '''\n",
    "\"select t1.id, t1.title,t2.text as content, t1.group_id, t1.publishtime as publishtime \\\n",
    "                    from elint_web_docinfo t1, wise_web_docinfo_text t2 \\\n",
    "                        where t1.id=t2.doc_id \\\n",
    "                              and date_format(t1.publishtime, '%%Y-%%m-%%d') = '{0}' \\\n",
    "                              group by t1.titlehash\".format(day_select)\n",
    "'''\n",
    "\n",
    "save_filename = ''''cbrc_result_class/result/cbrc_cor_predict_%s.xlsx'%day_select'''\n",
    "get_serve_data_yjh(day_list, sql_cbrc_cor, url, 'sec', save_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并 & 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:02:47.831194Z",
     "start_time": "2018-09-11T09:02:44.816Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_uncor = pd.DataFrame()\n",
    "for day_select in day_list:\n",
    "    tmp_data = pd.read_excel('cbrc_result_class/result/cbrc_uncor_predict_%s.xlsx'%day_select)\n",
    "    combined_uncor = pd.concat([combined_uncor, tmp_data], axis = 0)\n",
    "    \n",
    "print(combined_uncor.shape)  \n",
    "print('去重前：', combined_uncor.shape)\n",
    "combined_uncor = combined_uncor.drop_duplicates(subset = ['title', 'content'])\n",
    "print('去重后：', combined_uncor.shape)  \n",
    "combined_uncor = combined_uncor.dropna(subset = ['title', 'content'], axis = 0)\n",
    "print('去空值后：', combined_uncor.shape)  \n",
    "\n",
    "print(combined_uncor['predict_label'].value_counts())\n",
    "combined_uncor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:02:47.836194Z",
     "start_time": "2018-09-11T09:02:44.820Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fea_filename = 'cbrc_result_class/result/cbrc_uncor_predict_class_20180911(0909-0910).xlsx'\n",
    "with pd.ExcelWriter(fea_filename) as writer:\n",
    "    for label in combined_uncor['predict_label'].unique():\n",
    "        tmp_data = combined_uncor[combined_uncor['predict_label'] == label]\n",
    "        if tmp_data.shape[0] > 100:\n",
    "            N = 200\n",
    "            tmp_data.sample(n = N, axis = 0, random_state=42).to_excel(writer,label, index = False)\n",
    "    \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:02:47.839195Z",
     "start_time": "2018-09-11T09:02:44.826Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_cor = pd.DataFrame()\n",
    "for day_select in day_list:\n",
    "    tmp_data = pd.read_excel('cbrc_result_class/result/cbrc_cor_predict_%s.xlsx'%day_select)\n",
    "    combined_cor = pd.concat([combined_cor, tmp_data], axis = 0)\n",
    "\n",
    "print(combined_cor.shape)  \n",
    "print('去重前：', combined_cor.shape)\n",
    "combined_cor = combined_cor.drop_duplicates(subset = ['title', 'content'])\n",
    "print('去重后：', combined_cor.shape)  \n",
    "combined_cor = combined_cor.dropna(subset = ['title', 'content'], axis = 0)\n",
    "print('去空值后：', combined_cor.shape)  \n",
    "\n",
    "print(combined_cor.shape)  \n",
    "print(combined_cor['predict_label'].value_counts())\n",
    "combined_cor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:02:47.844195Z",
     "start_time": "2018-09-11T09:02:44.829Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fea_filename = 'cbrc_result_class/result/cbrc_cor_predict_class_20180911(0909-0910).xlsx'\n",
    "with pd.ExcelWriter(fea_filename) as writer:\n",
    "    for label in combined_cor['predict_label'].unique():\n",
    "        tmp_data = combined_cor[combined_cor['predict_label'] == label]\n",
    "        if tmp_data.shape[0] > 700:\n",
    "            N = 200\n",
    "            tmp_data.sample(n = N, axis = 0, random_state=42).to_excel(writer,label, index = False)\n",
    "    \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T03:51:49.646007Z",
     "start_time": "2018-09-11T03:51:48.860962Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存本文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:02:47.846195Z",
     "start_time": "2018-09-11T09:02:44.835Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    import datetime as dt\n",
    "    \n",
    "    def output_HTML(read_file, output_file):\n",
    "        from nbconvert import HTMLExporter\n",
    "        import codecs\n",
    "        import nbformat\n",
    "        exporter = HTMLExporter()\n",
    "        # read_file is '.ipynb', output_file is '.html'\n",
    "        output_notebook = nbformat.read(read_file, as_version=4)\n",
    "        output, resources = exporter.from_notebook_node(output_notebook)\n",
    "        codecs.open(output_file, 'w', encoding='utf-8').write(output)\n",
    "\n",
    "    html_file_folder = 'html_files'\n",
    "    if not os.path.exists(html_file_folder):\n",
    "        os.makedirs(html_file_folder)\n",
    "\n",
    "    today = dt.datetime.now().strftime('%Y%m%d')\n",
    "    current_file = 'circ_cor_model_2_train.ipynb'\n",
    "    output_file = 'html_files\\%s_%s.html'%(os.path.splitext(current_file)[0], today)\n",
    "    output_HTML(current_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 保监会 相关性模型 2 训练 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T07:00:44.458327Z",
     "start_time": "2018-07-18T07:00:42.099192Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.897 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "##load packages, needed\n",
    "# encoding=utf-8\n",
    "\n",
    "import jieba\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2,mutual_info_classif,f_classif \n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from collections import defaultdict\n",
    "\n",
    "import pickle\n",
    "\n",
    "import joblib\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pre_cor\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sqlalchemy import create_engine\n",
    "from pandas.io import sql\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T06:49:38.020112Z",
     "start_time": "2018-07-03T06:49:37.942108Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StatsFeatures(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.neg = set()\n",
    "        f = open(\"corpus/neg_words.txt\",\"r+\", encoding='UTF-8')\n",
    "        for content in f:\n",
    "            self.neg.add(content)\n",
    "        f.close()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def getcnt(self,x):        \n",
    "        return len(list(set(x)))\n",
    "\n",
    "    def getnegcnt(self,x):\n",
    "        negcnt = 0\n",
    "        words = x.split()\n",
    "        for w in words:\n",
    "            if w in self.neg:\n",
    "                negcnt = negcnt+1\n",
    "        return negcnt\n",
    "    \n",
    "    def transform(self, X):\n",
    "        data = []\n",
    "        for x in X:\n",
    "            if len(x) == 0:\n",
    "                length  = 1\n",
    "            else :\n",
    "                length = len(x)\n",
    "            data.append([len(x),self.getcnt(x),self.getcnt(x)/length,\n",
    "                         self.getnegcnt(x),self.getnegcnt(x)/length])            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上一版模型读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T06:49:41.731325Z",
     "start_time": "2018-07-03T06:49:38.024113Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 上一版模型\n",
    "from sklearn.externals import joblib\n",
    "pipeline_old = joblib.load( \"model/circ_cor_0625.pkl.z\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T07:00:55.291946Z",
     "start_time": "2018-07-18T07:00:54.746915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6111\n",
      "6111\n"
     ]
    }
   ],
   "source": [
    "folder = '20180703'\n",
    "\n",
    "# 相关数据\n",
    "corpus_cor = []\n",
    "label_cor = []\n",
    "\n",
    "filename = 'data/{0}/corpus_pre_cor_0703.txt'.format(folder)\n",
    "fid = open(filename, \"r+\", encoding='UTF-8')\n",
    "for f in fid:\n",
    "    corpus_cor.append(f)\n",
    "    label_cor.append(1)\n",
    "fid.close()\n",
    "print(len(corpus_cor))\n",
    "print(len(label_cor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T07:00:59.369180Z",
     "start_time": "2018-07-18T07:00:59.005159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8949\n",
      "8949\n"
     ]
    }
   ],
   "source": [
    "# 不相关数据\n",
    "corpus_uncor = []\n",
    "label_uncor = []\n",
    "\n",
    "filename = 'data/{0}/corpus_pre_uncor_0703.txt'.format(folder)\n",
    "fid = open(filename, \"r+\", encoding='UTF-8')\n",
    "for f in fid:\n",
    "    corpus_uncor.append(f)\n",
    "    label_uncor.append(0)\n",
    "fid.close()\n",
    "print(len(corpus_uncor))\n",
    "print(len(label_uncor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T07:01:10.024789Z",
     "start_time": "2018-07-18T07:01:10.016789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'月 日 闽侯 万佛寺 祈福 永泰 赏 梅花 旗山 森林 温泉 度假村 品 永泰 葱饼 特价 一日游 特价 特价 特价 元 人 含 车费 原价 元 温泉 特惠 门票 活动 时间 年 月 日 星期天 集合时间 上午 集中 准时 出发 超时 不侯 集合地点 福州 工业 路 万象 城 麦当劳 东側 中央 第五 街 下面 上车 集中 指示 相片 活动 性质 自愿 参加 量力而行 保险 自购 风险 自负 户外 风险 参加 需谨慎 购买 保险 网址 https 活动 类别 感受 户外 生活 祈福 赏花 摄影 泡温泉 风景 指数 活动 强度 休闲游 亲子 游 线路 地点 福州 闽侯 永泰 福州 活动 费用 元 人 往返 车费 原 元 温泉 特惠 门票 米 以下 小孩 车费 元 人 景区 特价 活动 任何 证件 均 不再 优惠 上车 缴费 午餐 自理 自带 干粮 镇上 自行 午餐 按照 报名 先后顺序 安排 车上 座位 按车 均分 顺序 诚信 报名 报名者 如 活动 前 小时 内 退出 应 自觉 缴纳 本次 活动 车费 代 报名者 负责 补交 找 其他人 替补 请 大家 共同 遵守 报名 方式 请 参加者 发短信 报名 发短信 格式 日 旗山 温泉 网名 名字 qq 网名 参加 人数 接收 短信 手机 活动 行程 安排 早上 万象 城 发车 永泰 葛岭 赏花 和品 永泰 葱饼 上车 前往 游 旗山 万福 寺 镇上 自行 午餐 驱车 旗山 温泉 度假村 泡温泉 适时 返回 福州 线路 介绍 福州 城 四周 青山 耸翠 碧水 环绕 西郊 之旗 山群峰 旖旎 奇岩 幽壑 飞泉 流涧 景色 佳绝 鼓山 隔江 相峙 素有 左旗 右鼓 八闽 二绝 之誉 自古 道 天下 名山 僧 占 多 名山 古刹 相得益彰 也 唐代 以后 峰回 水曲 洞天福地 之中 旗山 曾 九庵 十八 寺 错落 其间 而 今天 要说 中国 占地 规模 最大 佛教 寺院 万佛寺 位于 旗山 之麓 万顷 石松 围 佛寺 一江 闽水绕 旗山 寺 前 对联 万佛 万玉 也 寺 中之佛 佛佛 皆 玉雕 而成 如今 海内外 佛教 信徒 朝拜 圣地 也 成为 东南 旅游 重要 景观 永泰 成片 梅林 中 一朵朵 白 梅花 密密麻麻 点缀 枝丫 间 远远 看去 犹如 刚下 一场 冬雪 整座 山 变成 白色 一株株 梅树 挺直 腰杆 一颗颗 花蕾 争先 开放 一时间 满山 银装素裹 满树 梅花 傲立 枝头 不需 走进 一阵 清香 便 迎面 飘来 让 人 不知不觉 陶醉 王安石 诗境 中 美丽 来自 自然 健康 来自 温泉 旗山 森林 温泉 具备 保健 美容 护肤 疗养 功效 依山 而 建 温泉 中心 座 独具 风味 温泉 汤池 间 独享 尊贵 温泉 汤屋 分为 动感 泡池区 养生 泡池区 生态 泡池区 三大泡 池区 包含 鱼疗 池 红茶 泉 红 酒泉 牛奶 泉 人参 泉 多种 特色 温泉 背上 行囊 一起 去 神游 报名 须知 年 须 周岁 周岁 小孩 需 父母 全程 陪同 高血压 心脏病 性格 孤僻 以逸待劳 斤斤计较 不能 同甘共苦 俱乐部 视同 旅行社 人 参加 谢绝 参加 免责 声明 参加者 均 视为 具有 完全 民事行为 能力 人 自行 承担 产生 后果 负 完全 责任 本 俱乐部 活动 以 盈利 为 目的 属 结伴同游 性质 自愿 参加 参加者 已 认识 到 户外活动 风险 自助 活动 风险 自负 一切 意外 俱乐部 领队 无关 组织者 领队 均 承担 任何 相应 法律责任 经济 赔偿 责任 参加者 放弃 对 同行 组织者 领队 队友 索赔权 参加者 必须 个人 自行 购买 相关 意外 伤害 保险 后 参加 不是 旅行社 结伴同游 没有 保姆式 服务 一切 后勤 事物 需要 队员 协作 完成 可能 遭遇 迷路 堵车 坏车 一系列 无法 预料 情况 会 抱怨 请 三思而后行 特此 声明 活动 开始 后 本 声明 将 自动 生效 并 表明 接受 本 声明 否则 请 活动 开始 前 退出 本次 活动 若因 天气 不可 抗拒 外力 影响 低于 成行 人数 将 对 线路 调整 取消 请 出发 前 及时 本 网站 公告 途中 一些 不可 预计 因素 引起 计划 变更 民主 原则 最终 以 领队 意见 为准 参加者 均 视为 同意 以上 条款 个人 装备 建议 穿 软底 防滑 鞋 长袖 宽松 衣 裤 遮阳帽 毛巾 饮用水 雨具 报名 截止 日期 限 人数 报满 为止 请 参加者 马上发 报名 短信 自即日起 开始 名 报名 电话 仙游 手机号 微信 同号 网址 http 组织 活动 q q 群号 微信 公众 号 zgfj 上车 集中 地点 图 报名 确认 名 诚信 报名 占 坑者 活动 前 小时 内 退出 应 缴纳 本次 活动 车费 代 报名者 负责 补交 请 大家 共同 遵守 请 参加 人员 活动 前一天 晚上 之后 登陆 网站 再次 核对 名单 以 报名 先后顺序 安排 车辆 座位 按车 均分 想 去 抓紧 以 确认 报名 为准 位满 截止 如需 调整 座位 请 大家 自行 友好 协商 确认 名单 第一部 车 领队 小霞 人 计 限 提示 报名 方式 请 参加者 发短信 报名 发短信 格式 日 旗山 温泉 网名 名字 qq 网名 参加 人数 接收 短信 手机 报名 以 发短信 未 发短信 确认 朋友 请速发 确认 短信 谢谢合作 组织 活动 咨询 q q 群号 微信 公众 号 zgfj 保险 购置 方法 活动 性质 自愿 参加 结伴 而行 保险 自购 风险 自负 户外 风险 参加 需谨慎 为了 家人 安全 保障 提醒 参加 户外活动 购买 保险 请 参加者 网银 微信 支付 信用卡 支付宝 自行 购买 户外活动 保险 如需 协助 代购 保险 驴友 报名 时 将 网名 姓名 身份证 号码 手机号码 缺一不可 传至 仙游 手机 需加 元 人 保险 代购 款 本次 活动 选择 保险产品 购买 网址 https 现代 保险 齐乐游 计划 C 投保 须知 投保 前 请 仔细阅读 产品 条款 费率 表 客户 告知 书 保单 样本 免除 责任 保障 责任 犹豫 期 费用 扣除 退保 保险单 现金 价值 投保人 被保险人 义务 内容 详见 产品 条款 请 务必 仔细阅读 产品 条款 电子 保单 特别 约定 投保 须知 所有 保险责任 条款 均 以 现代财产保险 中国 有限公司 签发 正式 保险合同 相应 条款 为准 本 计划 承保 年 为 周岁 以 保单生效 时 周岁 年 为准 周岁 被保险人 其 涉及 意外 身故 残疾 保障 公共 交通工具 意外 保障 急性病 身故 保障 自驾车 意外 身故 残疾 保险金额 为 上表 载 金额 一半 保险费 维持 不变 周岁 以上 被保险人 因 保险 事故 造成 意外 急性病 医疗 保险公司 扣除 元免 赔后 赔付 按 中国保监会 规定 周岁 以下 未成年人 累计 身故 保险金额 不得 超过 人民币 万元 周岁 未成年人 累计 身故 保险金额 不得 超过 人民币 万元 若 未成年 被保险人 保险金额 超过 上述 规定 以 上述 规定 保险金额 为限 同一 保险 期间 每位 被保险人 投保 同一 产品 包括 同一 产品 同一 计划 不同 计划 限 投保 一份 如果 投保 多份 同一 计划 以 最先 投保 保单 为 有效 其余部分 视为 无效 保险费 将 无息 退还 如果 投保 多份 不同 计划 以 意外 伤害 保额 最高 保单 为 有效 其余部分 视为 无效 保险费 将 无息 退还 本 保险产品 单次 承保 最长 期间 为 天 本 保险 仅 承保 中华人民共和国 大陆 地区 境内 含 香港 澳门 台湾 地区 外籍人士 购买 本 产品 符合 投保 规则 即可 无 其它 特殊要求 本 产品 承保 被保险人 从事 潜水 滑水 滑雪 滑冰 驾驶 乘坐 滑翔翼 滑翔伞 跳伞 攀岩 运动 探险 活动 如 江河 漂流 武术比赛 摔跤 比赛 柔道 空手道 跆拳道 马术 拳击 特技表演 驾驶 卡丁车 赛马 赛车 各种 车辆 表演 蹦极 溯溪 高风险 运动 承保 旅行 期间 休闲 旅游 景区 内 滑雪 漂流 骑马 运动 业余 跑步 远足 徒步 登山运动 海拔高度 米 以下 定向 运动 拓展 活动 场地 趣味 活动 自行车 运动 山地 自行车 越野 场地 越野 轮滑 自驾车 旅行 游泳 低 风险 运动 前述 仅限 体验式 活动 包含 专业 性质 训练 运动 本 产品 指定 医院 为 符合 条款 要求 医院 除了 北京 平谷区 所有 医院 请 注意 北京市 平谷区 所有 医院 就医 均 给予 理赔 被保险人 故意 做出 危险性 行为 而 导致 意外 伤害事故 保险公司 承担 保险责任 危险性 行为 包括 但 限于 听从 导游 领队 教练 现场 安全 人员 要求 劝阻 违反 景区 当地 警示 禁令 标示 违规 进入 国家 当地政府 明令禁止 线路 地区 投保 表格 下载 人 国内 旅游 团购 模板 xls 福州 旗山 万佛寺 原为 旗 山石 松寺 始建 宋 大中祥符 三年 公元 年 初名 灵凤寺 绍兴 十年 公元 年 寺僧 天石于 寺 旁 种植 爪 松 长成 易名 为 石松 寺 明成化 万历 年间 两次 修建 颇具规模 曾 福州 佛教 圣地 年 政府 批准 重建 石松 寺 并 更名 为 旗山 万佛寺 雪峰 寺 方丈 释广霖 构思 提议 将 该寺 建为 全国 最大 寺院 藏 万尊 白瓷 佛 立寺 名曰 旗山 万佛寺 梅花香 自苦寒 来 最近 几天 永泰 梅树 已 进入 盛花期 正是 观赏 最佳时期 花朵 成片 成片 绽放 蔚为壮观 一朵朵 白 梅花 密密麻麻 点缀 枝丫 间 远远 看去 犹如 刚下 一场 冬雪 整座 山 变成 白色 一株株 梅树 挺直 腰杆 一颗颗 花蕾 争先 开放 一时间 满山 银装素裹 满树 梅花 傲立 枝头 不需 走进 一阵 清香 便 迎面 飘来 让 人 不知不觉 陶醉 王安石 诗境 中 山间 小道 而 上 观赏 到 成片 盛开 如雪 腊梅 林 近距离 欣赏 梅花 花姿 风韵 将 陶醉 遥知 不是 雪 唯有 暗香 来 梅林 中 此时 梅花 姿态 各异 俯 或仰 或侧 卧 依 梅花 树皮 漆黑 而多糙 纹 其 虬枝 苍劲 嶙峋 风韵 洒落 一种 饱经沧桑 威武不屈 阳刚之美 梅花 枝条 明晰 色彩 和谐 或曲 如游 披靡 而 下 多变 而 规律 呈现出 一种 很强 力度 刚硬 线条美 身处 梅林 中 梅花 缤纷 梅影 阵阵 徜徉 花丛 之中 聊天 也好 发呆 也好 赏花 也好 留影 也好 随心 而 为 微风 阵阵 略过 梅林 犹如 浸身 香海 通体 蕴香 冬日 梅花 树 下 不时 还 观得 几瓣 梅花 随风飘 落 静静 散落 身边 轻轻 划过 指尖 惬意 也 爱人 一起 漫步 梅林 之间 感受 枝头 点点 香雪 冬日 里 倾诉 绵绵 情话 也 带 孩子 梅林 中 享受 冬日 暖阳 呼吸 伴着 阵阵 花香 空气 还 将 孩子 天真 顽皮 一举一动 捕入 镜头 为 成长 留下 美好 回忆 下午 再 一起 去 泡个 舒适 温泉 冬日 阳光 下 享受 泡温泉 感觉 最 美妙 享受 温泉 中 含有 丰富 矿物质 不仅 对 多种 疾病 均 疗效 作用 而且 保健 美容 护肤 疗养 功效 永泰 葱 饼 福建 永泰 传统 名点 香脆 可口 让 人 回味无穷 刚 出炉 葱 饼 片刻 之后 酥脆 无比 咬 一小 口 葱香 肉香 芝麻 香 唇 留香 jpg KB jpg KB jpg KB \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_uncor[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分割训练集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T06:49:42.623376Z",
     "start_time": "2018-07-03T06:49:42.520370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集： 13554\n",
      "训练集-各类数量： Counter({0: 8087, 1: 5467})\n",
      "测试集： 1506\n",
      "测试集-各类数量： Counter({0: 862, 1: 644})\n"
     ]
    }
   ],
   "source": [
    "# 未加入系统中噪音\n",
    "corpus = corpus_cor + corpus_uncor\n",
    "label = label_cor + label_uncor\n",
    "X_train, X_test, y_train, y_test = train_test_split(corpus, label, test_size=0.1, random_state=42)\n",
    "print('训练集：',len(y_train))\n",
    "print('训练集-各类数量：',Counter(y_train))\n",
    "print('测试集：',len(y_test))\n",
    "print('测试集-各类数量：',Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T07:13:29.122063Z",
     "start_time": "2018-07-18T07:13:29.096062Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T07:14:18.094864Z",
     "start_time": "2018-07-18T07:14:14.069634Z"
    }
   },
   "outputs": [],
   "source": [
    "vec = vectorizer.fit(corpus_uncor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T07:14:49.479659Z",
     "start_time": "2018-07-18T07:14:49.452658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'闽侯': 144669,\n",
       " '万佛寺': 17574,\n",
       " '祈福': 113452,\n",
       " '永泰': 97218,\n",
       " '梅花': 93864,\n",
       " '旗山': 85612,\n",
       " '森林': 94193,\n",
       " '温泉': 101961,\n",
       " '度假村': 70025,\n",
       " '葱饼': 127603,\n",
       " '特价': 105483,\n",
       " '一日游': 16636,\n",
       " '车费': 136361,\n",
       " '原价': 45419,\n",
       " '特惠': 105575,\n",
       " '门票': 144296,\n",
       " '活动': 99800,\n",
       " '时间': 86986,\n",
       " '星期天': 87475,\n",
       " '集合时间': 146827,\n",
       " '上午': 18606,\n",
       " '集中': 146785,\n",
       " '准时': 37598,\n",
       " '出发': 38288,\n",
       " '超时': 135117,\n",
       " '不侯': 19375,\n",
       " '集合地点': 146826,\n",
       " '福州': 113846,\n",
       " '工业': 67005,\n",
       " '万象': 17848,\n",
       " '麦当劳': 152054,\n",
       " '东側': 20915,\n",
       " '中央': 22337,\n",
       " '第五': 116224,\n",
       " '下面': 19272,\n",
       " '上车': 18923,\n",
       " '指示': 80253,\n",
       " '相片': 111448,\n",
       " '性质': 74263,\n",
       " '自愿': 124530,\n",
       " '参加': 45788,\n",
       " '量力而行': 141957,\n",
       " '保险': 31938,\n",
       " '自购': 124769,\n",
       " '风险': 149394,\n",
       " '自负': 124765,\n",
       " '户外': 76587,\n",
       " '需谨慎': 147406,\n",
       " '购买': 133614,\n",
       " '网址': 120383,\n",
       " 'https': 5869,\n",
       " '类别': 117112,\n",
       " '感受': 75494,\n",
       " '生活': 108076,\n",
       " '赏花': 134213,\n",
       " '摄影': 82131,\n",
       " '泡温泉': 99067,\n",
       " '风景': 149314,\n",
       " '指数': 80219,\n",
       " '强度': 71754,\n",
       " '休闲游': 29281,\n",
       " '亲子': 26804,\n",
       " '线路': 118770,\n",
       " '地点': 54661,\n",
       " '费用': 133946,\n",
       " '往返': 72421,\n",
       " '以下': 28460,\n",
       " '小孩': 64946,\n",
       " '景区': 88070,\n",
       " '任何': 28906,\n",
       " '证件': 131430,\n",
       " '不再': 19415,\n",
       " '优惠': 29398,\n",
       " '缴费': 120281,\n",
       " '午餐': 43240,\n",
       " '自理': 124654,\n",
       " '自带': 124509,\n",
       " '干粮': 68673,\n",
       " '镇上': 143765,\n",
       " '自行': 124735,\n",
       " '按照': 80346,\n",
       " '报名': 78810,\n",
       " '先后顺序': 33701,\n",
       " '安排': 62280,\n",
       " '车上': 136126,\n",
       " '座位': 70067,\n",
       " '按车': 80367,\n",
       " '均分': 54837,\n",
       " '顺序': 148603,\n",
       " '诚信': 131773,\n",
       " '报名者': 78814,\n",
       " '小时': 65092,\n",
       " '退出': 139108,\n",
       " '自觉': 124746,\n",
       " '缴纳': 120278,\n",
       " '本次': 90311,\n",
       " '负责': 133126,\n",
       " '补交': 129020,\n",
       " '其他人': 35835,\n",
       " '替补': 88802,\n",
       " '大家': 57662,\n",
       " '共同': 35508,\n",
       " '遵守': 140357,\n",
       " '方式': 85350,\n",
       " '参加者': 45790,\n",
       " '发短信': 46749,\n",
       " '格式': 93416,\n",
       " '网名': 120377,\n",
       " '名字': 49489,\n",
       " 'qq': 10811,\n",
       " '人数': 27216,\n",
       " '接收': 81320,\n",
       " '短信': 112385,\n",
       " '手机': 77061,\n",
       " '行程': 128849,\n",
       " '早上': 86617,\n",
       " '发车': 46831,\n",
       " '葛岭': 127516,\n",
       " '和品': 51095,\n",
       " '前往': 40573,\n",
       " '万福': 17803,\n",
       " '驱车': 150496,\n",
       " '适时': 139336,\n",
       " '返回': 137986,\n",
       " '介绍': 27806,\n",
       " '四周': 52775,\n",
       " '青山': 147594,\n",
       " '耸翠': 122248,\n",
       " '碧水': 113060,\n",
       " '环绕': 107000,\n",
       " '西郊': 130035,\n",
       " '之旗': 23922,\n",
       " '山群峰': 66592,\n",
       " '旖旎': 85604,\n",
       " '奇岩': 59449,\n",
       " '幽壑': 69342,\n",
       " '飞泉': 149525,\n",
       " '流涧': 100016,\n",
       " '景色': 88101,\n",
       " '佳绝': 31059,\n",
       " '鼓山': 152742,\n",
       " '隔江': 146501,\n",
       " '相峙': 111388,\n",
       " '素有': 117781,\n",
       " '左旗': 67304,\n",
       " '右鼓': 48419,\n",
       " '八闽': 34956,\n",
       " '二绝': 25371,\n",
       " '之誉': 24013,\n",
       " '自古': 124463,\n",
       " '天下': 58359,\n",
       " '名山': 49497,\n",
       " '古刹': 47410,\n",
       " '相得益彰': 111411,\n",
       " '唐代': 51751,\n",
       " '以后': 28533,\n",
       " '峰回': 66811,\n",
       " '水曲': 96934,\n",
       " '洞天福地': 99686,\n",
       " '之中': 23784,\n",
       " '九庵': 24419,\n",
       " '十八': 42801,\n",
       " '错落': 143646,\n",
       " '其间': 35974,\n",
       " '今天': 27751,\n",
       " '要说': 130200,\n",
       " '中国': 22135,\n",
       " '占地': 44458,\n",
       " '规模': 130435,\n",
       " '最大': 88881,\n",
       " '佛教': 30816,\n",
       " '寺院': 64404,\n",
       " '位于': 30197,\n",
       " '之麓': 24061,\n",
       " '万顷': 17885,\n",
       " '石松': 112545,\n",
       " '佛寺': 30806,\n",
       " '一江': 16766,\n",
       " '闽水绕': 144678,\n",
       " '对联': 64354,\n",
       " '万佛': 17573,\n",
       " '万玉': 17790,\n",
       " '中之佛': 21931,\n",
       " '佛佛': 30794,\n",
       " '玉雕': 106313,\n",
       " '而成': 121972,\n",
       " '如今': 60368,\n",
       " '海内外': 100471,\n",
       " '信徒': 32102,\n",
       " '朝拜': 89802,\n",
       " '圣地': 54312,\n",
       " '成为': 75847,\n",
       " '东南': 20943,\n",
       " '旅游': 85535,\n",
       " '重要': 141846,\n",
       " '景观': 88103,\n",
       " '成片': 76005,\n",
       " '梅林': 93848,\n",
       " '一朵朵': 16674,\n",
       " '密密麻麻': 63897,\n",
       " '点缀': 103835,\n",
       " '枝丫': 92399,\n",
       " '远远': 138623,\n",
       " '看去': 111686,\n",
       " '犹如': 105788,\n",
       " '刚下': 39478,\n",
       " '一场': 16326,\n",
       " '冬雪': 37086,\n",
       " '整座': 84084,\n",
       " '变成': 47169,\n",
       " '白色': 110153,\n",
       " '一株株': 16707,\n",
       " '梅树': 93849,\n",
       " '挺直': 80621,\n",
       " '腰杆': 124189,\n",
       " '一颗颗': 17271,\n",
       " '花蕾': 125886,\n",
       " '争先': 24908,\n",
       " '开放': 70679,\n",
       " '一时间': 16647,\n",
       " '满山': 102622,\n",
       " '银装素裹': 143356,\n",
       " '满树': 102645,\n",
       " '傲立': 33313,\n",
       " '枝头': 92400,\n",
       " '不需': 20405,\n",
       " '走进': 134665,\n",
       " '一阵': 17243,\n",
       " '清香': 101776,\n",
       " '迎面': 137775,\n",
       " '飘来': 149438,\n",
       " '不知不觉': 20060,\n",
       " '陶醉': 146272,\n",
       " '王安石': 106465,\n",
       " '诗境': 131749,\n",
       " '美丽': 120829,\n",
       " '来自': 91639,\n",
       " '自然': 124624,\n",
       " '健康': 33071,\n",
       " '具备': 36008,\n",
       " '保健': 31632,\n",
       " '美容': 121022,\n",
       " '护肤': 78744,\n",
       " '疗养': 109585,\n",
       " '功效': 41080,\n",
       " '依山': 31282,\n",
       " '中心': 22485,\n",
       " '独具': 105908,\n",
       " '风味': 149269,\n",
       " '汤池': 97728,\n",
       " '独享': 105907,\n",
       " '尊贵': 64694,\n",
       " '汤屋': 97708,\n",
       " '分为': 38652,\n",
       " '动感': 41483,\n",
       " '泡池区': 99058,\n",
       " '养生': 36104,\n",
       " '生态': 107998,\n",
       " '三大泡': 18126,\n",
       " '池区': 97656,\n",
       " '包含': 41934,\n",
       " '鱼疗': 151606,\n",
       " '红茶': 118263,\n",
       " '酒泉': 141243,\n",
       " '牛奶': 105222,\n",
       " '人参': 27027,\n",
       " '多种': 57080,\n",
       " '特色': 105669,\n",
       " '背上': 123225,\n",
       " '行囊': 128771,\n",
       " '一起': 17138,\n",
       " '神游': 113601,\n",
       " '须知': 148666,\n",
       " '周岁': 50780,\n",
       " '父母': 105021,\n",
       " '全程': 34677,\n",
       " '陪同': 146203,\n",
       " '高血压': 151337,\n",
       " '心脏病': 73491,\n",
       " '性格': 74230,\n",
       " '孤僻': 61699,\n",
       " '以逸待劳': 28739,\n",
       " '斤斤计较': 84521,\n",
       " '不能': 20163,\n",
       " '同甘共苦': 49359,\n",
       " '俱乐部': 32380,\n",
       " '视同': 130472,\n",
       " '旅行社': 85572,\n",
       " '谢绝': 132768,\n",
       " '免责': 34124,\n",
       " '声明': 56093,\n",
       " '视为': 130462,\n",
       " '具有': 36012,\n",
       " '完全': 62489,\n",
       " '民事行为': 96448,\n",
       " '能力': 123621,\n",
       " '承担': 78026,\n",
       " '产生': 26594,\n",
       " '后果': 49755,\n",
       " '责任': 133311,\n",
       " '盈利': 110742,\n",
       " '目的': 111116,\n",
       " '结伴同游': 119358,\n",
       " '认识': 131030,\n",
       " '户外活动': 76588,\n",
       " '自助': 124444,\n",
       " '一切': 16172,\n",
       " '意外': 75408,\n",
       " '领队': 149043,\n",
       " '无关': 85703,\n",
       " '组织者': 118858,\n",
       " '相应': 111398,\n",
       " '法律责任': 98939,\n",
       " '经济': 119154,\n",
       " '赔偿': 134242,\n",
       " '放弃': 83147,\n",
       " '同行': 49391,\n",
       " '队友': 144770,\n",
       " '索赔权': 117855,\n",
       " '必须': 73648,\n",
       " '个人': 21766,\n",
       " '相关': 111337,\n",
       " '伤害': 29938,\n",
       " '不是': 19901,\n",
       " '没有': 98300,\n",
       " '保姆式': 31700,\n",
       " '服务': 89624,\n",
       " '后勤': 49658,\n",
       " '事物': 25045,\n",
       " '需要': 147402,\n",
       " '队员': 144774,\n",
       " '协作': 43683,\n",
       " '完成': 62527,\n",
       " '可能': 48143,\n",
       " '遭遇': 140319,\n",
       " '迷路': 138989,\n",
       " '堵车': 55599,\n",
       " '坏车': 54891,\n",
       " '一系列': 16989,\n",
       " '无法': 85948,\n",
       " '预料': 148835,\n",
       " '情况': 74968,\n",
       " '抱怨': 78962,\n",
       " '三思而后行': 18216,\n",
       " '特此': 105614,\n",
       " '开始': 70602,\n",
       " '自动': 124426,\n",
       " '生效': 108030,\n",
       " '表明': 129198,\n",
       " '接受': 81280,\n",
       " '否则': 50078,\n",
       " '若因': 126159,\n",
       " '天气': 58623,\n",
       " '不可': 19508,\n",
       " '抗拒': 78423,\n",
       " '外力': 56509,\n",
       " '影响': 72304,\n",
       " '低于': 30229,\n",
       " '成行': 76044,\n",
       " '调整': 132535,\n",
       " '取消': 46923,\n",
       " '及时': 45950,\n",
       " '网站': 120435,\n",
       " '公告': 35073,\n",
       " '途中': 139661,\n",
       " '一些': 16080,\n",
       " '预计': 148885,\n",
       " '因素': 53304,\n",
       " '引起': 71038,\n",
       " '计划': 130852,\n",
       " '变更': 47177,\n",
       " '民主': 96426,\n",
       " '原则': 45431,\n",
       " '最终': 88973,\n",
       " '意见': 75445,\n",
       " '为准': 23253,\n",
       " '同意': 49297,\n",
       " '以上': 28457,\n",
       " '条款': 91478,\n",
       " '装备': 129555,\n",
       " '建议': 70453,\n",
       " '软底': 136770,\n",
       " '防滑': 144928,\n",
       " '长袖': 144160,\n",
       " '宽松': 63769,\n",
       " '遮阳帽': 140344,\n",
       " '毛巾': 96301,\n",
       " '饮用水': 149798,\n",
       " '雨具': 146954,\n",
       " '截止': 76504,\n",
       " '日期': 86403,\n",
       " '报满': 78866,\n",
       " '为止': 23334,\n",
       " '马上发': 150212,\n",
       " '自即日起': 124455,\n",
       " '电话': 109082,\n",
       " '仙游': 28243,\n",
       " '手机号': 77064,\n",
       " '微信': 72933,\n",
       " '同号': 49243,\n",
       " 'http': 5868,\n",
       " '组织': 118846,\n",
       " '群号': 121265,\n",
       " '公众': 34984,\n",
       " 'zgfj': 15654,\n",
       " '确认': 113001,\n",
       " '坑者': 54985,\n",
       " '人员': 27057,\n",
       " '前一天': 40442,\n",
       " '晚上': 87824,\n",
       " '之后': 23840,\n",
       " '登陆': 109964,\n",
       " '再次': 36591,\n",
       " '核对': 93290,\n",
       " '名单': 49458,\n",
       " '车辆': 136373,\n",
       " '抓紧': 78217,\n",
       " '位满': 30213,\n",
       " '如需': 60600,\n",
       " '友好': 46027,\n",
       " '协商': 43702,\n",
       " '第一部': 116000,\n",
       " '小霞': 65495,\n",
       " '提示': 81760,\n",
       " '朋友': 89603,\n",
       " '请速发': 132270,\n",
       " '谢谢合作': 132772,\n",
       " '咨询': 51224,\n",
       " '购置': 133668,\n",
       " '方法': 85380,\n",
       " '结伴': 119357,\n",
       " '而行': 122020,\n",
       " '为了': 23222,\n",
       " '家人': 63502,\n",
       " '安全': 62127,\n",
       " '保障': 32002,\n",
       " '提醒': 81800,\n",
       " '网银': 120511,\n",
       " '支付': 82632,\n",
       " '信用卡': 32176,\n",
       " '支付宝': 82633,\n",
       " '协助': 43693,\n",
       " '代购': 28384,\n",
       " '驴友': 150512,\n",
       " '姓名': 60807,\n",
       " '身份证': 136001,\n",
       " '号码': 48533,\n",
       " '手机号码': 77065,\n",
       " '缺一不可': 120292,\n",
       " '传至': 29884,\n",
       " '需加': 147330,\n",
       " '选择': 139476,\n",
       " '保险产品': 31942,\n",
       " '现代': 107025,\n",
       " '齐乐游': 152802,\n",
       " '投保': 78241,\n",
       " '仔细阅读': 28074,\n",
       " '产品': 26536,\n",
       " '费率': 133942,\n",
       " '客户': 63264,\n",
       " '告知': 50661,\n",
       " '保单': 31665,\n",
       " '样本': 93233,\n",
       " '免除': 34145,\n",
       " '犹豫': 105798,\n",
       " '扣除': 77643,\n",
       " '退保': 139101,\n",
       " '保险单': 31948,\n",
       " '现金': 107175,\n",
       " '价值': 28831,\n",
       " '投保人': 78242,\n",
       " '被保险人': 129402,\n",
       " '义务': 23751,\n",
       " '内容': 36276,\n",
       " '详见': 131968,\n",
       " '务必': 41418,\n",
       " '电子': 108823,\n",
       " '特别': 105502,\n",
       " '约定': 118338,\n",
       " '所有': 76842,\n",
       " '保险责任': 31989,\n",
       " '现代财产保险': 107038,\n",
       " '有限公司': 89583,\n",
       " '签发': 116624,\n",
       " '正式': 95159,\n",
       " '保险合同': 31952,\n",
       " '承保': 77990,\n",
       " '保单生效': 31667,\n",
       " '涉及': 100929,\n",
       " '身故': 136054,\n",
       " '残疾': 95700,\n",
       " '公共': 35000,\n",
       " '交通工具': 26442,\n",
       " '急性病': 74134,\n",
       " '自驾车': 124806,\n",
       " '保险金额': 31998,\n",
       " '上表': 18894,\n",
       " '金额': 142520,\n",
       " '一半': 16234,\n",
       " '保险费': 31991,\n",
       " '维持': 119819,\n",
       " '不变': 19503,\n",
       " '事故': 25033,\n",
       " '造成': 140014,\n",
       " '医疗': 42622,\n",
       " '保险公司': 31946,\n",
       " '元免': 33456,\n",
       " '赔后': 134258,\n",
       " '赔付': 134237,\n",
       " '中国保监会': 22175,\n",
       " '规定': 130423,\n",
       " '未成年人': 90097,\n",
       " '累计': 118018,\n",
       " '不得': 19738,\n",
       " '超过': 135211,\n",
       " '人民币': 27284,\n",
       " '万元': 17581,\n",
       " '未成年': 90096,\n",
       " '上述': 18935,\n",
       " '为限': 23383,\n",
       " '同一': 49193,\n",
       " '期间': 89919,\n",
       " '每位': 95866,\n",
       " '包括': 41982,\n",
       " '不同': 19540,\n",
       " '一份': 16109,\n",
       " '如果': 60478,\n",
       " '多份': 56791,\n",
       " '最先': 88842,\n",
       " '有效': 89342,\n",
       " '其余部分': 35847,\n",
       " '无效': 85888,\n",
       " '无息': 85837,\n",
       " '退还': 139178,\n",
       " '保额': 32021,\n",
       " '最高': 89011,\n",
       " '单次': 43907,\n",
       " '最长': 89004,\n",
       " '中华人民共和国': 22057,\n",
       " '大陆': 58294,\n",
       " '地区': 54528,\n",
       " '境内': 55787,\n",
       " '香港': 150108,\n",
       " '澳门': 103161,\n",
       " '台湾': 48287,\n",
       " '外籍人士': 56668,\n",
       " '符合': 115875,\n",
       " '规则': 130417,\n",
       " '即可': 45004,\n",
       " '其它': 35886,\n",
       " '特殊要求': 105623,\n",
       " '从事': 27859,\n",
       " '潜水': 103018,\n",
       " '滑水': 102503,\n",
       " '滑雪': 102537,\n",
       " '滑冰': 102483,\n",
       " '驾驶': 150616,\n",
       " '乘坐': 24302,\n",
       " '滑翔翼': 102520,\n",
       " '滑翔伞': 102518,\n",
       " '跳伞': 135830,\n",
       " '攀岩': 82602,\n",
       " '运动': 137792,\n",
       " '探险': 81249,\n",
       " '江河': 97581,\n",
       " '漂流': 102799,\n",
       " '武术比赛': 95511,\n",
       " '摔跤': 82258,\n",
       " '比赛': 96188,\n",
       " '柔道': 92741,\n",
       " '空手道': 115108,\n",
       " '跆拳道': 135506,\n",
       " '马术': 150350,\n",
       " '拳击': 79868,\n",
       " '特技表演': 105583,\n",
       " '卡丁车': 44489,\n",
       " '赛马': 134413,\n",
       " '赛车': 134403,\n",
       " '各种': 48837,\n",
       " '表演': 129206,\n",
       " '蹦极': 135974,\n",
       " '溯溪': 102431,\n",
       " '高风险': 151426,\n",
       " '旅行': 85567,\n",
       " '休闲': 29276,\n",
       " '骑马': 150743,\n",
       " '业余': 20827,\n",
       " '跑步': 135563,\n",
       " '远足': 138618,\n",
       " '徒步': 72782,\n",
       " '登山运动': 109925,\n",
       " '海拔高度': 100561,\n",
       " '定向': 62712,\n",
       " '拓展': 79500,\n",
       " '场地': 54807,\n",
       " '趣味': 135418,\n",
       " '自行车': 124741,\n",
       " '山地': 66507,\n",
       " '越野': 135369,\n",
       " '轮滑': 136707,\n",
       " '游泳': 102118,\n",
       " '前述': 40680,\n",
       " '仅限': 27724,\n",
       " '体验式': 30565,\n",
       " '专业': 20491,\n",
       " '训练': 131085,\n",
       " '指定': 80183,\n",
       " '医院': 42671,\n",
       " '要求': 130154,\n",
       " '除了': 146018,\n",
       " '北京': 42216,\n",
       " '平谷区': 68923,\n",
       " '注意': 99233,\n",
       " '北京市': 42249,\n",
       " '就医': 65842,\n",
       " '给予': 119498,\n",
       " '理赔': 107491,\n",
       " '故意': 83368,\n",
       " '做出': 32878,\n",
       " '危险性': 44969,\n",
       " '行为': 128719,\n",
       " '导致': 64497,\n",
       " '伤害事故': 29939,\n",
       " '限于': 145905,\n",
       " '听从': 50219,\n",
       " '导游': 64483,\n",
       " '教练': 83608,\n",
       " '现场': 107071,\n",
       " '劝阻': 40976,\n",
       " '违反': 138640,\n",
       " '当地': 71976,\n",
       " '警示': 130815,\n",
       " '禁令': 113743,\n",
       " '标示': 93037,\n",
       " '违规': 138674,\n",
       " '进入': 138417,\n",
       " '国家': 53688,\n",
       " '当地政府': 71978,\n",
       " '明令禁止': 87121,\n",
       " '表格': 129203,\n",
       " '下载': 19239,\n",
       " '国内': 53611,\n",
       " '团购': 53399,\n",
       " '模板': 94508,\n",
       " 'xls': 15016,\n",
       " '原为': 45411,\n",
       " '山石': 66586,\n",
       " '松寺': 91961,\n",
       " '始建': 60775,\n",
       " '大中祥符': 57351,\n",
       " '三年': 18196,\n",
       " '公元': 34997,\n",
       " '初名': 39712,\n",
       " '灵凤寺': 103488,\n",
       " '绍兴': 119043,\n",
       " '十年': 42913,\n",
       " '寺僧': 64399,\n",
       " '天石于': 58722,\n",
       " '种植': 114220,\n",
       " '长成': 143998,\n",
       " '易名': 87312,\n",
       " '明成化': 87158,\n",
       " '万历': 17623,\n",
       " '年间': 69171,\n",
       " '两次': 21493,\n",
       " '修建': 32280,\n",
       " '颇具规模': 149051,\n",
       " '政府': 83267,\n",
       " '批准': 77882,\n",
       " '重建': 141708,\n",
       " '更名': 88537,\n",
       " '雪峰': 147046,\n",
       " '方丈': 85268,\n",
       " '释广霖': 141532,\n",
       " '构思': 92142,\n",
       " '提议': 81783,\n",
       " '该寺': 131874,\n",
       " '建为': 70330,\n",
       " '全国': 34488,\n",
       " '万尊': 17699,\n",
       " '白瓷': 110116,\n",
       " '立寺': 115434,\n",
       " '名曰': 49516,\n",
       " '梅花香': 93865,\n",
       " '自苦寒': 124728,\n",
       " '最近': 88997,\n",
       " '几天': 37914,\n",
       " '盛花期': 111073,\n",
       " '正是': 95191,\n",
       " '观赏': 130392,\n",
       " '最佳时期': 88836,\n",
       " '花朵': 125794,\n",
       " '绽放': 119929,\n",
       " '蔚为壮观': 127908,\n",
       " '山间': 66635,\n",
       " '小道': 65460,\n",
       " '盛开': 111051,\n",
       " '如雪': 60596,\n",
       " '腊梅': 124124,\n",
       " '近距离': 137971,\n",
       " '欣赏': 94790,\n",
       " '花姿': 125751,\n",
       " '风韵': 149419,\n",
       " '遥知': 140282,\n",
       " '唯有': 51912,\n",
       " '暗香': 88372,\n",
       " '此时': 95353,\n",
       " '姿态': 60951,\n",
       " '各异': 48778,\n",
       " '或仰': 76295,\n",
       " '或侧': 76299,\n",
       " '树皮': 93114,\n",
       " '漆黑': 102824,\n",
       " '而多糙': 121953,\n",
       " '虬枝': 128243,\n",
       " '苍劲': 125961,\n",
       " '嶙峋': 66926,\n",
       " '洒落': 99505,\n",
       " '一种': 16937,\n",
       " '饱经沧桑': 149829,\n",
       " '威武不屈': 60997,\n",
       " '阳刚之美': 145066,\n",
       " '枝条': 92404,\n",
       " '明晰': 87186,\n",
       " '色彩': 125322,\n",
       " '和谐': 51157,\n",
       " '或曲': 76353,\n",
       " '如游': 60510,\n",
       " '披靡': 78922,\n",
       " '多变': 56847,\n",
       " '规律': 130427,\n",
       " '呈现出': 50638,\n",
       " '很强': 72557,\n",
       " '力度': 40927,\n",
       " '刚硬': 39540,\n",
       " '线条美': 118752,\n",
       " '身处': 136029,\n",
       " '缤纷': 120215,\n",
       " '梅影': 93843,\n",
       " '阵阵': 145177,\n",
       " '徜徉': 72872,\n",
       " '花丛': 125695,\n",
       " '聊天': 122291,\n",
       " '也好': 24493,\n",
       " '发呆': 46560,\n",
       " '留影': 109412,\n",
       " '随心': 146378,\n",
       " '微风': 73099,\n",
       " '略过': 109507,\n",
       " '浸身': 100761,\n",
       " '香海': 150105,\n",
       " '通体': 139705,\n",
       " '蕴香': 127984,\n",
       " '冬日': 37057,\n",
       " '不时': 19891,\n",
       " '观得': 130357,\n",
       " '几瓣': 37967,\n",
       " '随风飘': 146431,\n",
       " '静静': 147791,\n",
       " '散落': 83741,\n",
       " '身边': 136089,\n",
       " '轻轻': 136963,\n",
       " '划过': 39129,\n",
       " '指尖': 80196,\n",
       " '惬意': 75219,\n",
       " '爱人': 104844,\n",
       " '漫步': 102914,\n",
       " '之间': 24045,\n",
       " '点点': 103817,\n",
       " '香雪': 150191,\n",
       " '倾诉': 32686,\n",
       " '绵绵': 119875,\n",
       " '情话': 75041,\n",
       " '孩子': 61922,\n",
       " '享受': 26642,\n",
       " '暖阳': 88317,\n",
       " '呼吸': 51009,\n",
       " '伴着': 30070,\n",
       " '花香': 125926,\n",
       " '空气': 115126,\n",
       " '天真': 58717,\n",
       " '顽皮': 148685,\n",
       " '一举一动': 16049,\n",
       " '捕入': 80712,\n",
       " '镜头': 143858,\n",
       " '成长': 76061,\n",
       " '留下': 109376,\n",
       " '美好': 120985,\n",
       " '回忆': 53066,\n",
       " '下午': 19022,\n",
       " '泡个': 99041,\n",
       " '舒适': 125039,\n",
       " '阳光': 145035,\n",
       " '感觉': 75549,\n",
       " '美妙': 121003,\n",
       " '含有': 50124,\n",
       " '丰富': 23023,\n",
       " '矿物质': 112667,\n",
       " '不仅': 19341,\n",
       " '疾病': 109662,\n",
       " '疗效': 109589,\n",
       " '作用': 30912,\n",
       " '而且': 121916,\n",
       " '福建': 113852,\n",
       " '传统': 29869,\n",
       " '名点': 49539,\n",
       " '香脆': 150155,\n",
       " '可口': 47927,\n",
       " '回味无穷': 53027,\n",
       " '出炉': 38411,\n",
       " '片刻': 105071,\n",
       " '酥脆': 141290,\n",
       " '无比': 85934,\n",
       " '一小': 16429,\n",
       " '葱香': 127604,\n",
       " '肉香': 122731,\n",
       " '芝麻': 125629,\n",
       " '留香': 109469,\n",
       " 'jpg': 6836,\n",
       " 'kb': 7032,\n",
       " '德国': 73134,\n",
       " '特约记者': 105658,\n",
       " '青木': 147638,\n",
       " '虚假': 128181,\n",
       " '领英': 149024,\n",
       " '账户': 133378,\n",
       " '性感': 74217,\n",
       " '实习生': 63013,\n",
       " '身上': 135991,\n",
       " '情报': 74998,\n",
       " '瑞士': 107573,\n",
       " '发行量': 46802,\n",
       " '报纸': 78879,\n",
       " '一瞥': 16922,\n",
       " '日称': 86476,\n",
       " '瑞士联邦': 107580,\n",
       " '情报局': 75001,\n",
       " 'ndb': 9012,\n",
       " '证实': 131459,\n",
       " '情报机构': 75004,\n",
       " '通过': 139879,\n",
       " '社交': 113327,\n",
       " '媒体': 61205,\n",
       " '科研人员': 114399,\n",
       " '决策者': 37334,\n",
       " '建立联系': 70418,\n",
       " '有步骤': 89394,\n",
       " '试图': 131671,\n",
       " '套取': 59653,\n",
       " '信息': 32109,\n",
       " '德国联邦': 73142,\n",
       " '宪法': 63411,\n",
       " '保卫局': 31672,\n",
       " '无理': 85985,\n",
       " '指责': 80267,\n",
       " '如出一辙': 60383,\n",
       " '苏黎世': 126102,\n",
       " '首先': 149920,\n",
       " '消息': 100818,\n",
       " '该报': 131886,\n",
       " '间谍': 144564,\n",
       " '领英上': 149025,\n",
       " '化名': 42115,\n",
       " 'lilywu': 7708,\n",
       " 'evahan': 4013,\n",
       " 'rachelli': 10948,\n",
       " '自称': 124702,\n",
       " '复旦大学': 56344,\n",
       " '浙江大学': 100280,\n",
       " '某一': 92544,\n",
       " '机构': 90600,\n",
       " '主动': 23432,\n",
       " '联系': 122482,\n",
       " '人士': 27081,\n",
       " '邀请': 140416,\n",
       " '出席会议': 38354,\n",
       " '全部': 34754,\n",
       " '中方': 22566,\n",
       " '还会': 138032,\n",
       " '瑞方': 107596,\n",
       " '索要': 117850,\n",
       " '往往': 72406,\n",
       " '伴有': 30069,\n",
       " '回报': 53077,\n",
       " '数千': 83836,\n",
       " '瑞郎': 107625,\n",
       " '联邦': 122519,\n",
       " '了解': 24897,\n",
       " '平台': 68747,\n",
       " '搜集': 81997,\n",
       " '企图': 29084,\n",
       " '新闻': 85199,\n",
       " '发言人': 46812,\n",
       " '格拉': 93421,\n",
       " '贝对': 133041,\n",
       " '联络': 122494,\n",
       " '议员': 131112,\n",
       " '公务员': 35034,\n",
       " '军方': 36809,\n",
       " '银行职员': 143344,\n",
       " '学术': 61827,\n",
       " '科研机构': 114405,\n",
       " '职员': 122345,\n",
       " '有人': 89113,\n",
       " '怀疑': 73938,\n",
       " '情报人员': 74999,\n",
       " '扮成': 77820,\n",
       " '渗透到': 101853,\n",
       " '公司': 35049,\n",
       " '研究': 112744,\n",
       " '目标': 111111,\n",
       " '进行': 138512,\n",
       " '间谍活动': 144565,\n",
       " '一名': 16284,\n",
       " '具名': 36007,\n",
       " '官员': 62646,\n",
       " '许多': 131275,\n",
       " '显得': 87670,\n",
       " '无知': 86013,\n",
       " '因为': 53186,\n",
       " '工资': 67233,\n",
       " '工作': 67052,\n",
       " '努力': 41585,\n",
       " '企业': 29042,\n",
       " '受欢迎': 47037,\n",
       " '金融': 142385,\n",
       " '制药': 40263,\n",
       " '行业': 128708,\n",
       " '世界领先': 20770,\n",
       " '感兴趣': 75482,\n",
       " '大国': 57559,\n",
       " '为此': 23335,\n",
       " '不择手段': 19833,\n",
       " '当局': 72005,\n",
       " '问题': 144493,\n",
       " '上持': 18706,\n",
       " '谨慎': 132799,\n",
       " '态度': 73949,\n",
       " '担心': 79138,\n",
       " '其他': 35834,\n",
       " '指控': 80215,\n",
       " '不利于': 19443,\n",
       " '外交活动': 56482,\n",
       " '热炒': 104200,\n",
       " '网络': 120453,\n",
       " '中国外交部': 22196,\n",
       " '批驳': 77918,\n",
       " '似乎': 30102,\n",
       " '适用': 139341,\n",
       " '陆慷': 145521,\n",
       " '德方': 73182,\n",
       " '说法': 132145,\n",
       " '捕风捉影': 80722,\n",
       " '毫无根据': 96403,\n",
       " '希望': 68131,\n",
       " '政府部门': 83274,\n",
       " '不要': 20225,\n",
       " '采取': 141465,\n",
       " '中德关系': 22479,\n",
       " '不利': 19442,\n",
       " '言行': 130709,\n",
       " '环球时报': 106994,\n",
       " '文章': 84378,\n",
       " '很多': 72541,\n",
       " '误以为': 132018,\n",
       " '随便': 146338,\n",
       " '果是': 92353,\n",
       " '知道': 112352,\n",
       " '功能性': 41097,\n",
       " '食品': 149613,\n",
       " '直观': 111257,\n",
       " '分析': 38795,\n",
       " '一下': 15968,\n",
       " '王老吉': 106708,\n",
       " '看看': 111782,\n",
       " '配料表': 141158,\n",
       " '白砂糖': 110132,\n",
       " '全是': 34591,\n",
       " '中草药': 22825,\n",
       " '仙草': 28249,\n",
       " '鸡蛋花': 151868,\n",
       " '布渣叶': 67983,\n",
       " '菊花': 127144,\n",
       " '四季': 52802,\n",
       " '优美': 29461,\n",
       " '配方': 141159,\n",
       " '青梅': 147644,\n",
       " '膳食': 124340,\n",
       " '纤维': 118319,\n",
       " '桑叶': 93649,\n",
       " '决明子': 37324,\n",
       " '马黛茶': 150464,\n",
       " '胡萝卜素': 123455,\n",
       " '两者': 21570,\n",
       " '药食': 126891,\n",
       " '同源': 49347,\n",
       " '食材': 149644,\n",
       " '枸杞': 92506,\n",
       " '山楂': 66559,\n",
       " '一样': 16708,\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-18T07:14:21.527060Z",
     "start_time": "2018-07-18T07:14:21.508059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on CountVectorizer in module sklearn.feature_extraction.text object:\n",
      "\n",
      "class CountVectorizer(sklearn.base.BaseEstimator, VectorizerMixin)\n",
      " |  Convert a collection of text documents to a matrix of token counts\n",
      " |  \n",
      " |  This implementation produces a sparse representation of the counts using\n",
      " |  scipy.sparse.csr_matrix.\n",
      " |  \n",
      " |  If you do not provide an a-priori dictionary and you do not use an analyzer\n",
      " |  that does some kind of feature selection then the number of features will\n",
      " |  be equal to the vocabulary size found by analyzing the data.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <text_feature_extraction>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  input : string {'filename', 'file', 'content'}\n",
      " |      If 'filename', the sequence passed as an argument to fit is\n",
      " |      expected to be a list of filenames that need reading to fetch\n",
      " |      the raw content to analyze.\n",
      " |  \n",
      " |      If 'file', the sequence items must have a 'read' method (file-like\n",
      " |      object) that is called to fetch the bytes in memory.\n",
      " |  \n",
      " |      Otherwise the input is expected to be the sequence strings or\n",
      " |      bytes items are expected to be analyzed directly.\n",
      " |  \n",
      " |  encoding : string, 'utf-8' by default.\n",
      " |      If bytes or files are given to analyze, this encoding is used to\n",
      " |      decode.\n",
      " |  \n",
      " |  decode_error : {'strict', 'ignore', 'replace'}\n",
      " |      Instruction on what to do if a byte sequence is given to analyze that\n",
      " |      contains characters not of the given `encoding`. By default, it is\n",
      " |      'strict', meaning that a UnicodeDecodeError will be raised. Other\n",
      " |      values are 'ignore' and 'replace'.\n",
      " |  \n",
      " |  strip_accents : {'ascii', 'unicode', None}\n",
      " |      Remove accents during the preprocessing step.\n",
      " |      'ascii' is a fast method that only works on characters that have\n",
      " |      an direct ASCII mapping.\n",
      " |      'unicode' is a slightly slower method that works on any characters.\n",
      " |      None (default) does nothing.\n",
      " |  \n",
      " |  analyzer : string, {'word', 'char', 'char_wb'} or callable\n",
      " |      Whether the feature should be made of word or character n-grams.\n",
      " |      Option 'char_wb' creates character n-grams only from text inside\n",
      " |      word boundaries; n-grams at the edges of words are padded with space.\n",
      " |  \n",
      " |      If a callable is passed it is used to extract the sequence of features\n",
      " |      out of the raw, unprocessed input.\n",
      " |  \n",
      " |  preprocessor : callable or None (default)\n",
      " |      Override the preprocessing (string transformation) stage while\n",
      " |      preserving the tokenizing and n-grams generation steps.\n",
      " |  \n",
      " |  tokenizer : callable or None (default)\n",
      " |      Override the string tokenization step while preserving the\n",
      " |      preprocessing and n-grams generation steps.\n",
      " |      Only applies if ``analyzer == 'word'``.\n",
      " |  \n",
      " |  ngram_range : tuple (min_n, max_n)\n",
      " |      The lower and upper boundary of the range of n-values for different\n",
      " |      n-grams to be extracted. All values of n such that min_n <= n <= max_n\n",
      " |      will be used.\n",
      " |  \n",
      " |  stop_words : string {'english'}, list, or None (default)\n",
      " |      If 'english', a built-in stop word list for English is used.\n",
      " |  \n",
      " |      If a list, that list is assumed to contain stop words, all of which\n",
      " |      will be removed from the resulting tokens.\n",
      " |      Only applies if ``analyzer == 'word'``.\n",
      " |  \n",
      " |      If None, no stop words will be used. max_df can be set to a value\n",
      " |      in the range [0.7, 1.0) to automatically detect and filter stop\n",
      " |      words based on intra corpus document frequency of terms.\n",
      " |  \n",
      " |  lowercase : boolean, True by default\n",
      " |      Convert all characters to lowercase before tokenizing.\n",
      " |  \n",
      " |  token_pattern : string\n",
      " |      Regular expression denoting what constitutes a \"token\", only used\n",
      " |      if ``analyzer == 'word'``. The default regexp select tokens of 2\n",
      " |      or more alphanumeric characters (punctuation is completely ignored\n",
      " |      and always treated as a token separator).\n",
      " |  \n",
      " |  max_df : float in range [0.0, 1.0] or int, default=1.0\n",
      " |      When building the vocabulary ignore terms that have a document\n",
      " |      frequency strictly higher than the given threshold (corpus-specific\n",
      " |      stop words).\n",
      " |      If float, the parameter represents a proportion of documents, integer\n",
      " |      absolute counts.\n",
      " |      This parameter is ignored if vocabulary is not None.\n",
      " |  \n",
      " |  min_df : float in range [0.0, 1.0] or int, default=1\n",
      " |      When building the vocabulary ignore terms that have a document\n",
      " |      frequency strictly lower than the given threshold. This value is also\n",
      " |      called cut-off in the literature.\n",
      " |      If float, the parameter represents a proportion of documents, integer\n",
      " |      absolute counts.\n",
      " |      This parameter is ignored if vocabulary is not None.\n",
      " |  \n",
      " |  max_features : int or None, default=None\n",
      " |      If not None, build a vocabulary that only consider the top\n",
      " |      max_features ordered by term frequency across the corpus.\n",
      " |  \n",
      " |      This parameter is ignored if vocabulary is not None.\n",
      " |  \n",
      " |  vocabulary : Mapping or iterable, optional\n",
      " |      Either a Mapping (e.g., a dict) where keys are terms and values are\n",
      " |      indices in the feature matrix, or an iterable over terms. If not\n",
      " |      given, a vocabulary is determined from the input documents. Indices\n",
      " |      in the mapping should not be repeated and should not have any gap\n",
      " |      between 0 and the largest index.\n",
      " |  \n",
      " |  binary : boolean, default=False\n",
      " |      If True, all non zero counts are set to 1. This is useful for discrete\n",
      " |      probabilistic models that model binary events rather than integer\n",
      " |      counts.\n",
      " |  \n",
      " |  dtype : type, optional\n",
      " |      Type of the matrix returned by fit_transform() or transform().\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  vocabulary_ : dict\n",
      " |      A mapping of terms to feature indices.\n",
      " |  \n",
      " |  stop_words_ : set\n",
      " |      Terms that were ignored because they either:\n",
      " |  \n",
      " |        - occurred in too many documents (`max_df`)\n",
      " |        - occurred in too few documents (`min_df`)\n",
      " |        - were cut off by feature selection (`max_features`).\n",
      " |  \n",
      " |      This is only available if no vocabulary was given.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  HashingVectorizer, TfidfVectorizer\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The ``stop_words_`` attribute can get large and increase the model size\n",
      " |  when pickling. This attribute is provided only for introspection and can\n",
      " |  be safely removed using delattr or set to None before pickling.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CountVectorizer\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      VectorizerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, stop_words=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), analyzer='word', max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class 'numpy.int64'>)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, raw_documents, y=None)\n",
      " |      Learn a vocabulary dictionary of all tokens in the raw documents.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      raw_documents : iterable\n",
      " |          An iterable which yields either str, unicode or file objects.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  fit_transform(self, raw_documents, y=None)\n",
      " |      Learn the vocabulary dictionary and return term-document matrix.\n",
      " |      \n",
      " |      This is equivalent to fit followed by transform, but more efficiently\n",
      " |      implemented.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      raw_documents : iterable\n",
      " |          An iterable which yields either str, unicode or file objects.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : array, [n_samples, n_features]\n",
      " |          Document-term matrix.\n",
      " |  \n",
      " |  get_feature_names(self)\n",
      " |      Array mapping from feature integer indices to feature name\n",
      " |  \n",
      " |  inverse_transform(self, X)\n",
      " |      Return terms per document with nonzero entries in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array, sparse matrix}, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_inv : list of arrays, len = n_samples\n",
      " |          List of arrays of terms.\n",
      " |  \n",
      " |  transform(self, raw_documents)\n",
      " |      Transform documents to document-term matrix.\n",
      " |      \n",
      " |      Extract token counts out of raw text documents using the vocabulary\n",
      " |      fitted with fit or the one provided to the constructor.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      raw_documents : iterable\n",
      " |          An iterable which yields either str, unicode or file objects.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : sparse matrix, [n_samples, n_features]\n",
      " |          Document-term matrix.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from VectorizerMixin:\n",
      " |  \n",
      " |  build_analyzer(self)\n",
      " |      Return a callable that handles preprocessing and tokenization\n",
      " |  \n",
      " |  build_preprocessor(self)\n",
      " |      Return a function to preprocess the text before tokenization\n",
      " |  \n",
      " |  build_tokenizer(self)\n",
      " |      Return a function that splits a string into a sequence of tokens\n",
      " |  \n",
      " |  decode(self, doc)\n",
      " |      Decode the input into a string of unicode symbols\n",
      " |      \n",
      " |      The decoding strategy depends on the vectorizer parameters.\n",
      " |  \n",
      " |  get_stop_words(self)\n",
      " |      Build or fetch the effective stop words list\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T06:52:51.068582Z",
     "start_time": "2018-07-03T06:49:42.688380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('tf_idf', Pipeline(memory=None,\n",
       "     steps=[('counts', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0...tate=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('tf_idf', Pipeline([\n",
    "            ('counts', CountVectorizer()),\n",
    "            ('tf_idf', TfidfTransformer()),\n",
    "            ('chi', SelectKBest(chi2, k=20000))\n",
    "        ])),\n",
    "        ('len_stats', StatsFeatures())\n",
    "    ])),\n",
    "    ('classifier', XGBClassifier(max_depth=7,objective='multi:softmax', num_class=2))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T06:53:04.027707Z",
     "start_time": "2018-07-03T06:52:51.087583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9536668142245831\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T06:53:05.363973Z",
     "start_time": "2018-07-03T06:53:04.034707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.8911022576361222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.94      0.91       862\n",
      "          1       0.92      0.82      0.87       644\n",
      "\n",
      "avg / total       0.89      0.89      0.89      1506\n",
      "\n",
      "confusion_matrix: \n",
      "[[813  49]\n",
      " [115 529]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_class = pipeline.predict(X_test)\n",
    "print('accuracy_score: ', metrics.accuracy_score(y_test, y_pred_class)) # 指所有分类正确的百分比\n",
    "print(metrics.classification_report(y_test, y_pred_class))\n",
    "print('confusion_matrix: ')\n",
    "print( metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T06:53:06.947443Z",
     "start_time": "2018-07-03T06:53:05.381974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.8652058432934927\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.89      0.88       862\n",
      "          1       0.85      0.84      0.84       644\n",
      "\n",
      "avg / total       0.87      0.87      0.87      1506\n",
      "\n",
      "confusion_matrix: \n",
      "[[764  98]\n",
      " [105 539]]\n"
     ]
    }
   ],
   "source": [
    "# 上一版模型 \n",
    "y_pred_class = pipeline_old.predict(X_test)\n",
    "print('accuracy_score: ', metrics.accuracy_score(y_test, y_pred_class)) # 指所有分类正确的百分比\n",
    "print(metrics.classification_report(y_test, y_pred_class))\n",
    "print('confusion_matrix: ')\n",
    "print( metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T09:51:12.095774Z",
     "start_time": "2018-06-13T09:51:11.751754Z"
    },
    "collapsed": true
   },
   "source": [
    "# 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T06:53:13.531160Z",
     "start_time": "2018-07-03T06:53:06.953443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/circ_cor_0703.pkl.z']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(pipeline, \"model/circ_cor_0703.pkl.z\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存本文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T06:53:13.560161Z",
     "start_time": "2018-07-03T06:53:13.537160Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    import datetime as dt\n",
    "    \n",
    "    def output_HTML(read_file, output_file):\n",
    "        from nbconvert import HTMLExporter\n",
    "        import codecs\n",
    "        import nbformat\n",
    "        exporter = HTMLExporter()\n",
    "        # read_file is '.ipynb', output_file is '.html'\n",
    "        output_notebook = nbformat.read(read_file, as_version=4)\n",
    "        output, resources = exporter.from_notebook_node(output_notebook)\n",
    "        codecs.open(output_file, 'w', encoding='utf-8').write(output)\n",
    "\n",
    "    html_file_folder = 'html_files'\n",
    "    if not os.path.exists(html_file_folder):\n",
    "        os.makedirs(html_file_folder)\n",
    "\n",
    "    today = dt.datetime.now().strftime('%Y%m%d')\n",
    "    current_file = 'circ_cor_model_2_train.ipynb'\n",
    "    output_file = 'html_files\\%s_%s.html'%(os.path.splitext(current_file)[0], today)\n",
    "    output_HTML(current_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

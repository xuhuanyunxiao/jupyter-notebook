{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T07:53:12.851864Z",
     "start_time": "2018-06-13T07:53:12.785860Z"
    }
   },
   "outputs": [],
   "source": [
    "##load packages, needed\n",
    "# encoding=utf-8\n",
    "\n",
    "import jieba\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2,mutual_info_classif,f_classif\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import KFold  \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.neighbors import KNeighborsClassifier   \n",
    "from sklearn import svm  \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "\n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from collections import defaultdict\n",
    "\n",
    "import joblib\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import pre\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T07:54:00.868610Z",
     "start_time": "2018-06-13T07:54:00.816607Z"
    }
   },
   "outputs": [],
   "source": [
    "class StatsFeatures(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.neg = set()\n",
    "        f = open(\"neg_words.txt\",\"r+\", encoding='UTF-8')\n",
    "        for content in f:\n",
    "            self.neg.add(content)\n",
    "        f.close()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def getcnt(self,x):\n",
    "        return len(list(set(x)))\n",
    "\n",
    "    def getnegcnt(self,x):\n",
    "        negcnt = 0\n",
    "        words = x.split()\n",
    "        for w in words:\n",
    "            if w in self.neg:\n",
    "                negcnt = negcnt+1\n",
    "        return negcnt\n",
    "    def transform(self, X):\n",
    "        data = []\n",
    "        for x in X:\n",
    "            if len(x) == 0:\n",
    "                length  = 1\n",
    "            else :\n",
    "                length = len(x)\n",
    "            data.append([len(x),self.getcnt(x),self.getcnt(x)/length,\n",
    "                         self.getnegcnt(x),self.getnegcnt(x)/length])            \n",
    "        return data\n",
    "#韩老师 原始自定义特征函数    \n",
    "#     def transform(self, X):\n",
    "#         #return [[len(x),self.getcnt(x),self.getcnt(x)/len(x),self.getnegcnt(x),self.getnegcnt(x)/len(x)] for x in X]\n",
    "#         return [[len(x),self.getcnt(x),self.getcnt(x)/len(x)] for x in X]\n",
    "\n",
    "#针对分词后部分新闻词数量<1   许欢 2018.06.19\n",
    "\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T09:01:25.294938Z",
     "start_time": "2018-06-13T09:01:25.264937Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classified_index(corpus_p, corpus_n, corpus, lab, chapter_pipeline_1):\n",
    "    '''\n",
    "    二分类模型各指标的结果\n",
    "    '''\n",
    "    \n",
    "    res = chapter_pipeline_1.predict(corpus_p)\n",
    "    print('正样本预测准确率: ', float(sum(res))/len(res),len(res))\n",
    "    \n",
    "    res = chapter_pipeline_1.predict(corpus_n)\n",
    "    print('负样本预测准确率: ',  1-float(sum(res))/len(res),len(res))\n",
    "    \n",
    "    y_pred_class = chapter_pipeline_1.predict(corpus)\n",
    "    print('accuracy_score: ', metrics.accuracy_score(lab, y_pred_class)) # 指所有分类正确的百分比\n",
    "    print(metrics.classification_report(lab, y_pred_class))\n",
    "    print('confusion_matrix: ')\n",
    "    print( metrics.confusion_matrix(lab, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保监会非预警数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取非预警数据 .txt\n",
    "n_corpus=[]\n",
    "n_labels=[]\n",
    "resultfile=open('F:/工作文件/银保监会/模型训练/预警/保监会/0612保监会非预警.txt','w',encoding='UTF-8') \n",
    "txt_filenames = glob.glob('F:/工作文件/银保监会/模型训练/预警/保监会/0612保监会非预警/*.txt')#获取当前文档下 所有后缀名称为.txt的文件\n",
    "for filename in txt_filenames:\n",
    "    #print (\"handling file: \"+filename)\n",
    "    #if(pre.handlefile(filename,resultfile)is None):\n",
    "        #print(filename) \n",
    "    n_corpus.append(pre.handlefile(filename,resultfile))\n",
    "    n_labels.append(0)\n",
    "resultfile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保监会预警数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0621\n",
    "#读取预警数据 .excel\n",
    "p_corpus_1 = pd.read_excel('F:/工作文件/银保监会/模型训练/预警/保监会/0612保监会预警数据.xlsx')\n",
    "p_corpus_1['label'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并相关与不相关数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3552 3552\n"
     ]
    }
   ],
   "source": [
    "#0621合并数据\n",
    "corpus_raw=n_corpus+pre.handle_contents(p_corpus_1['content'].tolist())\n",
    "label=n_labels+p_corpus_1['label'].tolist() \n",
    "print(len(corpus_raw),len(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 去除分词后词数量过少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将分完词后  词数量=0 的语料删除\n",
    "corpus_i = []\n",
    "label_i = []\n",
    "for m,n in zip(corpus_raw, label):\n",
    "    if m ==\"\" or m is None:\n",
    "        print('m:', m,'  - n:',n)\n",
    "    else :\n",
    "        corpus_i.append(m)\n",
    "        label_i.append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分割训练集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T08:02:51.609967Z",
     "start_time": "2018-06-13T08:02:51.590966Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(corpus_i, label_i, test_size=0.33, random_state=42)\n",
    "#random_state随机状态种子  对于某一个伪随机数发生器，只要该种子（seed）相同，产生的随机数序列就是相同的\n",
    "#不同的随机种子状态将会有不同的数据生成模式  也就是会产生不同的随机数序列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T08:04:19.549997Z",
     "start_time": "2018-06-13T08:02:54.759147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('tf_idf', Pipeline(memory=None,\n",
       "     steps=[('counts', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0...tate=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('tf_idf', Pipeline([\n",
    "            ('counts', CountVectorizer()),\n",
    "            ('tf_idf', TfidfTransformer()),\n",
    "            ('chi', SelectKBest(chi2, k=20000))\n",
    "        ])),\n",
    "        ('len_stats', StatsFeatures())\n",
    "    ])),\n",
    "    ('classifier', XGBClassifier(max_depth=7,objective='multi:softmax', num_class=2))\n",
    "])\n",
    "\n",
    "#params = {'nthread':8,'max_depth':6, 'eta':0.2, 'eval_metric':'merror', 'silent':1, 'objective':'multi:softmax', 'num_class':2}  # 参数\n",
    "#\n",
    "pipeline.fit(X_train, y_train)\n",
    " \n",
    "#kf = KFold(len(corpus), n_folds=10, shuffle=True)    \n",
    "#result_set = [(pipeline.fit(corpus[train], lab[train]).predict(corpus[test]), test) for train, test in kf]    \n",
    "#score = [accuracy(lab[result[1]], result[0]) for result in result_set]    \n",
    "#print(score,np.average(score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T08:04:30.582628Z",
     "start_time": "2018-06-13T08:04:24.887302Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T08:06:49.116552Z",
     "start_time": "2018-06-13T08:06:46.380395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.9147485080988917\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.94      0.93       657\n",
      "          1       0.92      0.88      0.90       516\n",
      "\n",
      "avg / total       0.92      0.91      0.91      1173\n",
      "\n",
      "confusion_matrix: \n",
      "[[620  37]\n",
      " [ 63 453]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred_class = pipeline.predict(X_test)\n",
    "print('accuracy_score: ', metrics.accuracy_score(y_test, y_pred_class)) # 指所有分类正确的百分比\n",
    "print(metrics.classification_report(y_test, y_pred_class))\n",
    "print('confusion_matrix: ')\n",
    "print( metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline_noise' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-06d3bd910c73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#保存训练好的模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_noise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model/0621_circ_yuqing.pkl.z\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pipeline_noise' is not defined"
     ]
    }
   ],
   "source": [
    "#保存训练好的模型\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(pipeline, \"model/0621_circ_yuqing.pkl.z\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

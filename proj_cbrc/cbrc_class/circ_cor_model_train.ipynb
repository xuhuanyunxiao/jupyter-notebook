{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 保监会 分类模型 2 训练 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:07:39.614261Z",
     "start_time": "2018-07-31T07:07:37.306982Z"
    }
   },
   "outputs": [],
   "source": [
    "##load packages, needed\n",
    "# encoding=utf-8\n",
    "\n",
    "import jieba\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2,mutual_info_classif,f_classif \n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from collections import defaultdict\n",
    "\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pre_cor\n",
    "import dict_dbutils\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sqlalchemy import create_engine\n",
    "from pandas.io import sql\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T09:53:23.260176Z",
     "start_time": "2018-07-27T09:53:23.254124Z"
    }
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    class StatsFeatures(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "        def __init__(self):\n",
    "            self.neg = set()\n",
    "            f = open(\"corpus/neg_words.txt\",\"r+\", encoding='UTF-8')\n",
    "            for content in f:\n",
    "                self.neg.add(content)\n",
    "            f.close()\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "\n",
    "        def getcnt(self,x):        \n",
    "            return len(list(set(x)))\n",
    "\n",
    "        def getnegcnt(self,x):\n",
    "            negcnt = 0\n",
    "            words = x.split()\n",
    "            for w in words:\n",
    "                if w in self.neg:\n",
    "                    negcnt = negcnt+1\n",
    "            return negcnt\n",
    "    \n",
    "        def transform(self, X):\n",
    "            data = []\n",
    "            for x in X:\n",
    "                if len(x) == 0:\n",
    "                    length  = 1\n",
    "                else :\n",
    "                    length = len(x)\n",
    "                data.append([len(x),self.getcnt(x),self.getcnt(x)/length,\n",
    "                             self.getnegcnt(x),self.getnegcnt(x)/length])            \n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:07:40.866120Z",
     "start_time": "2018-07-31T07:07:40.857557Z"
    }
   },
   "outputs": [],
   "source": [
    "class StatsFeatures_cor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.neg = set()\n",
    "        f = open(\"corpus/neg_words.txt\",\"r+\", encoding='UTF-8')\n",
    "        for content in f:\n",
    "            self.neg.add(content)\n",
    "        f.close()\n",
    "        dict_org=dict_dbutils.get_dicts()\n",
    "        self.org=set(dict_org.keys())\n",
    "        \n",
    "        \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def getcnt(self,x):        \n",
    "        return len(list(set(x)))\n",
    "\n",
    "    def getnegcnt(self,x):\n",
    "        negcnt = 0\n",
    "        words = x.split()\n",
    "        for w in words:\n",
    "            if w in self.neg:\n",
    "                negcnt = negcnt+1\n",
    "        return negcnt\n",
    "    def getorgcnttf(self,x):\n",
    "        orgcnt=0\n",
    "        orgtf=0\n",
    "        words = x.split()\n",
    "        words_set=set(words)\n",
    "        for w in words_set:\n",
    "            if w in self.org:\n",
    "                orgcnt = orgcnt+1\n",
    "                orgtf=orgtf+words.count(w)\n",
    "        if(orgcnt>0):\n",
    "            return orgcnt,orgtf\n",
    "        else:\n",
    "            return orgcnt,orgtf\n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "        data = []\n",
    "        for x in X:\n",
    "            if len(x) == 0:\n",
    "                length  = 1\n",
    "            else :\n",
    "                length = len(x)\n",
    "            orgcnt,orgtf=self.getorgcnttf(x)\n",
    "            data.append([len(x),self.getcnt(x),self.getcnt(x)/length,\n",
    "                         self.getnegcnt(x),self.getnegcnt(x)/length,\n",
    "                         orgcnt,orgtf])            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StatsFeatures_01(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.neg = set()\n",
    "        f = open(\"corpus/neg_words.txt\",\"r+\", encoding='UTF-8')\n",
    "        for content in f:\n",
    "            self.neg.add(content)\n",
    "        f.close()\n",
    "        dict_org=dict_dbutils.get_dicts()\n",
    "        self.org=set(dict_org.keys())\n",
    "        \n",
    "        \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def getcnt(self,x):        \n",
    "        return len(list(set(x)))\n",
    "\n",
    "    def getnegcnt(self,x):\n",
    "        negcnt = 0\n",
    "        words = x.split()\n",
    "        for w in words:\n",
    "            if w in self.neg:\n",
    "                negcnt = negcnt+1\n",
    "        return negcnt\n",
    "    def getorgcnttf(self,x):\n",
    "        orgcnt=0\n",
    "        orgtf=0\n",
    "        words = x.split()\n",
    "        words_set=set(words)\n",
    "        for w in words_set:\n",
    "            if w in self.org:\n",
    "                orgcnt = orgcnt+1\n",
    "                orgtf=orgtf+words.count(w)\n",
    "        if(orgcnt>0):\n",
    "            return orgcnt,orgtf\n",
    "        else:\n",
    "            return orgcnt,orgtf\n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "        data = []\n",
    "        for x in X:\n",
    "            if len(x) == 0:\n",
    "                length  = 1\n",
    "            else :\n",
    "                length = len(x)\n",
    "            orgcnt,orgtf=self.getorgcnttf(x)\n",
    "            data.append([len(x),self.getcnt(x),self.getcnt(x)/length,\n",
    "                         self.getnegcnt(x),self.getnegcnt(x)/length,\n",
    "                         orgcnt,orgtf])            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上一版模型读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T02:42:59.136881Z",
     "start_time": "2018-07-19T02:42:53.723420Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 上一版模型\n",
    "# from sklearn.externals import joblib\n",
    "# pipeline_old = joblib.load( \"model/circ_cor_0625.pkl.z\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:07:46.076460Z",
     "start_time": "2018-07-31T07:07:45.913195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7508\n"
     ]
    }
   ],
   "source": [
    "title_content = []\n",
    "filename = 'data/result/all_titles+contents_pre.txt'\n",
    "fid = open(filename, \"r+\", encoding='UTF-8')\n",
    "for f in fid:\n",
    "    title_content.append(f.strip())\n",
    "fid.close()\n",
    "print(len(title_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:07:48.056780Z",
     "start_time": "2018-07-31T07:07:47.891142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7508\n"
     ]
    }
   ],
   "source": [
    "content = []\n",
    "filename = 'data/result/all_contents_pre.txt'\n",
    "fid = open(filename, \"r+\", encoding='UTF-8')\n",
    "for f in fid:\n",
    "    content.append(f.strip())\n",
    "fid.close()\n",
    "print(len(title_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:07:50.311104Z",
     "start_time": "2018-07-31T07:07:50.306921Z"
    }
   },
   "outputs": [],
   "source": [
    "label_dic={'监管':1,'行业':2,'产品销售':3,'资本市场':4,'公司内部管理':5,'消费服务':6,'其他相关报道':7,'噪音':8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:07:51.917832Z",
     "start_time": "2018-07-31T07:07:51.881567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7508\n"
     ]
    }
   ],
   "source": [
    "label = []\n",
    "filename = 'data/result/all_labels_pre.txt'\n",
    "fid = open(filename, \"r+\", encoding='UTF-8')\n",
    "for f in fid:\n",
    "    label.append(f.strip())\n",
    "fid.close()\n",
    "label=[label_dic[x.strip()] for x in label]\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:07:53.512186Z",
     "start_time": "2018-07-31T07:07:53.481092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7508\n"
     ]
    }
   ],
   "source": [
    "title = []\n",
    "filename = 'data/result/all_titles_pre.txt'\n",
    "fid = open(filename, \"r+\", encoding='UTF-8')\n",
    "for f in fid:\n",
    "    title.append(f.strip())\n",
    "fid.close()\n",
    "print(len(title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分割训练集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:07:57.532824Z",
     "start_time": "2018-07-31T07:07:57.520834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集： 6757\n",
      "训练集-各类数量： Counter({8: 3054, 1: 1338, 7: 611, 5: 522, 4: 420, 3: 288, 2: 273, 6: 251})\n",
      "测试集： 751\n",
      "测试集-各类数量： Counter({8: 323, 1: 150, 7: 67, 5: 62, 2: 44, 4: 43, 3: 32, 6: 30})\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(title_content, label, test_size=0.1, random_state=42)\n",
    "print('训练集：',len(y_train))\n",
    "print('训练集-各类数量：',Counter(y_train))\n",
    "print('测试集：',len(y_test))\n",
    "print('测试集-各类数量：',Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:13:56.609192Z",
     "start_time": "2018-07-31T07:07:59.858169Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('tf_idf', Pipeline(memory=None,\n",
       "     steps=[('counts', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0...tate=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('tf_idf', Pipeline([\n",
    "            ('counts', CountVectorizer()),\n",
    "            ('tf_idf', TfidfTransformer()),\n",
    "            ('chi', SelectKBest(chi2, k=20000))\n",
    "        ])),\n",
    "        ('len_stats', StatsFeatures_cor())\n",
    "    ])),\n",
    "    ('classifier', XGBClassifier(max_depth=7,objective='multi:softmax', num_class=8))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:14:42.231608Z",
     "start_time": "2018-07-31T07:14:28.555100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9979280745893148\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:14:47.466965Z",
     "start_time": "2018-07-31T07:14:45.907012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.8415446071904128\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.83      0.87      0.85       150\n",
      "          2       0.79      0.50      0.61        44\n",
      "          3       0.81      0.53      0.64        32\n",
      "          4       0.86      0.72      0.78        43\n",
      "          5       0.75      0.74      0.75        62\n",
      "          6       0.96      0.80      0.87        30\n",
      "          7       0.85      0.90      0.87        67\n",
      "          8       0.86      0.93      0.89       323\n",
      "\n",
      "avg / total       0.84      0.84      0.84       751\n",
      "\n",
      "confusion_matrix: \n",
      "[[131   2   0   0   4   0   1  12]\n",
      " [  6  22   1   1   2   1   1  10]\n",
      " [  1   0  17   0   1   0   3  10]\n",
      " [  1   1   0  31   1   0   0   9]\n",
      " [  7   1   1   0  46   0   4   3]\n",
      " [  1   0   0   0   2  24   0   3]\n",
      " [  0   1   1   0   1   0  60   4]\n",
      " [ 10   1   1   4   4   0   2 301]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_class = pipeline.predict(X_test)\n",
    "print('accuracy_score: ', metrics.accuracy_score(y_test, y_pred_class)) # 指所有分类正确的百分比\n",
    "print(metrics.classification_report(y_test, y_pred_class))\n",
    "print('confusion_matrix: ')\n",
    "print( metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T06:53:06.947443Z",
     "start_time": "2018-07-03T06:53:05.381974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.8652058432934927\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.89      0.88       862\n",
      "          1       0.85      0.84      0.84       644\n",
      "\n",
      "avg / total       0.87      0.87      0.87      1506\n",
      "\n",
      "confusion_matrix: \n",
      "[[764  98]\n",
      " [105 539]]\n"
     ]
    }
   ],
   "source": [
    "# 上一版模型 \n",
    "y_pred_class = pipeline_old.predict(X_test)\n",
    "print('accuracy_score: ', metrics.accuracy_score(y_test, y_pred_class)) # 指所有分类正确的百分比\n",
    "print(metrics.classification_report(y_test, y_pred_class))\n",
    "print('confusion_matrix: ')\n",
    "print( metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T09:51:12.095774Z",
     "start_time": "2018-06-13T09:51:11.751754Z"
    },
    "collapsed": true
   },
   "source": [
    "# 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T07:15:22.901197Z",
     "start_time": "2018-07-31T07:15:16.443083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/circ_8classifier_0731.pkl.z']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(pipeline, \"model/circ_8classifier_0731.pkl.z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存本文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T06:53:13.560161Z",
     "start_time": "2018-07-03T06:53:13.537160Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    import datetime as dt\n",
    "    \n",
    "    def output_HTML(read_file, output_file):\n",
    "        from nbconvert import HTMLExporter\n",
    "        import codecs\n",
    "        import nbformat\n",
    "        exporter = HTMLExporter()\n",
    "        # read_file is '.ipynb', output_file is '.html'\n",
    "        output_notebook = nbformat.read(read_file, as_version=4)\n",
    "        output, resources = exporter.from_notebook_node(output_notebook)\n",
    "        codecs.open(output_file, 'w', encoding='utf-8').write(output)\n",
    "\n",
    "    html_file_folder = 'html_files'\n",
    "    if not os.path.exists(html_file_folder):\n",
    "        os.makedirs(html_file_folder)\n",
    "\n",
    "    today = dt.datetime.now().strftime('%Y%m%d')\n",
    "    current_file = 'circ_cor_model_2_train.ipynb'\n",
    "    output_file = 'html_files\\%s_%s.html'%(os.path.splitext(current_file)[0], today)\n",
    "    output_HTML(current_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

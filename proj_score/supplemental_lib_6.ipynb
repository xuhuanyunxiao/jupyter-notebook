{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T05:59:22.325573Z",
     "start_time": "2018-04-04T05:59:21.189508Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import datetime as dt\n",
    "\n",
    "today = dt.datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from pandas.io import sql\n",
    "\n",
    "from impala.dbapi import connect\n",
    "from impala.util import as_pandas\n",
    "\n",
    "names = locals()\n",
    "\n",
    "#\n",
    "pyfile_folder = r'D:\\XH\\Python_Project\\Proj_2\\files'\n",
    "data_folder = r'D:\\XH\\Python_Project\\Proj_2\\data\\ETL_data'\n",
    "result_folder = r'D:\\XH\\Python_Project\\Proj_2\\result\\ETL_result'\n",
    "\n",
    "os.chdir(pyfile_folder)\n",
    "sys.path.append(pyfile_folder)\n",
    "\n",
    "from Tookits import specific_func  \n",
    "from Tookits import cal_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T03:44:05.773333Z",
     "start_time": "2018-04-04T03:44:05.761332Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#% 结果文件夹结构\n",
    "database_list = ['odm_1','sdm_2','fdm_3','gdm_4',\n",
    "                 'standard_lib_5','supplemental_lib_6']\n",
    "for folder_n in database_list:\n",
    "    if not os.path.exists(result_folder + '\\\\' + folder_n):\n",
    "        os.mkdir(result_folder + '\\\\' + folder_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T05:59:32.025128Z",
     "start_time": "2018-04-04T05:59:31.854118Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% 建立连接\n",
    "# MySQL\n",
    "DB_CON_STR = 'mysql+pymysql://root:123456@localhost/supplemental_lib_6_mysql?charset=utf8'  \n",
    "engine = create_engine(DB_CON_STR, echo=False) \n",
    "\n",
    "# Hive\n",
    "conn = connect(host=\"192.168.20.102\", port=10000,  # database=\"system\", \n",
    "               auth_mechanism=\"PLAIN\",\n",
    "               user = 'admin', password = 'admin')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_hive_query(sql):   \n",
    "    cursor.execute(sql)  \n",
    "    return cursor.fetchall() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 全量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T05:59:37.231426Z",
     "start_time": "2018-04-04T05:59:36.881406Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_name = database_name = 'supplemental_lib_6'\n",
    "\n",
    "save_filename = os.path.join(result_folder, \n",
    "                             'supplemental_lib_6\\\\hadoop语句_supplemental_lib_' + today + '.txt')\n",
    "file = open(save_filename,\"w\")\n",
    "\n",
    "cursor.execute(\"create database if not exists {0} \".format(database_name))\n",
    "cursor.execute(\"use \"+ database_name)\n",
    "\n",
    "file_name = 'outbound_investment_0329.csv'\n",
    "file_path = data_folder + '\\\\' + file_name\n",
    "table_name = os.path.splitext(file_name)[0]\n",
    "names['%s' %table_name] = pd.read_csv(file_path, nrows = 5)\n",
    "#file_path = result_folder +  '\\\\supplemental_lib_6\\\\' + table_name + '.csv'\n",
    "#names['%s' %table_name].to_csv(file_path, index = False, \n",
    " #                              header = False,  encoding = 'utf-8')\n",
    "\n",
    "field = [x.strip() + ' string' for x in names['%s' %table_name].columns.tolist()]\n",
    "\n",
    "# 在hive上建立标准表 \n",
    "cursor.execute('drop table if exists %s;' %table_name)     \n",
    "sql_code  =  \"create external table if not exists {0}{1}\".\\\n",
    "        format(table_name,tuple(field)).replace(\"'\",\"\") \\\n",
    "        + '\\n' + \"ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\" \\\n",
    "        + '\\n' + \"LOCATION '/tmp/20180314/{0}'\".format(table_name)      \n",
    "cursor.execute(sql_code)\n",
    "\n",
    "file.write(\"hdfs dfs -put -f '/home/hadoop/Public/ETL_data/{0}/{1}.csv' '/tmp/20180314/{1}'\".\\\n",
    "           format(database_name,table_name) + \"\\n\")    \n",
    "file.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T06:21:27.058344Z",
     "start_time": "2018-04-04T06:21:25.335245Z"
    }
   },
   "outputs": [],
   "source": [
    "folder_name = database_name = 'supplemental_lib_6'\n",
    "file_list = os.listdir(os.path.join(data_folder, folder_name))\n",
    "\n",
    "if not os.path.exists(result_folder + '\\\\' + folder_name + '\\\\' + today):\n",
    "    os.makedirs(result_folder + '\\\\' + folder_name + '\\\\' + today) \n",
    "    \n",
    "save_filename = os.path.join(result_folder, \n",
    "                             'supplemental_lib_6\\\\hadoop语句_supplemental_lib_' + today + '.txt')\n",
    "file = open(save_filename,\"w\")\n",
    "\n",
    "cursor.execute(\"create database if not exists {0} \".format(database_name))\n",
    "cursor.execute(\"use \"+ database_name)\n",
    "\n",
    "table_list = [name[0] for name in run_hive_query(\"show tables\")] \n",
    "\n",
    "for file_name in file_list:\n",
    "    table_name = os.path.splitext(file_name)[0]\n",
    "    if table_name not in table_list:\n",
    "        names['%s' %table_name] = pd.read_csv(os.path.join(data_folder + '\\\\' + folder_name, file_name), \n",
    "                                              nrows = 5)\n",
    "                             #  encoding = 'ANSI')\n",
    "        #file_path = result_folder +  '\\\\supplemental_lib_6\\\\' + table_name + '.csv'\n",
    "        #names['%s' %table_name].to_csv(file_path, index = False, \n",
    "                                  #     header = False,  encoding = 'utf-8')\n",
    "        # 统计\n",
    "      #  fea_filename = os.path.join(result_folder + '\\\\' + folder_name + '\\\\' + today, table_name + '.xlsx')        \n",
    "      #  single_fea_desc = cal_func.describe(names['%s' %table_name],fea_filename, data_rate = 0.1)\n",
    "\n",
    "        #  field = [x.strip() + ' string' \n",
    "        #           if ind > 0 else 'index string'\n",
    "        #           for ind, x in enumerate(names['%s' %table_name].columns.tolist())]\n",
    "        field = [x.strip() + ' string' for x in names['%s' %table_name].columns.tolist()]\n",
    "        # 在hive上建立标准表 \n",
    "        cursor.execute('drop table if exists %s;' %table_name)     \n",
    "        sql_code  =  \"create external table if not exists {0}{1}\".\\\n",
    "                format(table_name,tuple(field)).replace(\"'\",\"\") \\\n",
    "                + '\\n' + \"ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\" \\\n",
    "                + '\\n' + \"LOCATION '/tmp/20180314/{0}'\".format(table_name)      \n",
    "        cursor.execute(sql_code)\n",
    "\n",
    "        # 写入mysql\n",
    "    #    sql.to_sql(names['%s' %table_name], table_name, \n",
    "    #       engine, schema='supplemental_lib_6_mysql', if_exists='replace') \n",
    "\n",
    "        # 打印在hadoop上操作的语句\n",
    "    #    file.write(\"load data inpath '/home/hadoop/Public/ETL_data/{0}/{1}.csv' \\ # hive 上用\n",
    "    #               into table {1};\".format(database_name,table_n) + \"\\n\")\n",
    "        file.write(\"hdfs dfs -put -f '/home/hadoop/Public/ETL_data/{0}/{1}.csv' '/tmp/20180314/{1}'\".\\\n",
    "                   format(database_name,table_name) + \"\\n\")    \n",
    "    # 如果已经put过，需加参数 -f\n",
    "    #hdfs dfs -put -f '/home/hadoop/Public/ETL_data/standard_lib/city_symbol.csv' '/tmp/20180302/city_symbol'\n",
    "    \n",
    "file.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 增量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 全量  ODM to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_hive_query(sql_command):   \n",
    "    cursor.execute(sql_command)  \n",
    "    return cursor.fetchall() \n",
    "\n",
    "database_name = 'supplemental_lib_6'\n",
    "cursor.execute(\"use \"+ database_name) \n",
    "\n",
    "table_list = [name[0] for name in run_hive_query(\"show tables\")] \n",
    "\n",
    "for table_name in table_list:\n",
    "    cursor.execute(\"select * from %s\"%table_name)\n",
    "    tmp_data = as_pandas(cursor)\n",
    "    sql.to_sql(tmp_data, table_name, \n",
    "           engine, schema='supplemental_lib_6_mysql', if_exists='replace') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

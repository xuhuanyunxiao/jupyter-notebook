{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 用tensorboard/tensorboardX可视化pytorch结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorboardX 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装与启动"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 安装\n",
    "> - pip install tensorboard\n",
    "> - pip install tensorboardX\n",
    "\n",
    "- 启动\n",
    "> - tensorboard --logdir=tensorboard_log -host=127.0.0.1\n",
    "> - http://127.0.0.1:6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- -host=127.0.0.1是我自己添加的，不加的话也可以。但我自己电脑不加的话显示不出\n",
    "- tensorboard要更新到最新版本，不然有些功能没有\n",
    "- 数据量大的时候耐心等一等，可能要读取一会才出现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorboardX 实例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T09:05:31.765223Z",
     "start_time": "2018-12-05T09:04:32.422829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "resnet18 = models.resnet18(False)\n",
    "writer = SummaryWriter(log_dir='tensorboard_log/demo', comment='demo')\n",
    "sample_rate = 44100\n",
    "freqs = [262, 294, 330, 349, 392, 440, 440, 440, 440, 440, 440]\n",
    "\n",
    "for n_iter in range(100):\n",
    "\n",
    "    dummy_s1 = torch.rand(1)\n",
    "    dummy_s2 = torch.rand(1)\n",
    "    # data grouping by `slash`\n",
    "    writer.add_scalar('data/scalar1', dummy_s1[0], n_iter)\n",
    "    writer.add_scalar('data/scalar2', dummy_s2[0], n_iter)\n",
    "\n",
    "    writer.add_scalars('data/scalar_group', {'xsinx': n_iter * np.sin(n_iter),\n",
    "                                             'xcosx': n_iter * np.cos(n_iter),\n",
    "                                             'arctanx': np.arctan(n_iter)}, n_iter)\n",
    "\n",
    "    dummy_img = torch.rand(32, 3, 64, 64)  # output from network\n",
    "    if n_iter % 10 == 0:\n",
    "        x = vutils.make_grid(dummy_img, normalize=True, scale_each=True)\n",
    "        writer.add_image('Image', x, n_iter)\n",
    "\n",
    "        dummy_audio = torch.zeros(sample_rate * 2)\n",
    "        for i in range(x.size(0)):\n",
    "            # amplitude of sound should in [-1, 1]\n",
    "            dummy_audio[i] = np.cos(freqs[n_iter // 10] * np.pi * float(i) / float(sample_rate))\n",
    "        writer.add_audio('myAudio', dummy_audio, n_iter, sample_rate=sample_rate)\n",
    "\n",
    "        writer.add_text('Text', 'text logged at step:' + str(n_iter), n_iter)\n",
    "\n",
    "        for name, param in resnet18.named_parameters():\n",
    "            writer.add_histogram(name, param.clone().cpu().data.numpy(), n_iter)\n",
    "\n",
    "        # needs tensorboard 0.4RC or later\n",
    "        writer.add_pr_curve('xoxo', np.random.randint(2, size=100), np.random.rand(100), n_iter)\n",
    "\n",
    "dataset = datasets.MNIST('mnist', train=False, download=True)\n",
    "images = dataset.test_data[:100].float()\n",
    "label = dataset.test_labels[:100]\n",
    "\n",
    "features = images.view(100, 784)\n",
    "writer.add_embedding(features, metadata=label, label_img=images.unsqueeze(1))\n",
    "\n",
    "# export scalar data to JSON for external processing\n",
    "writer.export_scalars_to_json(\"./all_scalars.json\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性拟合的训练过程中的loss可视化和模型的保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T08:20:13.614754Z",
     "start_time": "2018-12-05T08:20:13.238733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/60,loss:0.1699\n",
      "Epoch 10/60,loss:0.1699\n",
      "Epoch 15/60,loss:0.1698\n",
      "Epoch 20/60,loss:0.1698\n",
      "Epoch 25/60,loss:0.1698\n",
      "Epoch 30/60,loss:0.1698\n",
      "Epoch 35/60,loss:0.1698\n",
      "Epoch 40/60,loss:0.1697\n",
      "Epoch 45/60,loss:0.1697\n",
      "Epoch 50/60,loss:0.1697\n",
      "Epoch 55/60,loss:0.1697\n",
      "Epoch 60/60,loss:0.1697\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngxTuIiIepHAXEfEghbuIiAf9fwBBowWlv0IqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa292ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "num_epoches = 60\n",
    "learning_rate = 0.01\n",
    "writer = SummaryWriter(log_dir='tensorboard_log/example', comment='Linear')\n",
    "x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168],\n",
    "                    [9.779], [6.182], [7.59], [2.167], [7.042],\n",
    "                    [10.791], [5.313], [7.997], [3.1]], dtype=np.float32)\n",
    "y_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573],\n",
    "                    [3.366], [2.596], [2.53], [1.221], [2.827],\n",
    "                    [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)\n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "\n",
    "    output = model(inputs)\n",
    "    loss = criterion(output, targets)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # 保存loss的数据与epoch数值\n",
    "    writer.add_scalar('Train', loss, epoch)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('Epoch {}/{},loss:{:.4f}'.format(epoch + 1, num_epoches, loss.item()))\n",
    "\n",
    "# 将model保存为graph\n",
    "writer.add_graph(model, (inputs,))\n",
    "\n",
    "predicted = model(torch.from_numpy(x_train)).detach().numpy()\n",
    "plt.plot(x_train, y_train, 'ro', label='Original data')\n",
    "plt.plot(x_train, predicted, label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorboardX 可视化方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scalar 变量\n",
    "- SummaryWriter: log_dir为生成的文件所放的目录，comment为文件名称\n",
    "- writer.add_scalar('scalar/test', np.random.rand(), epoch)，这句代码的作用就是，将我们所需要的数据保存在文件里面供可视化使用。 \n",
    "- 这里是Scalar类型，所以使用writer.add_scalar()，其他的队形使用对应的函数。\n",
    "    - 第一个参数可以简单理解为保存图的名称，\n",
    "    - 第二个参数是可以理解为Y轴数据，\n",
    "    - 第三个参数可以理解为X轴数据。\n",
    "    - 当Y轴数据不止一个时，可以使用writer.add_scalars()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T08:19:58.370882Z",
     "start_time": "2018-12-05T08:19:58.249875Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir='tensorboard_log/scalar')\n",
    "for epoch in range(100):\n",
    "    writer.add_scalar('test', np.random.rand(), epoch)\n",
    "    writer.add_scalars('scalars_test', \n",
    "                       {'xsinx': epoch * np.sin(epoch), \n",
    "                        'xcosx': epoch * np.cos(epoch)}, epoch)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Graph 神经网络架构\n",
    "- 因为这是一个神经网络架构，所以使用 w.add_graph(model, (dummy_input,))\n",
    "    - 第一个参数为需要保存的模型，\n",
    "    - 第二个参数为输入值，元祖类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T08:19:31.201328Z",
     "start_time": "2018-12-05T08:19:31.059320Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        self.bn = nn.BatchNorm2d(20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(self.conv1(x), 2)\n",
    "        x = F.relu(x) + F.relu(-x)\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = self.bn(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "dummy_input = torch.rand(13, 1, 28, 28)\n",
    "\n",
    "model = Net1()\n",
    "# with 语句，可以避免因w.close未写造成的问题\n",
    "with SummaryWriter(log_dir='tensorboard_log/graph', comment='Net1') as w:\n",
    "    w.add_graph(model, (dummy_input,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## embedding 降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T08:18:41.570489Z",
     "start_time": "2018-12-05T08:18:36.852220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_value:0.6920217871665955\n",
      "loss_value:0.8206109404563904\n",
      "loss_value:0.5653269290924072\n",
      "loss_value:0.3914765417575836\n",
      "loss_value:0.4490695893764496\n",
      "loss_value:0.3116423487663269\n",
      "loss_value:0.2449614703655243\n",
      "loss_value:0.16987621784210205\n",
      "loss_value:0.11793910712003708\n",
      "loss_value:0.09033066779375076\n",
      "loss_value:0.1099458634853363\n",
      "loss_value:0.06549552828073502\n",
      "loss_value:0.07312457263469696\n",
      "loss_value:0.02840356156229973\n",
      "loss_value:0.027275869622826576\n",
      "loss_value:0.014830809086561203\n",
      "loss_value:0.0212051123380661\n",
      "loss_value:0.015640197321772575\n",
      "loss_value:0.019302107393741608\n",
      "loss_value:0.0127271618694067\n",
      "loss_value:0.006987855304032564\n",
      "loss_value:0.009496339596807957\n",
      "loss_value:0.013434902764856815\n",
      "loss_value:0.008479253388941288\n",
      "loss_value:0.006454657297581434\n",
      "loss_value:0.005604037083685398\n",
      "loss_value:0.008889805525541306\n",
      "loss_value:0.006641479674726725\n",
      "loss_value:0.006279394030570984\n",
      "loss_value:0.00678213220089674\n",
      "loss_value:0.006556646898388863\n",
      "loss_value:0.002577589126303792\n",
      "loss_value:0.005362409166991711\n",
      "loss_value:0.004429006949067116\n",
      "loss_value:0.005015226546674967\n",
      "loss_value:0.00717742508277297\n",
      "loss_value:0.0034603315871208906\n",
      "loss_value:0.004064172971993685\n",
      "loss_value:0.0036517754197120667\n",
      "loss_value:0.0045912801288068295\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from torch.autograd.variable import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# EMBEDDING VISUALIZATION FOR A TWO-CLASSES PROBLEM\n",
    "\n",
    "# just a bunch of layers\n",
    "\n",
    "\n",
    "class M(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(M, self).__init__()\n",
    "        self.cn1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3)\n",
    "        self.cn2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(in_features=128, out_features=2)\n",
    "\n",
    "    def forward(self, i):\n",
    "        i = self.cn1(i)\n",
    "        i = F.relu(i)\n",
    "        i = F.max_pool2d(i, 2)\n",
    "        i = self.cn2(i)\n",
    "        i = F.relu(i)\n",
    "        i = F.max_pool2d(i, 2)\n",
    "        i = i.view(len(i), -1)\n",
    "        i = self.fc1(i)\n",
    "        i = F.log_softmax(i, dim=1)\n",
    "        return i\n",
    "\n",
    "# get some random data around value\n",
    "\n",
    "\n",
    "def get_data(value, shape):\n",
    "    data = torch.ones(shape) * value\n",
    "    # add some noise\n",
    "    data += torch.randn(shape)**2\n",
    "    return data\n",
    "\n",
    "\n",
    "# dataset\n",
    "# cat some data with different values\n",
    "data = torch.cat(\n",
    "    (get_data(\n",
    "        0, (100, 1, 14, 14)), get_data(\n",
    "            0.5, (100, 1, 14, 14))), 0)\n",
    "# labels\n",
    "labels = torch.cat((torch.zeros(100), torch.ones(100)), 0)\n",
    "# generator\n",
    "gen = DataLoader(TensorDataset(data, labels), batch_size=25, shuffle=True)\n",
    "# network\n",
    "m = M()\n",
    "#loss and optim\n",
    "loss = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(params=m.parameters())\n",
    "# settings for train and log\n",
    "num_epochs = 20\n",
    "embedding_log = 5\n",
    "writer = SummaryWriter(log_dir='tensorboard_log/embedding', comment='mnist_embedding_training')\n",
    "\n",
    "# TRAIN\n",
    "for epoch in range(num_epochs):\n",
    "    for j, sample in enumerate(gen):\n",
    "        n_iter = (epoch * len(gen)) + j\n",
    "        # reset grad\n",
    "        m.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        # get batch data\n",
    "        data_batch = Variable(sample[0], requires_grad=True).float()\n",
    "        label_batch = Variable(sample[1], requires_grad=False).long()\n",
    "        # FORWARD\n",
    "        out = m(data_batch)\n",
    "        loss_value = loss(out, label_batch)\n",
    "        # BACKWARD\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        # LOGGING\n",
    "        writer.add_scalar('loss', loss_value.data.item(), n_iter)\n",
    "\n",
    "        if j % embedding_log == 0:\n",
    "            print(\"loss_value:{}\".format(loss_value.data.item()))\n",
    "            # we need 3 dimension for tensor to visualize it!\n",
    "            out = torch.cat((out.data, torch.ones(len(out), 1)), 1)\n",
    "            writer.add_embedding(\n",
    "                out,\n",
    "                metadata=label_batch.data,\n",
    "                label_img=data_batch.data,\n",
    "                global_step=n_iter)\n",
    "\n",
    "writer.close()\n",
    "\n",
    "# tensorboard --logdir runs\n",
    "# you should now see a dropdown list with all the timestep,\n",
    "# last timestep should have a visible separation between the two classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### multiple_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T08:19:00.046546Z",
     "start_time": "2018-12-05T08:18:57.481399Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "def main():\n",
    "    degrees = np.linspace(0, 3600 * math.pi / 180.0, 3600)\n",
    "    degrees = degrees.reshape(3600, 1)\n",
    "    labels = [\"%d\" % (i) for i in range(0, 3600)]\n",
    "\n",
    "    with SummaryWriter(log_dir='tensorboard_log/multiple_embedding', comment='multiple_embedding') as writer:\n",
    "        # Maybe make a bunch of data that's always shifted in some\n",
    "        # way, and that will be hard for PCA to turn into a sphere?\n",
    "\n",
    "        for epoch in range(0, 16):\n",
    "            shift = epoch * 2 * math.pi / 16.0\n",
    "            mat = np.concatenate([\n",
    "                np.sin(shift + degrees * 2 * math.pi / 180.0),\n",
    "                np.sin(shift + degrees * 3 * math.pi / 180.0),\n",
    "                np.sin(shift + degrees * 5 * math.pi / 180.0),\n",
    "                np.sin(shift + degrees * 7 * math.pi / 180.0),\n",
    "                np.sin(shift + degrees * 11 * math.pi / 180.0)\n",
    "            ], axis=1)\n",
    "            writer.add_embedding(\n",
    "                mat=mat,\n",
    "                metadata=labels,\n",
    "                tag=\"sin\",\n",
    "                global_step=epoch)\n",
    "\n",
    "            mat = np.concatenate([\n",
    "                np.cos(shift + degrees * 2 * math.pi / 180.0),\n",
    "                np.cos(shift + degrees * 3 * math.pi / 180.0),\n",
    "                np.cos(shift + degrees * 5 * math.pi / 180.0),\n",
    "                np.cos(shift + degrees * 7 * math.pi / 180.0),\n",
    "                np.cos(shift + degrees * 11 * math.pi / 180.0)\n",
    "            ], axis=1)\n",
    "            writer.add_embedding(\n",
    "                mat=mat,\n",
    "                metadata=labels,\n",
    "                tag=\"cos\",\n",
    "                global_step=epoch)\n",
    "\n",
    "            mat = np.concatenate([\n",
    "                np.tan(shift + degrees * 2 * math.pi / 180.0),\n",
    "                np.tan(shift + degrees * 3 * math.pi / 180.0),\n",
    "                np.tan(shift + degrees * 5 * math.pi / 180.0),\n",
    "                np.tan(shift + degrees * 7 * math.pi / 180.0),\n",
    "                np.tan(shift + degrees * 11 * math.pi / 180.0)\n",
    "            ], axis=1)\n",
    "            writer.add_embedding(\n",
    "                mat=mat,\n",
    "                metadata=labels,\n",
    "                tag=\"tan\",\n",
    "                global_step=epoch)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "main()\n",
    "\n",
    "# tensorboard --logdir runs\n",
    "# Under \"Projection, you should see\n",
    "#  48 tensor found named\n",
    "#     cos:cos-00000 to cos:cos-00016\n",
    "#     sin:sin-00000 to sin:sin-00016\n",
    "#     tan:tan-00000 to tan:tan-00016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T08:36:58.981258Z",
     "start_time": "2018-12-05T08:36:58.468228Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "c1 = plt.Circle((0.2, 0.5), 0.2, color='r')\n",
    "c2 = plt.Circle((0.8, 0.5), 0.2, color='r')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.add_patch(c1)\n",
    "ax.add_patch(c2)\n",
    "plt.axis('scaled')\n",
    "\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter(log_dir='tensorboard_log/matplotlib', comment='matplotlib_plt')\n",
    "writer.add_figure('matplotlib', fig)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## nvidia_smi GPU使用情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T08:41:34.273003Z",
     "start_time": "2018-12-05T08:41:32.996931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This demo needs nvidia-ml-py or nvidia-ml-py3\n"
     ]
    }
   ],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "import torch\n",
    "\n",
    "try:\n",
    "    import nvidia_smi\n",
    "    nvidia_smi.nvmlInit()\n",
    "    handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)  # gpu0\n",
    "except ImportError:\n",
    "    print('This demo needs nvidia-ml-py or nvidia-ml-py3')\n",
    "    exit()\n",
    "\n",
    "with SummaryWriter(log_dir='tensorboard_log/nvidia_smi', comment='nvidia_smi') as writer:\n",
    "    x = []\n",
    "    for n_iter in range(50):\n",
    "        x.append(torch.Tensor(1000, 1000).cuda())\n",
    "        res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)\n",
    "        writer.add_scalar('nv/gpu', res.gpu, n_iter)\n",
    "        res = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "        writer.add_scalar('nv/gpu_mem', res.used, n_iter)\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## image 图片\n",
    "- writer.add_image('Image', x, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## audio\n",
    "- writer.add_audio('myAudio', dummy_audio, n_iter, sample_rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## DISTRIBUTIONS和 HISTOGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name, param in resnet18.named_parameters():\n",
    "    writer.add_histogram(name, param.clone().cpu().data.numpy(), n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TEXT：\n",
    "- writer.add_text('Text', 'text logged at step:' + str(n_iter), n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PR CURVES:\n",
    "- needs tensorboard 0.4RC or later\n",
    "- writer.add_pr_curve('xoxo', np.random.randint(2, size=100), np.random.rand(100), n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

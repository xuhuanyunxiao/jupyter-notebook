{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 保监会 相关性模型 2 训练 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T07:34:13.038727Z",
     "start_time": "2018-08-30T07:34:11.635646Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##load packages, needed\n",
    "# encoding=utf-8\n",
    "\n",
    "import jieba\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2,mutual_info_classif,f_classif \n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from collections import defaultdict\n",
    "\n",
    "import joblib\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T07:34:13.069729Z",
     "start_time": "2018-08-30T07:34:13.043727Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StatsFeatures(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def getcnt(self,x):        \n",
    "        return len(list(set(x)))\n",
    "    \n",
    "    def transform(self, X):\n",
    "        data = []\n",
    "        for x in X:\n",
    "            if len(x) == 0:\n",
    "                length  = 1\n",
    "            else :\n",
    "                length = len(x)\n",
    "            data.append([len(x),self.getcnt(x),self.getcnt(x)/length])            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上一版模型读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T07:34:13.177735Z",
     "start_time": "2018-08-30T07:34:13.073729Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 上一版模型\n",
    "# from sklearn.externals import joblib\n",
    "# pipeline_old = joblib.load( \"model/circ_cor_0625.pkl.z\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T07:34:13.338744Z",
     "start_time": "2018-08-30T07:34:13.181735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5807\n"
     ]
    }
   ],
   "source": [
    "title = []\n",
    "filename = 'data/titles.txt'\n",
    "fid = open(filename, \"r+\", encoding='UTF-8')\n",
    "for f in fid:\n",
    "    title.append(f.strip().replace('\\n', ''))\n",
    "fid.close()\n",
    "print(len(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T07:34:14.023783Z",
     "start_time": "2018-08-30T07:34:13.344744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5807\n"
     ]
    }
   ],
   "source": [
    "content = []\n",
    "filename = 'data/contents.txt'\n",
    "fid = open(filename, \"r+\", encoding='UTF-8')\n",
    "for f in fid:\n",
    "    content.append(f.strip().replace('\\n', ''))\n",
    "fid.close()\n",
    "print(len(content))\n",
    "# content[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T07:34:14.063785Z",
     "start_time": "2018-08-30T07:34:14.029783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5807\n"
     ]
    }
   ],
   "source": [
    "title_content = [t + ' ' + c for t,c in zip(title, content)]\n",
    "print(len(title_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T07:34:14.156791Z",
     "start_time": "2018-08-30T07:34:14.067786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1', '1', '1', '1', '1']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = []\n",
    "filename = 'data/labels.txt'\n",
    "fid = open(filename, \"r+\", encoding='UTF-8')\n",
    "for f in fid:\n",
    "    label.append(f.strip().replace('\\n', ''))\n",
    "fid.close()\n",
    "print(len(label))\n",
    "label[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分割训练集、测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T07:34:14.294799Z",
     "start_time": "2018-08-30T07:34:14.162791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集： 4064\n",
      "训练集-各类数量： Counter({'0': 2067, '1': 1997})\n",
      "测试集： 1743\n",
      "测试集-各类数量： Counter({'1': 883, '0': 860})\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(title_content, label, test_size=0.3, random_state=42)\n",
    "print('训练集：',len(y_train))\n",
    "print('训练集-各类数量：',Counter(y_train))\n",
    "print('测试集：',len(y_test))\n",
    "print('测试集-各类数量：',Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T07:35:06.111762Z",
     "start_time": "2018-08-30T07:34:14.299799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9768700787401575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('tf_idf', Pipeline(memory=None,\n",
       "     steps=[('counts', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0...tate=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('tf_idf', Pipeline([\n",
    "            ('counts', CountVectorizer()),\n",
    "            ('tf_idf', TfidfTransformer()),\n",
    "            ('chi', SelectKBest(chi2, k=20000))\n",
    "        ])),\n",
    "        ('len_stats', StatsFeatures())\n",
    "    ])),\n",
    "    ('classifier', XGBClassifier(max_depth=7,objective='multi:softmax', num_class=2))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(pipeline.score(X_train, y_train))\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T07:35:07.056816Z",
     "start_time": "2018-08-30T07:35:06.116763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score:  0.861732644865175\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.89      0.86       860\n",
      "          1       0.88      0.84      0.86       883\n",
      "\n",
      "avg / total       0.86      0.86      0.86      1743\n",
      "\n",
      "confusion_matrix: \n",
      "[[764  96]\n",
      " [145 738]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_class = pipeline.predict(X_test)\n",
    "print('accuracy_score: ', metrics.accuracy_score(y_test, y_pred_class)) # 指所有分类正确的百分比\n",
    "print(metrics.classification_report(y_test, y_pred_class))\n",
    "print('confusion_matrix: ')\n",
    "print( metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T07:35:07.068817Z",
     "start_time": "2018-08-30T07:35:07.060817Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 上一版模型 \n",
    "# y_pred_class = pipeline_old.predict(X_test)\n",
    "# print('accuracy_score: ', metrics.accuracy_score(y_test, y_pred_class)) # 指所有分类正确的百分比\n",
    "# print(metrics.classification_report(y_test, y_pred_class))\n",
    "# print('confusion_matrix: ')\n",
    "# print( metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T01:46:54.962772Z",
     "start_time": "2018-08-28T01:46:54.746562Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "title_content = np.array(title_content)\n",
    "label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-28T01:54:46.490292Z",
     "start_time": "2018-08-28T01:46:55.979227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 1\n",
      "0.9741657696447793\n",
      "accuracy_score:  0.8898450946643718\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.90      0.89       597\n",
      "          1       0.89      0.88      0.89       565\n",
      "\n",
      "avg / total       0.89      0.89      0.89      1162\n",
      "\n",
      "confusion_matrix: \n",
      "[[537  60]\n",
      " [ 68 497]]\n",
      "---- 2\n",
      "0.976318622174381\n",
      "accuracy_score:  0.8623063683304647\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.88      0.86       575\n",
      "          1       0.88      0.84      0.86       587\n",
      "\n",
      "avg / total       0.86      0.86      0.86      1162\n",
      "\n",
      "confusion_matrix: \n",
      "[[508  67]\n",
      " [ 93 494]]\n",
      "---- 3\n",
      "0.9754627636676712\n",
      "accuracy_score:  0.8570198105081827\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.88      0.86       564\n",
      "          1       0.88      0.84      0.86       597\n",
      "\n",
      "avg / total       0.86      0.86      0.86      1161\n",
      "\n",
      "confusion_matrix: \n",
      "[[495  69]\n",
      " [ 97 500]]\n",
      "---- 4\n",
      "0.9776151528196297\n",
      "accuracy_score:  0.8725236864771748\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.90      0.88       599\n",
      "          1       0.89      0.84      0.86       562\n",
      "\n",
      "avg / total       0.87      0.87      0.87      1161\n",
      "\n",
      "confusion_matrix: \n",
      "[[539  60]\n",
      " [ 88 474]]\n",
      "---- 5\n",
      "0.9752475247524752\n",
      "accuracy_score:  0.8673557278208441\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.89      0.87       592\n",
      "          1       0.88      0.84      0.86       569\n",
      "\n",
      "avg / total       0.87      0.87      0.87      1161\n",
      "\n",
      "confusion_matrix: \n",
      "[[528  64]\n",
      " [ 90 479]]\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "for train_index , test_index in kf.split(title_content):\n",
    "    print('---- %s'%(num+1))\n",
    "    X_train,X_test = title_content[train_index], title_content[test_index]\n",
    "    y_train,y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('tf_idf', Pipeline([\n",
    "                ('counts', CountVectorizer(max_df=0.95, min_df=2)),\n",
    "                ('tf_idf', TfidfTransformer()),\n",
    "                ('chi', SelectKBest(chi2, k=20000))\n",
    "            ])),\n",
    "            ('len_stats', StatsFeatures())\n",
    "        ])),\n",
    "        ('standard', StandardScaler(with_mean=False)),\n",
    "        ('classifier', XGBClassifier(max_depth=7,objective='multi:softmax', num_class=8))\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print(pipeline.score(X_train, y_train))    \n",
    "    \n",
    "    y_pred_class = pipeline.predict(X_test)\n",
    "    print('accuracy_score: ', metrics.accuracy_score(y_test, y_pred_class)) # 指所有分类正确的百分比\n",
    "    print(metrics.classification_report(y_test, y_pred_class))\n",
    "    print('confusion_matrix: ')\n",
    "    print( metrics.confusion_matrix(y_test, y_pred_class))    \n",
    "    \n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T09:51:12.095774Z",
     "start_time": "2018-06-13T09:51:11.751754Z"
    },
    "collapsed": true
   },
   "source": [
    "# 模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-30T07:35:10.763028Z",
     "start_time": "2018-08-30T07:35:08.979926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/mfa_sen_0830.pkl.z']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(pipeline, \"model/mfa_sen_0830.pkl.z\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存本文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T06:53:13.560161Z",
     "start_time": "2018-07-03T06:53:13.537160Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    import datetime as dt\n",
    "    \n",
    "    def output_HTML(read_file, output_file):\n",
    "        from nbconvert import HTMLExporter\n",
    "        import codecs\n",
    "        import nbformat\n",
    "        exporter = HTMLExporter()\n",
    "        # read_file is '.ipynb', output_file is '.html'\n",
    "        output_notebook = nbformat.read(read_file, as_version=4)\n",
    "        output, resources = exporter.from_notebook_node(output_notebook)\n",
    "        codecs.open(output_file, 'w', encoding='utf-8').write(output)\n",
    "\n",
    "    html_file_folder = 'html_files'\n",
    "    if not os.path.exists(html_file_folder):\n",
    "        os.makedirs(html_file_folder)\n",
    "\n",
    "    today = dt.datetime.now().strftime('%Y%m%d')\n",
    "    current_file = 'circ_cor_model_2_train.ipynb'\n",
    "    output_file = 'html_files\\%s_%s.html'%(os.path.splitext(current_file)[0], today)\n",
    "    output_HTML(current_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

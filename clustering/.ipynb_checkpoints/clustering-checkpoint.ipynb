{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T07:52:29.605000Z",
     "start_time": "2019-04-03T07:52:28.201000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pre_cor\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from pandas.io import sql\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一些函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def clustering_metrics(labels_pred, labels_true = None, feature = None):\n",
    "    '''\n",
    "    聚类算法结果评估\n",
    "    需要真实标签：\n",
    "        兰德指数 ARI: 输入参数没有顺序要求，ARI值的范围是[-1,1]，\n",
    "            负的结果都是较差的，说明标签是独立分布的，相似分布的ARI结果是正的，\n",
    "            1是最佳结果，说明两种标签的分布完全一致\n",
    "        互信息 AMI：输入参数没有顺序要求，最好的值为1，最差的值（与labels_true不相关），其结果为非正值\n",
    "        同质性、完整性、两者的调和平均V-measure：从0到1反应出最差到最优的表现\n",
    "        Fowlkes-Mallows指数：针对训练集和验证集数据之间求得的查全率和查准率的几何平均值\n",
    "        \n",
    "    不需要真实标签：        \n",
    "        轮廓系数：取值范围是[-1,1]，同类别样本距离越相近不同类别样本距离越远，分数越高。\n",
    "        Calinski-Harabaz Index：分数值越大则聚类效果越好        \n",
    "    '''\n",
    "    \n",
    "    if labels_true is not None:\n",
    "        print u'兰德指数 ARI: ', metrics.adjusted_rand_score(labels_true, labels_pred)\n",
    "        print u'互信息 AMI: ', metrics.adjusted_mutual_info_score(labels_true, labels_pred)\n",
    "        print u'同质性、完整性、两者的调和平均V-measure: ', metrics.homogeneity_completeness_v_measure(labels_true, labels_pred)\n",
    "        print u'Fowlkes-Mallows指数 FMI: ', metrics.fowlkes_mallows_score(labels_true, labels_pred)\n",
    "        \n",
    "    if feature is not None:\n",
    "        print u'轮廓系数: ', metrics.silhouette_score(feature, labels_pred, metric='euclidean')\n",
    "        print u'Calinski-Harabaz Index: ', metrics.calinski_harabaz_score(feature, labels_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T10:01:46.406000Z",
     "start_time": "2019-04-02T10:01:44.478000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7396, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publishtime</th>\n",
       "      <th>site_name</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29064424</td>\n",
       "      <td>Serie A Roundup: Moise Kean keeps up scoring f...</td>\n",
       "      <td>2019-03-31 13:35:20</td>\n",
       "      <td>印度快报</td>\n",
       "      <td>Moise Kean can’t seem to miss lately. Days aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29102555</td>\n",
       "      <td>Motor racing-We will come back stronger, says ...</td>\n",
       "      <td>2019-04-01 04:45:23</td>\n",
       "      <td>每日邮报</td>\n",
       "      <td>MANAMA, March 31 (Reuters) - Charles Leclerc p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29087495</td>\n",
       "      <td>Two women reveal how tragedy made them 'really...</td>\n",
       "      <td>2019-04-01 00:15:39</td>\n",
       "      <td>每日邮报</td>\n",
       "      <td>Georgina Brown (pictured) was hit by tragedy w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29099506</td>\n",
       "      <td>Kevin Maher: I promise to cook more often than...</td>\n",
       "      <td>2019-04-01 07:01:00</td>\n",
       "      <td>泰晤士报</td>\n",
       "      <td>Young couples in love, what’s wrong with you? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29067200</td>\n",
       "      <td>Farewell to the Telegraph and its readers afte...</td>\n",
       "      <td>2019-03-31 15:00:00</td>\n",
       "      <td>每日电讯报</td>\n",
       "      <td>Farewell to the Telegraph and its readers afte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0  29064424  Serie A Roundup: Moise Kean keeps up scoring f...   \n",
       "1  29102555  Motor racing-We will come back stronger, says ...   \n",
       "2  29087495  Two women reveal how tragedy made them 'really...   \n",
       "3  29099506  Kevin Maher: I promise to cook more often than...   \n",
       "4  29067200  Farewell to the Telegraph and its readers afte...   \n",
       "\n",
       "          publishtime site_name  \\\n",
       "0 2019-03-31 13:35:20      印度快报   \n",
       "1 2019-04-01 04:45:23      每日邮报   \n",
       "2 2019-04-01 00:15:39      每日邮报   \n",
       "3 2019-04-01 07:01:00      泰晤士报   \n",
       "4 2019-03-31 15:00:00     每日电讯报   \n",
       "\n",
       "                                             content  \n",
       "0  Moise Kean can’t seem to miss lately. Days aft...  \n",
       "1  MANAMA, March 31 (Reuters) - Charles Leclerc p...  \n",
       "2  Georgina Brown (pictured) was hit by tragedy w...  \n",
       "3  Young couples in love, what’s wrong with you? ...  \n",
       "4  Farewell to the Telegraph and its readers afte...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_excel('news_data_20190401/news_data.xls')\n",
    "print(raw_data.shape)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T10:01:48.595000Z",
     "start_time": "2019-04-02T10:01:47.168000Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-02 18:01:48 16776 16196 textcleaner.py [line:37] INFO 'pattern' package not found; tag filters are not available for English\n",
      "2019-04-02 18:09:33 16776 16196 nltk_multipro_new.py [line:170] INFO start cut_tasks ....\n",
      "2019-04-02 18:09:33 16776 16196 nltk_multipro_new.py [line:181] INFO end cut_tasks ...., 0s\n",
      "2019-04-02 18:09:33 16776 16196 nltk_multipro_new.py [line:223] INFO start multi_process ....\n",
      "2019-04-02 18:11:51 16776 16196 nltk_multipro_new.py [line:238] INFO end multi_process ...., 138s\n",
      "2019-04-02 18:11:51 16776 16196 hierarchical_cluster.py [line:326] INFO first_cut_results end....\n",
      "2019-04-02 18:11:52 16776 16196 hierarchical_cluster.py [line:336] INFO first_tfidf_matrix end....\n",
      "2019-04-02 18:27:57 16776 16196 hierarchical_cluster.py [line:341] INFO first_cluster_results end....\n",
      "2019-04-02 18:27:57 16776 16196 nltk_multipro_new.py [line:170] INFO start cut_tasks ....\n",
      "2019-04-02 18:27:57 16776 16196 nltk_multipro_new.py [line:181] INFO end cut_tasks ...., 0s\n",
      "2019-04-02 18:27:57 16776 16196 nltk_multipro_new.py [line:223] INFO start multi_process ....\n",
      "2019-04-02 18:28:13 16776 16196 nltk_multipro_new.py [line:238] INFO end multi_process ...., 15s\n",
      "2019-04-02 18:28:13 16776 16196 hierarchical_cluster.py [line:358] INFO second_cut_results end....\n",
      "2019-04-02 18:30:51 16776 16196 hierarchical_cluster.py [line:372] INFO second_tf_matrix end....\n",
      "2019-04-02 18:33:43 16776 16196 hierarchical_cluster.py [line:376] INFO second_cluster_results end....\n",
      "2019-04-02 18:33:44 16776 16196 hierarchical_cluster.py [line:393] INFO cluster_results....\n"
     ]
    }
   ],
   "source": [
    "from dao.mysql.base_data_view import BaseDataView\n",
    "\n",
    "import hierarchical_cluster\n",
    "'''\n",
    "perform_cluster(is_manual, cluster_type, manual_id, subtopic_id, language_type,\n",
    "                    corpus, min_sample, save_group_id)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T10:02:20.214000Z",
     "start_time": "2019-04-02T10:01:48.656000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_manual = 0\n",
    "cluster_type = 0\n",
    "manual_id = 0\n",
    "subtopic_id = 0\n",
    "language_type = 1\n",
    "min_sample = 1\n",
    "save_group_id = 5\n",
    "\n",
    "base_data_view = BaseDataView()\n",
    "dict_data = raw_data.to_dict('records')\n",
    "corpus = BaseDataView.parse_corpus_records(dict_data, language_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T01:44:17.219000Z",
     "start_time": "2019-04-03T01:44:17.211000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7302"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print raw_data.shape\n",
    "len(corpus)\n",
    "# corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T10:33:47.692000Z",
     "start_time": "2019-04-02T10:09:33.564000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_results = hierarchical_cluster.perform_cluster(is_manual, cluster_type, manual_id, \n",
    "                                                       subtopic_id, language_type,corpus, \n",
    "                                                       min_sample, save_group_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T01:14:33.221000Z",
     "start_time": "2019-04-03T01:14:33.211000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<entity.cluster_result.MergerClusterResult at 0x301a9748>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cluster_results)\n",
    "cluster_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save baseline result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T01:45:30.917000Z",
     "start_time": "2019-04-03T01:45:30.875000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['29077036',\n",
       " u\"Warren: Decision on 2020 up to Biden after woman's claim(accuser/biden/warren)\",\n",
       " '0_3085',\n",
       " u'Ex-U.S. Vice President Biden denies inappropriate conduct over alleged kiss(biden/joe/woman/kiss/act/inappropriate)',\n",
       " 3085,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " '29077036^A29076426^A29054671^A29103572^A29089361^A29082773^A29086886^A29084555^A29081648^A29087088^A29086922^A29087906^A29089186^A29099413^A29103568^A29084836^A29099059^A29092063^A29083362^A29085250^A29071826^A29100379^A29101552^A29085788^A29100658^A29085775^A29091997^A29081865^A29094944^A29121113^A29081501^A29090051^A29103137^A29117505^A29090770^A29080284^A29081512^A29098701^A29082701^A29083242^A29082429^A29086277^A29084773^A29080298^A29080912^A29066161^A29093998^A29090846^A29086676^A29094440^A29101521^A29092325^A29087122^A29090847^A29094774^A29085927^A29084956^A29090062^A29096712^A29088431^A29093997^A29081605^A29081375^A29085011',\n",
       " 64]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_result = []\n",
    "\n",
    "for fir_cluster_ind, merger_cluster_result in enumerate(cluster_results):\n",
    "    fir_topic = merger_cluster_result.topic\n",
    "    fir_member = merger_cluster_result.member\n",
    "    fir_member_count = merger_cluster_result.member_count\n",
    "    for sub_cluster_result in merger_cluster_result.sub_cluster_results:\n",
    "        member_list = sub_cluster_result.member.split('^A')\n",
    "        topic = sub_cluster_result.topic        \n",
    "        member_count = sub_cluster_result.member_count\n",
    "        site_count = sub_cluster_result.site_count\n",
    "        cluster_id = sub_cluster_result.cluster_id\n",
    "        c_id = str(fir_cluster_ind) + '_' + str(cluster_id)\n",
    "        for member in member_list:\n",
    "            baseline_result.append([member, topic, c_id, fir_topic, cluster_id, fir_cluster_ind, \n",
    "                                    member_count, site_count, fir_member, fir_member_count])\n",
    "        \n",
    "baseline_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T01:47:14.853000Z",
     "start_time": "2019-04-03T01:47:10.721000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7302, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = '''member, topic, c_id, fir_topic, cluster_id, fir_cluster_ind, member_count, site_count, fir_member, fir_member_count'''\n",
    "baseline_result = pd.DataFrame(baseline_result, columns = col.split(', '))\n",
    "baseline_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T01:54:02.199000Z",
     "start_time": "2019-04-03T01:54:01.417000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data['id'] = raw_data['id'].astype(str)\n",
    "baseline_result = pd.merge(baseline_result, raw_data, how = 'left', left_on = 'member', right_on = 'id')\n",
    "baseline_result.shape\n",
    "# baseline_result.head()\n",
    "# baseline_result.to_csv('baseline_result_0403.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T02:12:41.961000Z",
     "start_time": "2019-04-03T02:12:33.714000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xlsxwriter\n",
    "bb = pd.ExcelWriter('baseline_result_0403.xlsx',engine='xlsxwriter')\n",
    "baseline_result.to_excel(bb, sheet_name='Sheet1')\n",
    "bb.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T02:33:19.457000Z",
     "start_time": "2019-04-03T02:33:19.362000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7302, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data = baseline_result[['id', 'title', 'content']]\n",
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T06:34:59.479000Z",
     "start_time": "2019-04-03T06:34:59.461000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29077036</td>\n",
       "      <td>Event organizer: Biden, accuser were never alo...</td>\n",
       "      <td>\\nThe organizer of a Nevada campaign rally sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29076426</td>\n",
       "      <td>Warren and Castro back Biden accuser – but don...</td>\n",
       "      <td>Lucy Flores says then-VP kissed her at 2014 Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29054671</td>\n",
       "      <td>Warren: Decision on 2020 up to Biden after wom...</td>\n",
       "      <td>Some Democratic presidential candidates are ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29103572</td>\n",
       "      <td>Flores: Interaction with Biden 'a violation of...</td>\n",
       "      <td>Lucy Flores, a former Nevada state assemblyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29089361</td>\n",
       "      <td>Bernie Sanders: 'No Reason' To Doubt Lucy Flor...</td>\n",
       "      <td>By  Benjamin Fearnow  On 3/31/19 at 1:33 PM ED...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                              title  \\\n",
       "0  29077036  Event organizer: Biden, accuser were never alo...   \n",
       "1  29076426  Warren and Castro back Biden accuser 鈥�but don...   \n",
       "2  29054671  Warren: Decision on 2020 up to Biden after wom...   \n",
       "3  29103572  Flores: Interaction with Biden 'a violation of...   \n",
       "4  29089361  Bernie Sanders: 'No Reason' To Doubt Lucy Flor...   \n",
       "\n",
       "                                             content  \n",
       "0   \\nThe organizer of聽a聽Nevada聽campaign rally sa...  \n",
       "1  Lucy Flores says then-VP kissed her at 2014 Ne...  \n",
       "2  Some Democratic presidential candidates are ex...  \n",
       "3    Lucy Flores, a former Nevada state assemblyw...  \n",
       "4  By  Benjamin Fearnow  On 3/31/19 at 1:33 PM ED...  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T03:07:00.707000Z",
     "start_time": "2019-04-03T03:07:00.696000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import digits\n",
    "import re\n",
    "\n",
    "stopwords = {}\n",
    "stw = open(\"corpus/stopwords.txt\")\n",
    "for ws in stw:\n",
    "    ws = ws.replace(\"\\n\", \"\")\n",
    "    ws = ws.replace(\"\\r\", \"\")\n",
    "    stopwords[ws] = 1\n",
    "stw.close()\n",
    "\n",
    "# stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T09:16:16.278000Z",
     "start_time": "2019-04-03T09:16:16.128000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_content(content):\n",
    "    content = str(content)\n",
    "    raw = content.strip()\n",
    "    line = \"\"\n",
    "    if raw != \"\":       \n",
    "        # 1 清理字符串\n",
    "        content = clean_sent(content)\n",
    "#         print '--------------  content: ', content\n",
    "\n",
    "        # 2 分句\n",
    "        sent_tokenize_list = nltk.sent_tokenize(content)\n",
    "#         print '--------------  sent_tokenize_list: ', sent_tokenize_list\n",
    "        \n",
    "        # 3 清理句子\n",
    "        clean_sent_list = [clean_sent(sent) for sent in sent_tokenize_list]\n",
    "#         print '--------------  clean_sent_list: ', clean_sent_list\n",
    "        \n",
    "        # 4 分词 \n",
    "        # 去掉长度小于3、去掉数字、去掉标点符号/去掉 non-alpha 词\n",
    "        word_tokenize_list = []\n",
    "        for sent in clean_sent_list:\n",
    "            word_t_l = filter(lambda x: len(x) > 2, map(clean_word, nltk.word_tokenize(sent)))\n",
    "            word_tokenize_list += list(word_t_l)\n",
    "            \n",
    "#         print '--------------  word_tokenize_list: ', word_tokenize_list\n",
    "        \n",
    "        # 5 清理词\n",
    "        # 去掉停用词、，小写化\n",
    "        word_list = [word.lower() for word in word_tokenize_list if word.lower() not in stopwords]\n",
    "#         print '--------------  word_list: ', word_list\n",
    "        \n",
    "        # 6 词形还原\n",
    "        wnl = WordNetLemmatizer()\n",
    "        word_list = [wnl.lemmatize(word) for word in word_list]\n",
    "#         print '--------------  WordNetLemmatizer  word_list: ', word_list\n",
    "\n",
    "        line = \" \".join(word_list)\n",
    "    return line\n",
    "\n",
    "def remove_special_symbol(sentence):\n",
    "    '''去除特殊符号'''\n",
    "    normal_symbol_en = \",.!;:?''\"\"<>()%+#· \"\n",
    "    normal_symbol_ch = \"，。！；：“”‘’？《》（）%+、…【】\"\n",
    "    normal_symbol = normal_symbol_en + normal_symbol_ch\n",
    "    regex = re.compile(u\"[a-zA-Z0-9]\")\n",
    "    removed_sent = ''\n",
    "    special_symbol = set()\n",
    "    for s in sentence:\n",
    "        if regex.match(s): \n",
    "            removed_sent += s\n",
    "        elif s in normal_symbol: \n",
    "            removed_sent += s\n",
    "        else :\n",
    "            special_symbol.add(s)\n",
    "#     print 'special_symbol: %s'%special_symbol\n",
    "    return removed_sent\n",
    "\n",
    "def clean_sent(sent):\n",
    "    # 去网页中的特殊编码字符串\n",
    "    sent = \" \".join(sent.split())\n",
    "    word_list = []\n",
    "    for word in sent.split():\n",
    "        try :\n",
    "            word_code = word.encode('raw_unicode_escape').decode('utf-8', \"ignore\")\n",
    "            if \"\\\\u\" in word_code:\n",
    "                if len(word_code) >= (word_code.index('\\\\u') +6):\n",
    "                    w = word_code[word_code.index('\\\\u'): word_code.index('\\\\u') +6]\n",
    "                else :\n",
    "                    w = word_code[word_code.index('\\\\u'): ]\n",
    "                word_code = word_code.replace(w, ' ')\n",
    "            word_list.append(word_code) \n",
    "        except :\n",
    "            print '---', s\n",
    "            \n",
    "    sent = \" \".join(word_list)\n",
    "            \n",
    "    sent = sent.replace(\"\\n\", \" \").replace('\\r',' ').replace('\\r\\n',' ').replace('\\t', ' ')\n",
    "    reobj = re.compile('//@(.*?)[:\\s]')\n",
    "    sent = reobj.sub(\"\", sent)\n",
    "    reobj = re.compile(\"@(.*?)[:\\s]\")\n",
    "    sent = reobj.sub(\"\", sent)\n",
    "    reobj = re.compile(r\"\\[[^\\[\\]]*?\\]\")\n",
    "    sent = reobj.sub(\"\", sent)\n",
    "\n",
    "    sent = sent.replace(\"，\", \",\")\n",
    "    sent = sent.replace(\"。\", \".\")\n",
    "    sent = sent.replace(\"！\", \"!\")\n",
    "    sent = sent.replace(\"？\", \"?\")\n",
    "    reobj = re.compile(\"//(.*?)[:\\s]\")\n",
    "    sent = reobj.sub(\"\", sent)\n",
    "    \n",
    "    \n",
    "    removed_sent = remove_special_symbol(sent)\n",
    "    return sent\n",
    "\n",
    "def clean_word(s):  \n",
    "    # 去除标点和特殊字符、数字、汉字\n",
    "    regex = re.compile(r\"[^a-zA-Z]\")\n",
    "    s = regex.sub('', s)\n",
    "    \n",
    "    # 去除字符串中的数字 s = 'abc123def456ghi789zero0'\n",
    "#     remove_digits = str.maketrans('', '', digits)\n",
    "#     res = s.translate(remove_digits)\n",
    "    res = s\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T09:32:09.137000Z",
     "start_time": "2019-04-03T09:32:09.117000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime\n",
    "from multiprocessing.pool import ThreadPool as Pool\n",
    "\n",
    "def multi_process(func_name, func, param):\n",
    "    '''\n",
    "    多线程处理\n",
    "    '''\n",
    "    if 'win' in sys.platform:\n",
    "        njobs = 3 # 一半\n",
    "    elif 'linux' in sys.platform:\n",
    "        njobs = 6\n",
    "    \n",
    "    t1 = datetime.now()\n",
    "#     logger.info('starting func: %s. num: %s'%(func_name, len(param)))\n",
    "    print 'starting func: %s. njobs: %s, num: %s'%(func_name, njobs, len(param))\n",
    "    p = Pool(processes = njobs) # 创建5条进程\n",
    "    result = p.map(func,param)\n",
    "    p.close() # 关闭进程池，不再接受请求\n",
    "    p.join() # 等待所有的子进程结束\n",
    "    \n",
    "    result_list = [re for re in result]\n",
    "    \n",
    "    t2 = datetime.now()\n",
    "    elapsed_time = '%0.2f'%((t2 - t1).seconds)\n",
    "#     logger.info('end func: %s. elapsed_time: %s, num_sent: %s'%(func_name, elapsed_time, \n",
    "#                                                                 len(result_list)))\n",
    "    print 'end func: %s. elapsed_time: %s, num_sent: %s'%(func_name, elapsed_time, len(result_list))\n",
    "    return result_list\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T09:36:37.832000Z",
     "start_time": "2019-04-03T09:32:42.567000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7302"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lines = multi_process('handle_content', handle_content, filtered_data['content'].tolist())\n",
    "# len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T10:08:44.358000Z",
     "start_time": "2019-04-03T10:08:44.350000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_contents(l_contents):\n",
    "    lines = multi_process('handle_content', handle_content, l_contents)\n",
    "#     lines = []\n",
    "#     for line in l_contents:\n",
    "#         lines.append(handle_content(line))\n",
    "    return lines    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T10:08:51.854000Z",
     "start_time": "2019-04-03T10:08:45.817000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7302"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_title = handle_contents(filtered_data['title'].tolist())\n",
    "len(clean_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T10:12:56.403000Z",
     "start_time": "2019-04-03T10:09:07.410000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7302"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_content = handle_contents(filtered_data['content'].tolist())\n",
    "len(clean_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T10:12:59.900000Z",
     "start_time": "2019-04-03T10:12:59.894000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'organizer ofanevadacampaign rally late saturday biden joseph robinette biden politician accuses biden inappropriate contact poll american ocasiocortez democrat hill report trump raise stake threat close mexican border assemblywoman accused vice president inappropriate contact event reviewed photographic documentation event spoken principle attendance staff event recollection time lucy flores vice president biden henry munoz cofounder latino victory project statement advertisement flores friday accused biden expected presidential campaign coming week inappropriately touching atthe rally running nevada lieutenant governor flores wrote biden hand shoulder leaned smell hair kissed head stood stage campaign event brain couldn process happening embarrassed shocked confused wrote flores experienced blatantly inappropriate unnerving munoz statement biden hisown holding event flores waited andorganization leader advance staff campaign staff moment vice president candidate onstage address supporter press stage left surrounded security medical production staff munoz lucy friend friend latino victory supported political career firmly woman supported heard reckoning culture overdue vice president biden close friend degree presided marriage individual love respect time leader organization cofounded attendance circumstance support allegation event spokesman biden told hillon friday vice president staff recalled event flores butadded biden belief share recollection elizabeth warren elizabeth warren money mcmahon step business administrator trump defends reversing north korea sanction white house tout progress china trade talk inslee release return hillicon valley ncta huawei lash loser attitude koch attack warren plan tech crackdown bipartisan push surveillance program warren gender front center fundraising campaign mass housing urban development secretary julin castro democratic presidential candidate saturday flores'"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_content[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T10:15:23.850000Z",
     "start_time": "2019-04-03T10:15:23.845000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T10:28:36.241000Z",
     "start_time": "2019-04-03T10:28:29.719000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tf_matrix = vectorizer.fit_transform(clean_content).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T10:30:24.448000Z",
     "start_time": "2019-04-03T10:30:23.510000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7302L, 79291L)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T10:32:31.494000Z",
     "start_time": "2019-04-03T10:32:27.289000Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-03T10:32:44.646Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "pca = PCA(n_components=n, copy=False)\n",
    "tf_matrix = pca.fit_transform(tf_matrix)\n",
    "tf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### feature agglomeration\n",
    "- feature agglomeration with Ward hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "agglo = cluster.FeatureAgglomeration(n_clusters=n)\n",
    "tf_matrix = agglo.fit_transform(tf_matrix)\n",
    "tf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix = tf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## scipy hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "def hierarchy_cluster(tfidf_matrix, t):\n",
    "\n",
    "    # 1. 层次聚类\n",
    "    # 生成点与点之间的距离矩阵,这里用的cos距离\n",
    "    disMat = sch.distance.pdist(tfidf_matrix, 'cosine')\n",
    "\n",
    "    # 进行层次聚类:\n",
    "    # Z = sch.linkage(disMat)\n",
    "    Z = sch.linkage(disMat, method='average')\n",
    "\n",
    "    # 将层级聚类结果以树状图表示出来并保存为plot_dendrogram.png\n",
    "    # P=sch.dendrogram(Z)\n",
    "    # plt.savefig('plot_dendrogram.png')\n",
    "\n",
    "    # 根据linkage matrix Z得到聚类结果:\n",
    "    labels = sch.fcluster(Z, t=t, criterion='distance')\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = hierarchy_cluster(feature_matrix, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustering_metrics(labels, labels_true = None, feature = feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## sklearn BIRCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brc = cluster.Birch(branching_factor=50, n_clusters=None, threshold=0.5,compute_labels=True)\n",
    "labels = brc.fit_predict(feature_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustering_metrics(labels, labels_true = None, feature = feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustering = cluster.DBSCAN(eps=3, min_samples=2).fit(feature_matrix)\n",
    "labels = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustering_metrics(labels, labels_true = None, feature = feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn mean-shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustering = cluster.MeanShift(bandwidth=2).fit(feature_matrix)\n",
    "labels = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustering_metrics(labels, labels_true = None, feature = feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustering = AffinityPropagation().fit(feature_matrix)\n",
    "labels = clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustering_metrics(labels, labels_true = None, feature = feature_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "265px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

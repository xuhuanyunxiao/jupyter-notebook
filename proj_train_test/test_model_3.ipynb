{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本文件说明\n",
    "- 数据库里导出数据，本地模型、线上模型测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:03.894242Z",
     "start_time": "2018-12-04T01:36:02.487161Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import requests,json\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:07.134427Z",
     "start_time": "2018-12-04T01:36:03.897242Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.927 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "from toolkits.setup.date_time import get_day_list\n",
    "from toolkits.setup import specific_func\n",
    "\n",
    "from toolkits.nlp import pre_cor_circ\n",
    "from toolkits.nlp import pre_cor_cbrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 一些函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:07.153428Z",
     "start_time": "2018-12-04T01:36:07.137427Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_server_res_yjh(data, url, col_name):\n",
    "    '''\n",
    "    服务器接口测试程序\n",
    "    传入 dict, 传出 DataFrame\n",
    "    '''\n",
    "    # data = {'record':[{'id':0,'title':'ss','content':'zzz'},]}\n",
    "    # data = {\"record\":marked_human_data.iloc[:5,:3].to_dict(orient = 'records')}\n",
    "    # url \"http://47.93.77.19:10000/correlation_negative\"\n",
    "    headers={'content-type':'application/json'}\n",
    "    result = requests.post(url,\n",
    "                      data = json.dumps(data),\n",
    "                      headers=headers, allow_redirects=True)\n",
    "    # print(result.text)\n",
    "    json_data = json.loads(result.text)\n",
    "    parse_data = []\n",
    "    elapsed_time = json_data['elapsed_time']\n",
    "    for i in range(len(json_data['docs'])):\n",
    "        parse_data.append([json_data['docs'][i]['id'],\n",
    "                          json_data['docs'][i][col_name]])\n",
    "    parse_data = pd.DataFrame(parse_data, columns = ['id', col_name])    \n",
    "    return parse_data , elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:07.280435Z",
     "start_time": "2018-12-04T01:36:07.158428Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_serve_data_yjh(day_list, sql_one_day, url, col_name, save_filename):    \n",
    "    chunksize = 1000\n",
    "    for day_select in day_list:\n",
    "        print('-- day_select: ', day_select)\n",
    "        mysql_data = pd.read_sql(eval(sql_one_day), engine, chunksize= chunksize)\n",
    "        num = 1\n",
    "        combined_data = pd.DataFrame()\n",
    "        for tmp_data in mysql_data:  \n",
    "            print('---- loop num: ', num, 'tmp_data: ', tmp_data.shape)\n",
    "            data = {\"record\":tmp_data.loc[:,['id', 'title' ,'content']].to_dict(orient = 'records')}\n",
    "            parse_data = get_server_res_yjh(data, url, col_name)\n",
    "\n",
    "            parse_data.columns = ['id', 'predict_label']\n",
    "            \n",
    "            parse_data['label'] = ''\n",
    "            combined_tmp = pd.merge(parse_data, tmp_data, on = 'id', how = 'inner')\n",
    "            combined_data = pd.concat([combined_tmp, combined_data])\n",
    "\n",
    "        combined_data['predict_label'] = combined_data['predict_label'].apply(lambda x:class_name_dict[x])\n",
    "        combined_data['group_id'] = combined_data['group_id'].apply(lambda x:group_dict[str(x)])\n",
    "        combined_data.to_excel(eval(save_filename), index = False)\n",
    "        print(combined_data['predict_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:07.439445Z",
     "start_time": "2018-12-04T01:36:07.283436Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_server_res(data, url, col_name):\n",
    "    '''\n",
    "    服务器接口测试程序\n",
    "    传入 dict, 传出 DataFrame\n",
    "    '''\n",
    "    # data = {'record':[{'id':0,'title':'ss','content':'zzz'},]}\n",
    "    # data = {\"record\":marked_human_data.iloc[:5,:3].to_dict(orient = 'records')}\n",
    "    # url \"http://47.93.77.19:10000/correlation_negative\"\n",
    "    headers={'content-type':'application/json'}\n",
    "    result = requests.post(url,\n",
    "                      data = json.dumps(data),\n",
    "                      headers=headers, allow_redirects=True)\n",
    "    # print(result.text)\n",
    "    json_data = json.loads(result.text)\n",
    "    parse_data = []\n",
    "    elapsed_time = json_data['elapsed_time']\n",
    "    for i in range(len(json_data['docs'])):\n",
    "        parse_data.append([json_data['docs'][i]['id'],\n",
    "                          json_data['docs'][i][col_name]])\n",
    "    parse_data = pd.DataFrame(parse_data, columns = ['id', col_name])    \n",
    "    return parse_data, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:07.563452Z",
     "start_time": "2018-12-04T01:36:07.445445Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_serve_data(day_list, sql_one_day, url, col_name):\n",
    "    combined_data = pd.DataFrame()\n",
    "    for day_select in day_list:\n",
    "        print('-- day_select: ', day_select)\n",
    "        mysql_data = pd.read_sql(eval(sql_one_day), engine)\n",
    "        print('去空值前：', mysql_data.shape)\n",
    "        mysql_data = mysql_data.drop_duplicates(subset = ['title', 'content'])\n",
    "        print('去空值后：', mysql_data.shape)\n",
    "        data = {\"record\":mysql_data.loc[:,['id', 'title' ,'content']].to_dict(orient = 'records')}\n",
    "        \n",
    "        parse_data, elapsed_time = get_server_res(data, url)\n",
    "        print('elapsed_time: ', elapsed_time)\n",
    "        \n",
    "        parse_data.columns = ['id', 'predict_label']\n",
    "        parse_data['predict_label'] = parse_data['predict_label'].apply(lambda x:class_name_dict[x])\n",
    "        parse_data['label'] = ''\n",
    "        combined_cor = pd.merge(parse_data, mysql_data, on = 'id', how = 'inner')\n",
    "        combined_data = pd.concat([combined_data, combined_cor], axis = 0)\n",
    "\n",
    "        print(combined_cor['predict_label'].value_counts())\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:07.710460Z",
     "start_time": "2018-12-04T01:36:07.567452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '补录',\n",
       " 1: '监管',\n",
       " 2: '行业',\n",
       " 3: '产品销售',\n",
       " 4: '资本市场',\n",
       " 5: '公司内部管理',\n",
       " 6: '消费服务',\n",
       " 7: '其他相关报道',\n",
       " 8: '噪音',\n",
       " 9: '交通',\n",
       " 10: '环保'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dic={'补录':0,'监管':1,'行业':2,'产品销售':3,'资本市场':4,'公司内部管理':5,\n",
    "           '消费服务':6,'其他相关报道':7,'噪音':8,'交通':9,'环保':10}\n",
    "class_name_dict = {v: k for k, v in label_dic.items()}\n",
    "class_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:07.860469Z",
     "start_time": "2018-12-04T01:36:07.714460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': '新闻',\n",
       " '11': '微信',\n",
       " '13': '新闻客户端',\n",
       " '15': '推特',\n",
       " '2': '论坛',\n",
       " '3': '博客',\n",
       " '4': '微博',\n",
       " '5': '纸媒',\n",
       " '6': '视频',\n",
       " '7': '外媒',\n",
       " '8': '广播',\n",
       " '9': '电视'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = '1-新闻，2-论坛，3-博客，4-微博，5-纸媒，6-视频，7-外媒，8-广播，9-电视，11-微信，13-新闻客户端，15-推特'\n",
    "group_dict = dict([x.split('-') for x in group.split('，')])\n",
    "group_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:08.060480Z",
     "start_time": "2018-12-04T01:36:07.868469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '银监会', 2: '保监会', 3: '中国人寿', 4: '建行北分', 5: '中国人保'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_dic={'银监会':1,'保监会':2,'中国人寿':3,'建行北分':4,'中国人保':5}\n",
    "proj_name_dict = {v: k for k, v in proj_dic.items()}\n",
    "proj_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:08.202488Z",
     "start_time": "2018-12-04T01:36:08.066480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '系统采集', 1: '补录', 2: '校正', 3: '导入数据', 4: '其它'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gather_type_dic={'系统采集':0,'补录':1,'校正':2,'导入数据':3,'其它':4}\n",
    "gather_type_name_dict = {v: k for k, v in gather_type_dic.items()}\n",
    "gather_type_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:08.460503Z",
     "start_time": "2018-12-04T01:36:08.208488Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = 'cbirc_result\\pom.json'\n",
    "\n",
    "with open(file_path,'r',encoding='utf-8-sig') as json_file:\n",
    "    cbrc_data = json.load(json_file)  \n",
    "    \n",
    "# cbrc_data = pd.DataFrame.from_dict(json_data['record'], orient='index' ) \n",
    "# cbrc_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:08.557508Z",
     "start_time": "2018-12-04T01:36:08.464503Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from langconv import *\n",
    "from toolkits.nlp.langconv import *\n",
    "\n",
    "def Traditional2Simplified(sentence):\n",
    "    '''\n",
    "    将sentence中的繁体字转为简体字\n",
    "    :param sentence: 待转换的句子\n",
    "    :return: 将句子中繁体字转换为简体字之后的句子\n",
    "    '''\n",
    "    sentence = Converter('zh-hans').convert(sentence)\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:08.995534Z",
     "start_time": "2018-12-04T01:36:08.562509Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-62e54cc4f3d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# url = \"http://47.93.77.19:6001/judge_correlation_yjh\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m data = {\"record\":[{'id':'1', \n\u001b[1;32m----> 5\u001b[1;33m                    \u001b[1;34m'title'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTraditional2Simplified\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'record'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                    'content': Traditional2Simplified(data['record'][0]['content'])},]}\n\u001b[0;32m      7\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"http://192.168.0.104:8100/judge_correlation_yjh\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "index = 481\n",
    "# data = {\"record\":[cbrc_data['record'][index],]}\n",
    "# url = \"http://47.93.77.19:6001/judge_correlation_yjh\"\n",
    "data = {\"record\":[{'id':'1', \n",
    "                   'title': Traditional2Simplified(data['record'][0]['title']),  \n",
    "                   'content': Traditional2Simplified(data['record'][0]['content'])},]}\n",
    "url = \"http://192.168.0.104:8100/judge_correlation_yjh\"\n",
    "col_name = 'sec'\n",
    "\n",
    "parse_data , elapsed_time = get_server_res_yjh(data, url, col_name)\n",
    "print(index, '  耗时：%s s'%(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:08.996534Z",
     "start_time": "2018-12-04T01:36:02.609Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['record'][0]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:08.998534Z",
     "start_time": "2018-12-04T01:36:02.616Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{\"record\":[cbrc_data['record'][152:155],]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:09.000534Z",
     "start_time": "2018-12-04T01:36:02.622Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{\"record\":[cbrc_data['record'][154],]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:09.002534Z",
     "start_time": "2018-12-04T01:36:02.633Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = {\"record\":combined_data.loc[:,['id', 'title' ,'content']].to_dict(orient = 'records')}\n",
    "import time\n",
    "for index in range(len(cbrc_data['record'])):\n",
    "#     data = {\"record\":[cbrc_data['record'][index],]}\n",
    "#     url = \"http://47.93.77.19:6001/judge_correlation_yjh\"\n",
    "    data = {\"record\":[{'id':cbrc_data['record'][index]['id'], \n",
    "                       'title': Traditional2Simplified(cbrc_data['record'][index]['title']),  \n",
    "                       'content': Traditional2Simplified(cbrc_data['record'][index]['content'])},]}\n",
    "    url = \"http://192.168.0.104:8100/judge_correlation_yjh\"\n",
    "    col_name = 'sec'\n",
    "    \n",
    "    parse_data , elapsed_time = get_server_res_yjh(data, url, col_name)\n",
    "    print(index, '  耗时：%s s'%(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:09.007534Z",
     "start_time": "2018-12-04T01:36:02.640Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "for index in range(len(cbrc_data['record'])):\n",
    "    data = {\"record\":[cbrc_data['record'][index],]}\n",
    "#     url = \"http://47.93.77.19:6001/judge_correlation_yjh\"\n",
    "    url = \"http://192.168.0.104:8100/judge_correlation_yjh\"\n",
    "    col_name = 'sec'\n",
    "    \n",
    "    parse_data , elapsed_time = get_server_res_yjh(data, url, col_name)\n",
    "    print(index, '  耗时：%s s'%(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:09.010534Z",
     "start_time": "2018-12-04T01:36:02.646Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {\"record\":cbrc_data['record']}\n",
    "#     url = \"http://47.93.77.19:6001/judge_correlation_yjh\"\n",
    "url = \"http://192.168.0.104:8100/judge_correlation_yjh\"\n",
    "col_name = 'sec'\n",
    "\n",
    "parse_data , elapsed_time = get_server_res_yjh(data, url, col_name)\n",
    "print(index, '  耗时：%s s'%(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:09.011534Z",
     "start_time": "2018-12-04T01:36:02.652Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:09.014535Z",
     "start_time": "2018-12-04T01:36:02.660Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = {\"record\":combined_data.loc[:,['id', 'title' ,'content']].to_dict(orient = 'records')}\n",
    "import time\n",
    "for index in range(len(cbrc_data['record'])):\n",
    "    data = {\"record\":[cbrc_data['record'][index],]}\n",
    "#     url = \"http://47.93.77.19:6001/judge_correlation_yjh\"\n",
    "    url = \"http://192.168.0.104:8100/judge_correlation_yjh\"\n",
    "    col_name = 'sec'\n",
    "    \n",
    "    parse_data , elapsed_time = get_server_res_yjh(data, url, col_name)\n",
    "    print(index, '  耗时：%s s'%(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:09.016535Z",
     "start_time": "2018-12-04T01:36:02.666Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {\"record\":[cbrc_data['record'][0], ]}\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:09.018535Z",
     "start_time": "2018-12-04T01:36:02.674Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cbrc_data['record'][0]\n",
    "len(cbrc_data['record'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 保险业--旧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:38:55.978169Z",
     "start_time": "2018-12-03T07:38:43.293444Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = specific_func.get_engine('circ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## mysql 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 八分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T07:38:37.699124Z",
     "start_time": "2018-12-03T07:38:35.010970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018-09-02', '2018-09-03', '2018-09-04', '2018-09-05', '2018-09-06', '2018-09-07', '2018-09-08', '2018-09-09', '2018-09-10', '2018-09-11', '2018-09-12', '2018-09-13', '2018-09-14', '2018-09-15', '2018-09-16', '2018-09-17', '2018-09-18', '2018-09-19', '2018-09-20', '2018-09-21', '2018-09-22', '2018-09-23', '2018-09-24', '2018-09-25', '2018-09-26', '2018-09-27', '2018-09-28', '2018-09-29', '2018-09-30', '2018-10-01', '2018-10-02', '2018-10-03', '2018-10-04', '2018-10-05', '2018-10-06', '2018-10-07', '2018-10-08', '2018-10-09', '2018-10-10', '2018-10-11', '2018-10-12', '2018-10-13', '2018-10-14', '2018-10-15', '2018-10-16', '2018-10-17', '2018-10-18', '2018-10-19', '2018-10-20', '2018-10-21', '2018-10-22', '2018-10-23', '2018-10-24', '2018-10-25', '2018-10-26', '2018-10-27', '2018-10-28', '2018-10-29', '2018-10-30', '2018-10-31', '2018-11-01', '2018-11-02', '2018-11-03', '2018-11-04', '2018-11-05', '2018-11-06', '2018-11-07', '2018-11-08', '2018-11-09', '2018-11-10', '2018-11-11', '2018-11-12', '2018-11-13', '2018-11-14', '2018-11-15', '2018-11-16', '2018-11-17', '2018-11-18', '2018-11-19', '2018-11-20', '2018-11-21', '2018-11-22', '2018-11-23', '2018-11-24', '2018-11-25', '2018-11-26', '2018-11-27', '2018-11-28', '2018-11-29', '2018-11-30', '2018-12-01', '2018-12-02', '2018-12-03']\n"
     ]
    }
   ],
   "source": [
    "# day_select = '2018-09-09'\n",
    "day_list = get_day_list('2018-09-01', '2018-12-03')\n",
    "print(day_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取数据--系统采集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T02:39:39.147862Z",
     "start_time": "2018-11-26T01:51:35.477926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- day_select:  2018-11-22\n",
      "circ_cor:  (8462, 6)\n",
      "circ_uncor:  (25505, 6)\n",
      "去重前： (33967, 6)\n",
      "去重后： (22798, 6)\n",
      "去空值后： (22798, 6)\n",
      "(22798, 7)\n",
      "噪音        14336\n",
      "资本市场       2472\n",
      "消费服务       1247\n",
      "监管         1043\n",
      "产品销售       1030\n",
      "行业         1003\n",
      "其他相关报道      929\n",
      "公司内部管理      736\n",
      "补录            2\n",
      "Name: predict_label, dtype: int64\n",
      "-- day_select:  2018-11-23\n",
      "circ_cor:  (9350, 6)\n",
      "circ_uncor:  (26999, 6)\n",
      "去重前： (36349, 6)\n",
      "去重后： (23964, 6)\n",
      "去空值后： (23964, 6)\n",
      "(23964, 7)\n",
      "噪音        14614\n",
      "资本市场       3130\n",
      "监管         1256\n",
      "消费服务       1113\n",
      "其他相关报道     1038\n",
      "行业         1021\n",
      "产品销售        962\n",
      "公司内部管理      825\n",
      "补录            5\n",
      "Name: predict_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "gather_types = '采集'\n",
    "\n",
    "for day_select in day_list:\n",
    "    print('-- day_select: ', day_select)\n",
    "\n",
    "    # 相关数据\n",
    "    sql_one_day = \"select t1.id, t1.group_id,t1.classify as predict_label,\\\n",
    "                        t1.title,t2.center as content, t1.publishtime as publishtime \\\n",
    "                        from wise_web_docinfo t1, wise_web_docinfo_center t2 \\\n",
    "                            where t1.id=t2.doc_id \\\n",
    "                                  and  date_format(t1.publishtime, '%%Y-%%m-%%d') = '{0}' \\\n",
    "                                  and t1.gather_type = 0 \\\n",
    "                                  group by t1.titlehash\".format(day_select) # \n",
    "    # # titlehash 去重后\n",
    "    circ_cor = pd.read_sql(sql_one_day, engine)\n",
    "    print('circ_cor: ', circ_cor.shape  )\n",
    "    \n",
    "    # 不相关数据\n",
    "    sql_one_day = \"select t1.id, t1.group_id,t1.title,t2.center as content, t1.publishtime as publishtime \\\n",
    "                        from wise_web_docinfo_uncorr t1, wise_web_docinfo_center_uncurr t2 \\\n",
    "                            where t1.id=t2.doc_id \\\n",
    "                                  and t1.publishtime >= '{0} 8:00:00' \\\n",
    "                              and t1.publishtime <= '{0} 14:00:00'\".format(day_select)\n",
    "    # 一段时间\n",
    "    circ_uncor = pd.read_sql(sql_one_day, engine)\n",
    "    circ_uncor.insert(2, 'predict_label', 8) # 噪音\n",
    "    print('circ_uncor: ', circ_uncor.shape)\n",
    "\n",
    "    circ_data = pd.concat([circ_cor, circ_uncor], axis = 0)\n",
    "    print('去重前：', circ_data.shape)\n",
    "    circ_data = circ_data.drop_duplicates(subset = 'title')\n",
    "    print('去重后：', circ_data.shape)  \n",
    "    circ_data = circ_data.dropna(subset = ['content'], axis = 0)\n",
    "    print('去空值后：', circ_data.shape)  \n",
    "\n",
    "    circ_data['predict_label'] = circ_data['predict_label'].apply(lambda x:class_name_dict[x])\n",
    "    circ_data['group_id'] = circ_data['group_id'].apply(lambda x:group_dict[str(x)])\n",
    "    circ_data.insert(3, 'label', '')\n",
    "    fea_filename = 'circ_result_class/result/%s_circ_class_predict_mysql_%s.xlsx'%(gather_types, day_select)\n",
    "    circ_data.to_excel(fea_filename, index = False)\n",
    "    print(circ_data.shape)\n",
    "    print(circ_data['predict_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 合并 & 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T02:39:46.741297Z",
     "start_time": "2018-11-26T02:39:39.286870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46755, 7)\n",
      "去重前： (46755, 7)\n",
      "去重后： (45047, 7)\n",
      "去空值后： (45003, 7)\n",
      "噪音        28088\n",
      "资本市场       5411\n",
      "消费服务       2261\n",
      "监管         2164\n",
      "其他相关报道     1889\n",
      "行业         1886\n",
      "产品销售       1833\n",
      "公司内部管理     1471\n",
      "Name: predict_label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>predict_label</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>publishtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12252939</td>\n",
       "      <td>微信</td>\n",
       "      <td>消费服务</td>\n",
       "      <td>NaN</td>\n",
       "      <td>交通事故发生后，受害人治疗其他疾病能否得到赔偿？</td>\n",
       "      <td>【新疆巴州律师魏娜为您提供专业的法律咨询，联系电话：138 9900 7303】 前言 ...</td>\n",
       "      <td>2018-11-22 09:35:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12256481</td>\n",
       "      <td>新闻</td>\n",
       "      <td>其他相关报道</td>\n",
       "      <td>NaN</td>\n",
       "      <td>西藏银保监局筹备组关于核准中国农业发展银行西藏自治区分行熊壮任职资格的批复</td>\n",
       "      <td>西藏银保监局筹备组关于核准中国农业发展银行西藏自治区分行熊壮任职资格的批复 藏银保监（筹）〔...</td>\n",
       "      <td>2018-11-22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12252533</td>\n",
       "      <td>新闻</td>\n",
       "      <td>监管</td>\n",
       "      <td>NaN</td>\n",
       "      <td>银行“理财子公司”来了</td>\n",
       "      <td>银行“理财子公司”来了　　 经济日报·中国经济网记者 郭子源　　设立理财子公司开展资管业...</td>\n",
       "      <td>2018-11-22 08:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12250479</td>\n",
       "      <td>微信</td>\n",
       "      <td>产品销售</td>\n",
       "      <td>NaN</td>\n",
       "      <td>和优秀的人在一起，有多重要？</td>\n",
       "      <td>- 欢迎关注 - 知乎上有个话题，你的舍友能上进到什么地步？ 底下近千条的答案，都在述说着许...</td>\n",
       "      <td>2018-11-22 08:02:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12248558</td>\n",
       "      <td>新闻</td>\n",
       "      <td>其他相关报道</td>\n",
       "      <td>NaN</td>\n",
       "      <td>复星保德信人寿总裁储良荣获2018年度中国保险业“教育培训年度贡献者”称号</td>\n",
       "      <td>(图片)(图片)11月21日，由中国保险行业协会主办的2018年度中国保险业“教育培训年度贡...</td>\n",
       "      <td>2018-11-22 06:15:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id group_id predict_label  label  \\\n",
       "0  12252939       微信          消费服务    NaN   \n",
       "1  12256481       新闻        其他相关报道    NaN   \n",
       "2  12252533       新闻            监管    NaN   \n",
       "3  12250479       微信          产品销售    NaN   \n",
       "4  12248558       新闻        其他相关报道    NaN   \n",
       "\n",
       "                                   title  \\\n",
       "0               交通事故发生后，受害人治疗其他疾病能否得到赔偿？   \n",
       "1  西藏银保监局筹备组关于核准中国农业发展银行西藏自治区分行熊壮任职资格的批复   \n",
       "2                            银行“理财子公司”来了   \n",
       "3                         和优秀的人在一起，有多重要？   \n",
       "4  复星保德信人寿总裁储良荣获2018年度中国保险业“教育培训年度贡献者”称号   \n",
       "\n",
       "                                             content         publishtime  \n",
       "0    【新疆巴州律师魏娜为您提供专业的法律咨询，联系电话：138 9900 7303】 前言 ... 2018-11-22 09:35:37  \n",
       "1  西藏银保监局筹备组关于核准中国农业发展银行西藏自治区分行熊壮任职资格的批复 藏银保监（筹）〔... 2018-11-22 00:00:00  \n",
       "2  　　银行“理财子公司”来了　　 经济日报·中国经济网记者 郭子源　　设立理财子公司开展资管业... 2018-11-22 08:54:00  \n",
       "3  - 欢迎关注 - 知乎上有个话题，你的舍友能上进到什么地步？ 底下近千条的答案，都在述说着许... 2018-11-22 08:02:48  \n",
       "4  (图片)(图片)11月21日，由中国保险行业协会主办的2018年度中国保险业“教育培训年度贡... 2018-11-22 06:15:48  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = pd.DataFrame()\n",
    "for day_select in day_list:\n",
    "    file_name = 'circ_result_class/result/%s_circ_class_predict_mysql_%s.xlsx'%(gather_types, day_select)\n",
    "    if os.path.isfile(file_name):\n",
    "        print(file_name)\n",
    "        tmp_data = pd.read_excel(file_name)\n",
    "        combined_data = pd.concat([combined_data, tmp_data], axis = 0)\n",
    "\n",
    "if gather_types != '补录':\n",
    "    combined_data = combined_data[combined_data['predict_label'] != '补录']\n",
    "print(combined_data.shape)  \n",
    "print('去重前：', combined_data.shape)\n",
    "combined_data = combined_data.drop_duplicates(subset = 'title')\n",
    "print('去重后：', combined_data.shape)  \n",
    "combined_data = combined_data.dropna(subset = ['content'], axis = 0)\n",
    "print('去空值后：', combined_data.shape)  \n",
    "\n",
    "print(combined_data['predict_label'].value_counts())\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T02:43:59.708765Z",
     "start_time": "2018-11-26T02:43:58.877718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "噪音        28088\n",
      "资本市场       5411\n",
      "消费服务       2261\n",
      "监管         2164\n",
      "其他相关报道     1889\n",
      "行业         1886\n",
      "产品销售       1833\n",
      "公司内部管理     1471\n",
      "Name: predict_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "fea_filename = 'circ_result_class/result/%s_circ_class_predict_mysql_20181126(1122-1123).xlsx'%gather_types\n",
    "# sel_col = ['行业','资本市场', '消费服务', '公司内部管理', '监管']\n",
    "# sel_col = ['其他相关报道','行业',  '公司内部管理', '监管']\n",
    "sel_col = combined_data['predict_label'].unique().tolist()\n",
    "sel_data = combined_data[combined_data['predict_label'].isin(sel_col)]\n",
    "print(sel_data['predict_label'].value_counts())\n",
    "with pd.ExcelWriter(fea_filename) as writer:\n",
    "    for label in sel_data['predict_label'].unique():\n",
    "        tmp_data = sel_data[sel_data['predict_label'] == label]\n",
    "        if gather_types == '补录':\n",
    "            N = tmp_data.shape[0]\n",
    "        else :\n",
    "            if tmp_data.shape[0] > 100:\n",
    "                N = 100\n",
    "            else :\n",
    "                N = tmp_data.shape[0]\n",
    "    #         if label == '公司内部管理': \n",
    "    #             N = 200\n",
    "        tmp_data.sample(n = N, axis = 0, random_state=3).to_excel(writer,label, index = False)\n",
    "    \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 倾向性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T06:34:42.386907Z",
     "start_time": "2018-11-12T06:34:42.378906Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# day_select = '2018-09-09'\n",
    "day_list = get_day_list('2018-11-05', '2018-11-08')\n",
    "print(day_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T06:33:51.028969Z",
     "start_time": "2018-11-12T06:32:30.589369Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for day_select in day_list:\n",
    "    print('-- day_select: ', day_select)\n",
    "\n",
    "    # 相关数据\n",
    "    sql_one_day = \"select t1.id, t1.group_id,t1.classify as predict_label, t1.tendency,\\\n",
    "                        t1.title,t2.center as content, t1.publishtime as publishtime \\\n",
    "                        from wise_web_docinfo t1, wise_web_docinfo_center t2 \\\n",
    "                            where t1.id=t2.doc_id \\\n",
    "                                  and  date_format(t1.publishtime, '%%Y-%%m-%%d') = '{0}' \\\n",
    "                                  and t1.gather_type = 0 \\\n",
    "                                  group by t1.titlehash\".format(day_select) # \n",
    "    # # titlehash 去重后\n",
    "    circ_cor = pd.read_sql(sql_one_day, engine)\n",
    "    print('circ_cor: ', circ_cor.shape  )\n",
    "\n",
    "    circ_data = circ_cor\n",
    "    print('去重前：', circ_data.shape)\n",
    "    circ_data = circ_data.drop_duplicates(subset = 'title')\n",
    "    print('去重后：', circ_data.shape)  \n",
    "    circ_data = circ_data.dropna(subset = ['content'], axis = 0)\n",
    "    print('去空值后：', circ_data.shape)  \n",
    "\n",
    "    circ_data['predict_label'] = circ_data['predict_label'].apply(lambda x:class_name_dict[x])\n",
    "    circ_data['group_id'] = circ_data['group_id'].apply(lambda x:group_dict[str(x)])\n",
    "    circ_data.insert(4, 'label', '')\n",
    "    fea_filename = 'circ_result_tendency/result/circ_tendency_predict_mysql_%s.xlsx'%day_select\n",
    "    circ_data.to_excel(fea_filename, index = False)\n",
    "    print(circ_data.shape)\n",
    "    \n",
    "    print(circ_data.pivot_table(index = ['tendency'], columns = ['predict_label'], \n",
    "                          values = 'title', aggfunc=len, \n",
    "                          fill_value=0, margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 合并 & 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T08:00:28.415958Z",
     "start_time": "2018-11-12T08:00:24.514735Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data = pd.DataFrame()\n",
    "for day_select in day_list:\n",
    "    tmp_data = pd.read_excel('circ_result_tendency/result/circ_tendency_predict_mysql_%s.xlsx'%day_select)\n",
    "    combined_data = pd.concat([combined_data, tmp_data], axis = 0)\n",
    "\n",
    "combined_data = combined_data[combined_data['predict_label'] != '补录']\n",
    "print(combined_data.shape)  \n",
    "print('去重前：', combined_data.shape)\n",
    "combined_data = combined_data.drop_duplicates(subset = 'title')\n",
    "print('去重后：', combined_data.shape)  \n",
    "combined_data = combined_data.dropna(subset = ['content'], axis = 0)\n",
    "print('去空值后：', combined_data.shape)  \n",
    "\n",
    "print(combined_data['tendency'].value_counts())\n",
    "combined_data.pivot_table(index = ['tendency', 'group_id'], \n",
    "                                columns = ['predict_label'], \n",
    "                                values = 'title', aggfunc=len, \n",
    "                                fill_value=0, margins=True)\n",
    "# combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T08:00:37.181459Z",
     "start_time": "2018-11-12T08:00:36.467419Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fea_filename = 'circ_result_tendency/result/circ_tendency_predict_mysql_20181112(1106-1108).xlsx'\n",
    "# sel_col = combined_data['predict_label'].unique().tolist()\n",
    "# sel_data = combined_data[combined_data['tendency'].isin(sel_col)]\n",
    "print(combined_data['tendency'].value_counts())\n",
    "\n",
    "N = 200 # 每类 N 条数据\n",
    "class_n = int(combined_data['predict_label'].unique().shape[0])\n",
    "n = int(N / class_n) + 20\n",
    "\n",
    "print('正负各 %s 条，共 %s 类， 每类各 %s 条'%(N, class_n, n))\n",
    "with pd.ExcelWriter(fea_filename) as writer:\n",
    "    for tendency in combined_data['tendency'].unique():\n",
    "        tmp_data = pd.DataFrame()\n",
    "        sel_data = combined_data[combined_data['tendency'] == tendency]        \n",
    "        for predict_label in combined_data['predict_label'].unique():\n",
    "            label_data = sel_data[sel_data['predict_label'] == predict_label]\n",
    "            if label_data.shape[0] > n:\n",
    "                sel_label_data = label_data.sample(n = n, axis = 0, random_state=3)\n",
    "            else :\n",
    "                sel_label_data = label_data\n",
    "            tmp_data = pd.concat([tmp_data, sel_label_data], axis = 0)        \n",
    "            print('tendency: %s, predict_label: %s, size: %s'%(tendency, predict_label, tmp_data.shape))\n",
    "        \n",
    "        if tmp_data.shape[0] > N:\n",
    "            t_n = N\n",
    "        else :\n",
    "            t_n = tmp_data.shape[0]\n",
    "        \n",
    "        tmp_data = tmp_data.sample(n = N, axis = 0, random_state=3)\n",
    "        tmp_data.to_excel(writer,str(tendency), index = False)\n",
    "        print(tmp_data.pivot_table(index = ['tendency'], \n",
    "                                    columns = ['predict_label'], \n",
    "                                    values = 'title', aggfunc=len, \n",
    "                                    fill_value=0, margins=True))    \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 补录数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T09:29:11.314545Z",
     "start_time": "2018-12-03T09:28:41.011812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title 去重前： (573, 8)\n",
      "title 去重后： (573, 8)\n",
      "content 去重后： (573, 8)\n",
      "title 去空值后： (573, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>publishtime</th>\n",
       "      <th>gather_type</th>\n",
       "      <th>tendency</th>\n",
       "      <th>mysql_label</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10933233</td>\n",
       "      <td>微信</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>外资股东全搜罗：隐身中资险企，财险、寿险市场份额双双接近10%</td>\n",
       "      <td>(图片)\\n\\n说到外资在国内保险市场的表现，很多人首先就会想到市场份额低这一点。确实，自...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10910821</td>\n",
       "      <td>微信</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>从“天鸽”到“山竹”，保险业用这些方法更好的“管住”风险</td>\n",
       "      <td>(图片)\\n\\n台风“山竹”在广东西部沿海过境已经3天，得益于国家及地方政府相关部门的及早...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11483454</td>\n",
       "      <td>微信</td>\n",
       "      <td>2018-10-20</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>突发，上市公司举报“平安养老风控总监伪造公章夺控制权”</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t 关于&lt;font color=\"#FF0000\"&gt;平安养老保险&lt;/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11666987</td>\n",
       "      <td>微信</td>\n",
       "      <td>2018-10-26</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>上半年持续亏损   董事长遭逮捕华安保险精达股份玩起“二人转” | 保险</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t 特华投资与&lt;font color=\"#FF0000\"&gt;华安保险&lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11765888</td>\n",
       "      <td>纸媒</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018年10月31日--视点--业内专家分析如何保障重疾险消费者权益</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t \\n\\t\\t\\t\\t\\t今年6月,中国&lt;font color=\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id group_id publishtime  gather_type  tendency  mysql_label  \\\n",
       "0  10933233       微信  2018-09-20            1         0            0   \n",
       "1  10910821       微信  2018-09-18            1         0            0   \n",
       "2  11483454       微信  2018-10-20            1        -1            0   \n",
       "3  11666987       微信  2018-10-26            1        -1            0   \n",
       "4  11765888       纸媒  2018-10-31            1         0            0   \n",
       "\n",
       "                                  title  \\\n",
       "0       外资股东全搜罗：隐身中资险企，财险、寿险市场份额双双接近10%   \n",
       "1          从“天鸽”到“山竹”，保险业用这些方法更好的“管住”风险   \n",
       "2           突发，上市公司举报“平安养老风控总监伪造公章夺控制权”   \n",
       "3  上半年持续亏损   董事长遭逮捕华安保险精达股份玩起“二人转” | 保险   \n",
       "4   2018年10月31日--视点--业内专家分析如何保障重疾险消费者权益   \n",
       "\n",
       "                                             content  \n",
       "0   (图片)\\n\\n说到外资在国内保险市场的表现，很多人首先就会想到市场份额低这一点。确实，自...  \n",
       "1   (图片)\\n\\n台风“山竹”在广东西部沿海过境已经3天，得益于国家及地方政府相关部门的及早...  \n",
       "2   \\n\\t\\t\\t\\t\\t 关于<font color=\"#FF0000\">平安养老保险</...  \n",
       "3   \\n\\t\\t\\t\\t\\t 特华投资与<font color=\"#FF0000\">华安保险<...  \n",
       "4   \\n\\t\\t\\t\\t\\t \\n\\t\\t\\t\\t\\t今年6月,中国<font color=\"...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 人工补录\n",
    "sql_human_additional = \"select t1.id, t1.group_id, date_format(t1.publishtime,'%%Y-%%m-%%d') as publishtime,  \\\n",
    "                            t1.gather_type, t1.tendency,t1.classify as mysql_label, \\\n",
    "                            t1.title, t2.center as content\\\n",
    "                            from wise_web_docinfo t1, wise_web_docinfo_center t2 \\\n",
    "                                where (date_format(publishtime, '%%Y-%%m-%%d') >= '{0}' and \\\n",
    "                                      date_format(publishtime, '%%Y-%%m-%%d') <= '{1}') and \\\n",
    "                                      t1.id = t2.doc_id and \\\n",
    "                                      t1.gather_type in (1,3) \\\n",
    "                            group by t1.titlehash\".format('2018-09-16', '2018-12-03') \n",
    "\n",
    "human_additional = pd.read_sql(sql_human_additional, engine)\n",
    "human_additional['group_id'] = human_additional['group_id'].apply(lambda x:group_dict[str(x)])\n",
    "print('title 去重前：', human_additional.shape)\n",
    "human_additional = human_additional.drop_duplicates(subset = 'title')\n",
    "print('title 去重后：', human_additional.shape)  \n",
    "human_additional = human_additional.drop_duplicates(subset = ['content'])\n",
    "print('content 去重后：', human_additional.shape)  \n",
    "human_additional = human_additional.dropna(subset = ['title'], axis = 0)\n",
    "print('title 去空值后：', human_additional.shape) \n",
    "human_additional.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T09:29:23.324232Z",
     "start_time": "2018-12-03T09:29:12.009585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行业        180\n",
      "监管        109\n",
      "噪音        106\n",
      "公司内部管理    102\n",
      "资本市场       44\n",
      "消费服务       20\n",
      "产品销售       12\n",
      "Name: predict_label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>publishtime</th>\n",
       "      <th>gather_type</th>\n",
       "      <th>tendency</th>\n",
       "      <th>mysql_label</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>predict_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10933233</td>\n",
       "      <td>微信</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>外资股东全搜罗：隐身中资险企，财险、寿险市场份额双双接近10%</td>\n",
       "      <td>(图片)\\n\\n说到外资在国内保险市场的表现，很多人首先就会想到市场份额低这一点。确实，自...</td>\n",
       "      <td>行业</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10910821</td>\n",
       "      <td>微信</td>\n",
       "      <td>2018-09-18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>从“天鸽”到“山竹”，保险业用这些方法更好的“管住”风险</td>\n",
       "      <td>(图片)\\n\\n台风“山竹”在广东西部沿海过境已经3天，得益于国家及地方政府相关部门的及早...</td>\n",
       "      <td>行业</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11483454</td>\n",
       "      <td>微信</td>\n",
       "      <td>2018-10-20</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>突发，上市公司举报“平安养老风控总监伪造公章夺控制权”</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t 关于&lt;font color=\"#FF0000\"&gt;平安养老保险&lt;/...</td>\n",
       "      <td>资本市场</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11666987</td>\n",
       "      <td>微信</td>\n",
       "      <td>2018-10-26</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>上半年持续亏损   董事长遭逮捕华安保险精达股份玩起“二人转” | 保险</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t 特华投资与&lt;font color=\"#FF0000\"&gt;华安保险&lt;...</td>\n",
       "      <td>公司内部管理</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11765888</td>\n",
       "      <td>纸媒</td>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2018年10月31日--视点--业内专家分析如何保障重疾险消费者权益</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t \\n\\t\\t\\t\\t\\t今年6月,中国&lt;font color=\"...</td>\n",
       "      <td>噪音</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id group_id publishtime  gather_type  tendency  mysql_label label  \\\n",
       "0  10933233       微信  2018-09-20            1         0            0         \n",
       "1  10910821       微信  2018-09-18            1         0            0         \n",
       "2  11483454       微信  2018-10-20            1        -1            0         \n",
       "3  11666987       微信  2018-10-26            1        -1            0         \n",
       "4  11765888       纸媒  2018-10-31            1         0            0         \n",
       "\n",
       "                                  title  \\\n",
       "0       外资股东全搜罗：隐身中资险企，财险、寿险市场份额双双接近10%   \n",
       "1          从“天鸽”到“山竹”，保险业用这些方法更好的“管住”风险   \n",
       "2           突发，上市公司举报“平安养老风控总监伪造公章夺控制权”   \n",
       "3  上半年持续亏损   董事长遭逮捕华安保险精达股份玩起“二人转” | 保险   \n",
       "4   2018年10月31日--视点--业内专家分析如何保障重疾险消费者权益   \n",
       "\n",
       "                                             content predict_label  \n",
       "0   (图片)\\n\\n说到外资在国内保险市场的表现，很多人首先就会想到市场份额低这一点。确实，自...            行业  \n",
       "1   (图片)\\n\\n台风“山竹”在广东西部沿海过境已经3天，得益于国家及地方政府相关部门的及早...            行业  \n",
       "2   \\n\\t\\t\\t\\t\\t 关于<font color=\"#FF0000\">平安养老保险</...          资本市场  \n",
       "3   \\n\\t\\t\\t\\t\\t 特华投资与<font color=\"#FF0000\">华安保险<...        公司内部管理  \n",
       "4   \\n\\t\\t\\t\\t\\t \\n\\t\\t\\t\\t\\t今年6月,中国<font color=\"...            噪音  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_additional['title'] = human_additional['title'].astype(str) \n",
    "human_additional['content'] = human_additional['content'].astype(str)\n",
    "data = {\"record\":human_additional.loc[:,['id', 'title' ,'content']].to_dict(orient = 'records')}\n",
    "url = \"http://47.93.77.19:10000/judge_correlation_i\"\n",
    "col_name = 'cor'\n",
    "parse_data, elapsed_time = get_server_res(data, url, col_name)\n",
    "parse_data.columns = ['id', 'predict_label']\n",
    "human_additional = pd.merge(human_additional, parse_data, on = 'id', how = 'left')\n",
    "human_additional['predict_label'] = human_additional['predict_label'].apply(lambda x:class_name_dict[x])\n",
    "human_additional.insert(6, 'label', '')\n",
    "print(human_additional['predict_label'].value_counts())\n",
    "human_additional.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T09:29:24.581304Z",
     "start_time": "2018-12-03T09:29:23.882264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "circ_result_class/result/补录_保监会（旧）_class_predict_mysql_20181203(0917-1203).xlsx\n",
      "行业        180\n",
      "监管        109\n",
      "噪音        106\n",
      "公司内部管理    102\n",
      "资本市场       44\n",
      "消费服务       20\n",
      "产品销售       12\n",
      "Name: predict_label, dtype: int64\n",
      "\n",
      "predict_label  产品销售  公司内部管理   噪音  消费服务   监管   行业  资本市场  All\n",
      "group_id                                                   \n",
      "微信                3      23   27     2   26   69    11  161\n",
      "微博                0       0    1     0    0    0     0    1\n",
      "新闻                9      72   64    15   65   87    31  343\n",
      "新闻客户端             0       4    3     0    7    5     1   20\n",
      "纸媒                0       3    3     1   11   18     1   37\n",
      "视频                0       0    8     1    0    1     0   10\n",
      "论坛                0       0    0     1    0    0     0    1\n",
      "All              12     102  106    20  109  180    44  573\n"
     ]
    }
   ],
   "source": [
    "fea_filename = 'circ_result_class/result/补录_保监会（旧）_class_predict_mysql_20181203(0917-1203).xlsx'\n",
    "print(fea_filename)\n",
    "\n",
    "sel_col = ['噪音', '消费服务', '公司内部管理', '监管',\n",
    "           '行业', '资本市场', '其他相关报道','产品销售','交通','环保']\n",
    "sel_data = human_additional[human_additional['predict_label'].isin(sel_col)]\n",
    "print(sel_data['predict_label'].value_counts())\n",
    "print()\n",
    "\n",
    "c_data = pd.DataFrame()\n",
    "with pd.ExcelWriter(fea_filename) as writer:\n",
    "    for label in sel_data['predict_label'].unique():\n",
    "        tmp_data = sel_data[sel_data['predict_label'] == label]\n",
    "        N = tmp_data.shape[0]            \n",
    "        save_data = tmp_data.sample(n = N, axis = 0, random_state=42)\n",
    "        save_data.to_excel(writer,label, index = False)\n",
    "        c_data = pd.concat([c_data, save_data], axis = 0)\n",
    "    print(c_data.pivot_table(index = ['group_id'], \n",
    "                                columns = ['predict_label'], \n",
    "                                values = 'title', aggfunc=len, \n",
    "                                fill_value=0, margins=True))      \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T09:29:25.627363Z",
     "start_time": "2018-12-03T09:29:25.075332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "circ_result_tendency/result/补录_保监会（旧）_tendency_predict_mysql_20181203(0917-1203).xlsx\n",
      " 0    381\n",
      "-1    192\n",
      "Name: tendency, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "fea_filename = 'circ_result_tendency/result/补录_保监会（旧）_tendency_predict_mysql_20181203(0917-1203).xlsx'\n",
    "print(fea_filename)\n",
    "print(human_additional['tendency'].value_counts())\n",
    "\n",
    "with pd.ExcelWriter(fea_filename) as writer:\n",
    "    for tendency in human_additional['tendency'].unique():\n",
    "        sel_data = human_additional[human_additional['tendency'] == tendency]    \n",
    "        t_n = sel_data.shape[0]        \n",
    "        tmp_data = sel_data.sample(n = t_n, axis = 0, random_state=3)\n",
    "        tmp_data.to_excel(writer,str(tendency), index = False)           \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本地模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 八分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T03:26:26.197443Z",
     "start_time": "2018-09-20T03:26:23.897915Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "pipeline_old = joblib.load( \"model/circ_8classifier_1015.pkl.z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T03:30:52.594390Z",
     "start_time": "2018-09-20T03:28:37.834752Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data['title_content'] = combined_data['title'].astype(str) + '。' + combined_data['content'].astype(str)\n",
    "title_content = pre_cor_circ.handle_contents(combined_data['title_content'].tolist())\n",
    "print(len(title_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-20T03:50:00.412Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local_label = pipeline_old.predict(title_content)\n",
    "local_proba = pipeline_old.predict_proba(title_content)\n",
    "\n",
    "combined_data['local_label'] = local_label\n",
    "combined_data['local_proba'] = local_proba.max(axis = 1)\n",
    "combined_data['local_label'] = combined_data['local_label'].apply(lambda x:class_name_dict[x])\n",
    "print(combined_data.shape)\n",
    "combined_data.iloc[:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线上线下一致性: mysql 与 local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-20T03:48:25.094577Z",
     "start_time": "2018-09-20T03:48:24.380536Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data['R_W'] = combined_data.apply(lambda x: 'Right' if x['local_label'] == x['predict_label'] else 'Wrong', axis = 1)\n",
    "print(combined_data[combined_data['R_W'] == 'Right'].shape[0]/combined_data.shape[0])\n",
    "print(combined_data['R_W'].value_counts())\n",
    "combined_data[combined_data['R_W'] == 'Wrong'].pivot_table(index = ['local_label'], columns = ['predict_label'], \n",
    "                                                            aggfunc = [len], values = ['id'], \n",
    "                                                            fill_value = 0, margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线上线下一致性: online 与 local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data['id'] = range(combined_data.shape[0])\n",
    "combined_data['title'] = combined_data['title'].astype(str) \n",
    "combined_data['content'] = combined_data['content'].astype(str)\n",
    "data = {\"record\":combined_data.loc[:,['id', 'title' ,'content']].to_dict(orient = 'records')}\n",
    "url = \"http://47.93.77.19:10000/judge_correlation_i\"\n",
    "col_name = 'cor'\n",
    "parse_data, elapsed_time = get_server_res(data, url, col_name)\n",
    "parse_data.columns = ['id', 'online_label']\n",
    "parse_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data = pd.merge(combined_data, parse_data, on  = 'id')\n",
    "print(combined_data.shape)\n",
    "combined_data['O_R_W'] = combined_data.apply(lambda x: 'Right' if x['local_label'] == x['online_label'] else 'Wrong', axis = 1)\n",
    "print(combined_data[combined_data['O_R_W'] == 'Right'].shape[0]/combined_data.shape[0])\n",
    "print(combined_data['O_R_W'].value_counts())\n",
    "combined_data[combined_data['O_R_W'] == 'Wrong'].pivot_table(index = ['local_label'], columns = ['online_label'], \n",
    "                                                            aggfunc = [len], values = ['urlhash'], \n",
    "                                                            fill_value = 0, margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 银行业--旧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:12.858754Z",
     "start_time": "2018-12-04T01:36:12.596739Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = specific_func.get_engine('cbrc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:36:13.244777Z",
     "start_time": "2018-12-04T01:36:13.238776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018-11-06', '2018-11-07', '2018-11-08']\n"
     ]
    }
   ],
   "source": [
    "# day_select = '2018-09-09'\n",
    "day_list = get_day_list('2018-11-05', '2018-11-08')\n",
    "print(day_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## mysql 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 八分类数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T03:49:29.356849Z",
     "start_time": "2018-11-12T03:49:29.348848Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sql_circ_cor_one_day = \"select t1.id, t1.publishtime, t1.title,t2.text as content \\\n",
    "#                             from elint_web_docinfo t1, wise_web_docinfo_text t2 \\\n",
    "#                                 where t1.id = t2.doc_id \\\n",
    "#                                   and date_format(t1.publishtime, '%%Y-%%m-%%d') = '{0}'\".format('2018-08-07')\n",
    "# # 实际\n",
    "# circ_cor = pd.read_sql(sql_circ_cor_one_day, engine)\n",
    "# print(circ_cor.shape)\n",
    "# circ_cor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T04:42:11.480734Z",
     "start_time": "2018-11-12T04:06:51.501600Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for day_select in day_list:\n",
    "    print('-- day_select: ', day_select)\n",
    "    \n",
    "    # 获取八分类\n",
    "    sql_one_day = \"select t2.urlhash, t1.traffic_id, t2.title as title_1\\\n",
    "                        from wise_web_classify_traffic_docinfo t1, wise_web_docinfo_basic t2 \\\n",
    "                            where t1.base_id=t2.id \\\n",
    "                                  and date_format(t2.publishtime, '%%Y-%%m-%%d') = '{0}' \".format(day_select)\n",
    "    cbrc_flag = pd.read_sql(sql_one_day, engine)\n",
    "    print('cbrc_flag：', cbrc_flag.shape)\n",
    "    \n",
    "    # 相关数据\n",
    "    sql_one_day = \"select t1.urlhash, t1.title,t2.text as content, t1.group_id, t1.publishtime as publishtime \\\n",
    "                        from elint_web_docinfo t1, wise_web_docinfo_text t2 \\\n",
    "                            where t1.id=t2.doc_id \\\n",
    "                                  and t1.publishtime >= '{0} 08:00:00' \\\n",
    "                                  and t1.publishtime <= '{0} 14:00:00' \\\n",
    "                                group by t1.titlehash\".format(day_select)\n",
    "    # titlehash 去重后\n",
    "    cbrc_cor = pd.read_sql(sql_one_day, engine) \n",
    "    print('cbrc_cor：', cbrc_cor.shape)\n",
    "    \n",
    "    # 不相关数据\n",
    "    sql_cbrc_uncor = \"select urlhash, title, content, group_id, publishtime \\\n",
    "                            from wise_web_docinfo_uncor \\\n",
    "                            where date_format(publishtime, '%%Y-%%m-%%d') = '{0}'\".format(day_select)\n",
    "    cbrc_uncor = pd.read_sql(sql_cbrc_uncor, engine)  \n",
    "    print('cbrc_uncor：', cbrc_uncor.shape)\n",
    "\n",
    "    cbrc_data = pd.concat([cbrc_cor, cbrc_uncor], axis = 0)\n",
    "    print('去重前：', cbrc_data.shape)\n",
    "    cbrc_data = cbrc_data.drop_duplicates(subset = 'title')\n",
    "    print('去重后：', cbrc_data.shape)  \n",
    "    cbrc_data = cbrc_data.dropna(subset = ['content'], axis = 0)\n",
    "    print('去空值后：', cbrc_data.shape)  \n",
    "\n",
    "    cbrc_combined = pd.merge(cbrc_flag, cbrc_data, how = 'inner', on = 'urlhash')\n",
    "    cbrc_combined['predict_label'] = cbrc_combined['traffic_id'].apply(lambda x:class_name_dict[x])\n",
    "    cbrc_combined['group_id'] = cbrc_combined['group_id'].apply(lambda x:group_dict[str(x)])\n",
    "    cbrc_combined['label'] = ''\n",
    "    cbrc_combined = cbrc_combined[['urlhash', 'predict_label', 'label', 'title', 'content', 'group_id', 'publishtime']]\n",
    "    fea_filename = 'cbrc_result_class/result/cbrc_class_predict_mysql_%s.xlsx'%day_select\n",
    "    cbrc_combined.to_excel(fea_filename, index = False)\n",
    "    print(cbrc_combined.shape)\n",
    "    print(cbrc_combined['predict_label'].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 合并 & 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T05:37:30.963878Z",
     "start_time": "2018-11-12T05:37:22.421679Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data = pd.DataFrame()\n",
    "for day_select in day_list:\n",
    "    tmp_data = pd.read_excel('cbrc_result_class/result/cbrc_class_predict_mysql_%s.xlsx'%day_select)\n",
    "    combined_data = pd.concat([combined_data, tmp_data], axis = 0)\n",
    "\n",
    "combined_data = combined_data[combined_data['predict_label'] != '补录']\n",
    "print(combined_data.shape)  \n",
    "print('去重前：', combined_data.shape)\n",
    "combined_data = combined_data.drop_duplicates(subset = 'title')\n",
    "print('去重后：', combined_data.shape)  \n",
    "combined_data = combined_data.dropna(subset = ['content'], axis = 0)\n",
    "print('去空值后：', combined_data.shape)  \n",
    "\n",
    "print(combined_data['predict_label'].value_counts())\n",
    "combined_data.iloc[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T05:37:37.756021Z",
     "start_time": "2018-11-12T05:37:36.778775Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fea_filename = 'cbrc_result_class/result/cbrc_class_predict_mysql_20181112(1106-1110).xlsx'\n",
    "# sel_col = ['噪音', '消费服务', '公司内部管理', '监管',\n",
    "#            '行业', '资本市场', '其他相关报道','产品销售']\n",
    "sel_col = ['公司内部管理', '监管', '行业', '产品销售']\n",
    "# sel_col = combined_data['predict_label'].unique().tolist()\n",
    "sel_data = combined_data[combined_data['predict_label'].isin(sel_col)]\n",
    "print(sel_data['predict_label'].value_counts())\n",
    "with pd.ExcelWriter(fea_filename) as writer:\n",
    "    for label in sel_data['predict_label'].unique():\n",
    "        tmp_data = sel_data[sel_data['predict_label'] == label]\n",
    "        if tmp_data.shape[0] > 300:\n",
    "            N = 300\n",
    "        else :\n",
    "            N = tmp_data.shape[0]\n",
    "        tmp_data.sample(n = N, axis = 0, random_state=42).to_excel(writer,label, index = False)\n",
    "    \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 倾向性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:48:39.688721Z",
     "start_time": "2018-11-12T07:33:09.932088Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for day_select in day_list:\n",
    "    print('-- day_select: ', day_select)\n",
    "    \n",
    "    # 获取八分类\n",
    "    sql_one_day = \"select t2.urlhash, t1.traffic_id, t2.title as title_1\\\n",
    "                        from wise_web_classify_traffic_docinfo t1, wise_web_docinfo_basic t2 \\\n",
    "                            where t1.base_id=t2.id \\\n",
    "                                  and date_format(t2.publishtime, '%%Y-%%m-%%d') = '{0}' \".format(day_select)\n",
    "    cbrc_flag = pd.read_sql(sql_one_day, engine)\n",
    "    print('cbrc_flag：', cbrc_flag.shape)\n",
    "    \n",
    "    # 相关数据\n",
    "    sql_one_day = \"select t1.urlhash, t1.title,t2.text as content, t1.group_id, \\\n",
    "                            t1.sen as tendency, t1.publishtime as publishtime \\\n",
    "                        from elint_web_docinfo t1, wise_web_docinfo_text t2 \\\n",
    "                            where t1.id=t2.doc_id \\\n",
    "                                  and t1.publishtime >= '{0} 08:00:00' \\\n",
    "                                  and t1.publishtime <= '{0} 14:00:00' \\\n",
    "                                group by t1.titlehash\".format(day_select)\n",
    "    # titlehash 去重后\n",
    "    cbrc_cor = pd.read_sql(sql_one_day, engine) \n",
    "    print('cbrc_cor：', cbrc_cor.shape)\n",
    "\n",
    "    cbrc_data = cbrc_cor\n",
    "    print('去重前：', cbrc_data.shape)\n",
    "    cbrc_data = cbrc_data.drop_duplicates(subset = 'title')\n",
    "    print('去重后：', cbrc_data.shape)  \n",
    "    cbrc_data = cbrc_data.dropna(subset = ['content'], axis = 0)\n",
    "    print('去空值后：', cbrc_data.shape)  \n",
    "\n",
    "    cbrc_combined = pd.merge(cbrc_flag, cbrc_data, how = 'inner', on = 'urlhash')\n",
    "    cbrc_combined['predict_label'] = cbrc_combined['traffic_id'].apply(lambda x:class_name_dict[x])\n",
    "    cbrc_combined['group_id'] = cbrc_combined['group_id'].apply(lambda x:group_dict[str(x)])\n",
    "    cbrc_combined['label'] = ''\n",
    "    cbrc_combined = cbrc_combined[['urlhash', 'group_id', 'predict_label', 'tendency', \n",
    "                                   'label', 'title', 'content', 'publishtime']]\n",
    "    fea_filename = 'cbrc_result_tendency/result/cbrc_tendency_predict_mysql_%s.xlsx'%day_select\n",
    "    cbrc_combined.to_excel(fea_filename, index = False)\n",
    "    print(cbrc_combined.shape)\n",
    "    print(cbrc_combined.pivot_table(index = ['tendency'], columns = ['predict_label'], \n",
    "                          values = 'title', aggfunc=len, \n",
    "                          fill_value=0, margins=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 合并 & 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:53:16.284065Z",
     "start_time": "2018-11-12T07:53:09.716948Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data = pd.DataFrame()\n",
    "for day_select in day_list:\n",
    "    tmp_data = pd.read_excel('cbrc_result_tendency/result/cbrc_tendency_predict_mysql_%s.xlsx'%day_select)\n",
    "    combined_data = pd.concat([combined_data, tmp_data], axis = 0)\n",
    "\n",
    "combined_data = combined_data[combined_data['predict_label'] != '补录']\n",
    "sel_col = [ '消费服务', '公司内部管理', '监管','行业']\n",
    "combined_data = combined_data[combined_data['predict_label'].isin(sel_col)]\n",
    "print(combined_data.shape)  \n",
    "print('去重前：', combined_data.shape)\n",
    "combined_data = combined_data.drop_duplicates(subset = 'title')\n",
    "print('去重后：', combined_data.shape)  \n",
    "combined_data = combined_data.dropna(subset = ['content'], axis = 0)\n",
    "print('去空值后：', combined_data.shape)  \n",
    "\n",
    "print(combined_data['tendency'].value_counts())\n",
    "combined_data.pivot_table(index = ['tendency', 'group_id'], \n",
    "                                columns = ['predict_label'], \n",
    "                                values = 'title', aggfunc=len, \n",
    "                                fill_value=0, margins=True)\n",
    "# combined_data.iloc[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T07:58:24.151850Z",
     "start_time": "2018-11-12T07:58:23.683824Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fea_filename = 'cbrc_result_tendency/result/cbrc_tendency_predict_mysql_20181112(1106-1108).xlsx'\n",
    "print(combined_data['tendency'].value_counts())\n",
    "\n",
    "N = 200 # 每类 N 条数据\n",
    "class_n = int(combined_data['predict_label'].unique().shape[0])\n",
    "n = int(N / class_n) + 200\n",
    "\n",
    "print('正负各 %s 条，共 %s 类， 每类各 %s 条'%(N, class_n, n))\n",
    "with pd.ExcelWriter(fea_filename) as writer:\n",
    "    for tendency in combined_data['tendency'].unique():\n",
    "        tmp_data = pd.DataFrame()\n",
    "        sel_data = combined_data[combined_data['tendency'] == tendency]        \n",
    "        for predict_label in combined_data['predict_label'].unique():\n",
    "            label_data = sel_data[sel_data['predict_label'] == predict_label]\n",
    "            if label_data.shape[0] > n:\n",
    "                sel_label_data = label_data.sample(n = n, axis = 0, random_state=3)\n",
    "            else :\n",
    "                sel_label_data = label_data\n",
    "            tmp_data = pd.concat([tmp_data, sel_label_data], axis = 0)        \n",
    "            print('tendency: %s, predict_label: %s, size: %s'%(tendency, predict_label, tmp_data.shape))\n",
    "        \n",
    "        if tmp_data.shape[0] > N:\n",
    "            t_n = N\n",
    "        else :\n",
    "            t_n = tmp_data.shape[0]\n",
    "        \n",
    "        tmp_data = tmp_data.sample(n = N, axis = 0, random_state=3)\n",
    "        tmp_data.to_excel(writer,str(tendency), index = False)\n",
    "        print(tmp_data.pivot_table(index = ['tendency'], \n",
    "                                    columns = ['predict_label'], \n",
    "                                    values = 'title', aggfunc=len, \n",
    "                                    fill_value=0, margins=True))    \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 补录数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:39:49.448143Z",
     "start_time": "2018-12-04T01:39:41.537690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title 去重前： (3334, 7)\n",
      "title 去重后： (3334, 7)\n",
      "content 去重后： (3334, 7)\n",
      "title 去空值后： (3334, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>publishtime</th>\n",
       "      <th>gather_type</th>\n",
       "      <th>tendency</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>267289612</td>\n",
       "      <td>微博</td>\n",
       "      <td>2018-10-31 12:11:44</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>24号没叫取了28号给我 26号后直接跳到了32号 @中国工商银行 麻烦请加强下底层工作人员...</td>\n",
       "      <td>24号没叫取了28号给我\\n26号后直接跳到了32号\\n@中国工商银行 麻烦请加强下底层工作...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>266932412</td>\n",
       "      <td>微博</td>\n",
       "      <td>2018-10-30 11:46:06</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>#魔法万圣节# 在建行庆祝万圣节 各种暂停服务 没人的情况下等待二十分钟 后边的一个叔叔等待...</td>\n",
       "      <td>#魔法万圣节# 在建行庆祝万圣节 各种暂停服务 没人的情况下等待二十分钟 后边的一个叔叔等待...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>249135456</td>\n",
       "      <td>微博</td>\n",
       "      <td>2018-09-28 10:31:29</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>工商银行的服务真是稀烂！不是财大气粗吗？从工作人员的业务熟悉度到业务平台系统都是渣渣！</td>\n",
       "      <td>工商银行的服务真是稀烂！不是财大气粗吗？从工作人员的业务熟悉度到业务平台系统都是渣渣！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>263284185</td>\n",
       "      <td>微信</td>\n",
       "      <td>2018-10-17 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>老牌长租公寓也摊事儿！雷军等明星投资人加持却也难逃一劫，年内已有5家爆雷</td>\n",
       "      <td>(图片)\\n\\n(图片)\\n\\n长租公寓又“摊上事儿”了。\\n\\n上海老牌长租公寓  寓见...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>269162185</td>\n",
       "      <td>微博</td>\n",
       "      <td>2018-11-06 20:42:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>不得不表扬下@招商银行信用卡 了，前几天在...</td>\n",
       "      <td>不得不表扬下\\n@招商银行信用卡\\n 了，前几天在苏格兰玩儿弄丢了卡，发现可以直接打开手机...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id group_id         publishtime  gather_type  tendency  \\\n",
       "0  267289612       微博 2018-10-31 12:11:44            1        -1   \n",
       "1  266932412       微博 2018-10-30 11:46:06            1        -1   \n",
       "2  249135456       微博 2018-09-28 10:31:29            1        -1   \n",
       "3  263284185       微信 2018-10-17 00:00:00            1        -1   \n",
       "4  269162185       微博 2018-11-06 20:42:00            1        -1   \n",
       "\n",
       "                                               title  \\\n",
       "0  24号没叫取了28号给我 26号后直接跳到了32号 @中国工商银行 麻烦请加强下底层工作人员...   \n",
       "1  #魔法万圣节# 在建行庆祝万圣节 各种暂停服务 没人的情况下等待二十分钟 后边的一个叔叔等待...   \n",
       "2        工商银行的服务真是稀烂！不是财大气粗吗？从工作人员的业务熟悉度到业务平台系统都是渣渣！   \n",
       "3               老牌长租公寓也摊事儿！雷军等明星投资人加持却也难逃一劫，年内已有5家爆雷   \n",
       "4                           不得不表扬下@招商银行信用卡 了，前几天在...   \n",
       "\n",
       "                                             content  \n",
       "0  24号没叫取了28号给我\\n26号后直接跳到了32号\\n@中国工商银行 麻烦请加强下底层工作...  \n",
       "1  #魔法万圣节# 在建行庆祝万圣节 各种暂停服务 没人的情况下等待二十分钟 后边的一个叔叔等待...  \n",
       "2        工商银行的服务真是稀烂！不是财大气粗吗？从工作人员的业务熟悉度到业务平台系统都是渣渣！  \n",
       "3   (图片)\\n\\n(图片)\\n\\n长租公寓又“摊上事儿”了。\\n\\n上海老牌长租公寓  寓见...  \n",
       "4   不得不表扬下\\n@招商银行信用卡\\n 了，前几天在苏格兰玩儿弄丢了卡，发现可以直接打开手机...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 人工补录\n",
    "sql_one_day = \"select t1.id, t1.group_id, t1.publishtime as publishtime, t1.gather_type, \\\n",
    "                    t1.sen as tendency, t1.title,t2.text as content \\\n",
    "                    from elint_web_docinfo t1, wise_web_docinfo_text t2 \\\n",
    "                        where t1.id=t2.doc_id \\\n",
    "                              and t1.publishtime >= '{0} 00:00:00' \\\n",
    "                              and t1.publishtime <= '{1} 23:59:59' \\\n",
    "                              and t1.gather_type in (1,3) \\\n",
    "                            group by t1.titlehash\".format('2018-09-01', '2018-12-03')\n",
    "# titlehash 去重后\n",
    "human_additional = pd.read_sql(sql_one_day, engine) \n",
    "human_additional['group_id'] = human_additional['group_id'].apply(lambda x:group_dict[str(x)])\n",
    "print('title 去重前：', human_additional.shape)\n",
    "human_additional = human_additional.drop_duplicates(subset = 'title')\n",
    "print('title 去重后：', human_additional.shape)  \n",
    "human_additional = human_additional.drop_duplicates(subset = ['content'])\n",
    "print('content 去重后：', human_additional.shape)  \n",
    "human_additional = human_additional.dropna(subset = ['title'], axis = 0)\n",
    "print('title 去空值后：', human_additional.shape) \n",
    "human_additional.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:41:39.411432Z",
     "start_time": "2018-12-04T01:39:59.952744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "消费服务      2366\n",
      "行业         290\n",
      "噪音         252\n",
      "资本市场       131\n",
      "监管         103\n",
      "公司内部管理     101\n",
      "产品销售        80\n",
      "其他相关报道      11\n",
      "Name: predict_label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>publishtime</th>\n",
       "      <th>gather_type</th>\n",
       "      <th>tendency</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>predict_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>267289612</td>\n",
       "      <td>微博</td>\n",
       "      <td>2018-10-31 12:11:44</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>24号没叫取了28号给我 26号后直接跳到了32号 @中国工商银行 麻烦请加强下底层工作人员...</td>\n",
       "      <td>24号没叫取了28号给我\\n26号后直接跳到了32号\\n@中国工商银行 麻烦请加强下底层工作...</td>\n",
       "      <td>消费服务</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>266932412</td>\n",
       "      <td>微博</td>\n",
       "      <td>2018-10-30 11:46:06</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>#魔法万圣节# 在建行庆祝万圣节 各种暂停服务 没人的情况下等待二十分钟 后边的一个叔叔等待...</td>\n",
       "      <td>#魔法万圣节# 在建行庆祝万圣节 各种暂停服务 没人的情况下等待二十分钟 后边的一个叔叔等待...</td>\n",
       "      <td>消费服务</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>249135456</td>\n",
       "      <td>微博</td>\n",
       "      <td>2018-09-28 10:31:29</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>工商银行的服务真是稀烂！不是财大气粗吗？从工作人员的业务熟悉度到业务平台系统都是渣渣！</td>\n",
       "      <td>工商银行的服务真是稀烂！不是财大气粗吗？从工作人员的业务熟悉度到业务平台系统都是渣渣！</td>\n",
       "      <td>消费服务</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>263284185</td>\n",
       "      <td>微信</td>\n",
       "      <td>2018-10-17 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>老牌长租公寓也摊事儿！雷军等明星投资人加持却也难逃一劫，年内已有5家爆雷</td>\n",
       "      <td>(图片)\\n\\n(图片)\\n\\n长租公寓又“摊上事儿”了。\\n\\n上海老牌长租公寓  寓见...</td>\n",
       "      <td>行业</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>269162185</td>\n",
       "      <td>微博</td>\n",
       "      <td>2018-11-06 20:42:00</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>不得不表扬下@招商银行信用卡 了，前几天在...</td>\n",
       "      <td>不得不表扬下\\n@招商银行信用卡\\n 了，前几天在苏格兰玩儿弄丢了卡，发现可以直接打开手机...</td>\n",
       "      <td>消费服务</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id group_id         publishtime  gather_type  tendency label  \\\n",
       "0  267289612       微博 2018-10-31 12:11:44            1        -1         \n",
       "1  266932412       微博 2018-10-30 11:46:06            1        -1         \n",
       "2  249135456       微博 2018-09-28 10:31:29            1        -1         \n",
       "3  263284185       微信 2018-10-17 00:00:00            1        -1         \n",
       "4  269162185       微博 2018-11-06 20:42:00            1        -1         \n",
       "\n",
       "                                               title  \\\n",
       "0  24号没叫取了28号给我 26号后直接跳到了32号 @中国工商银行 麻烦请加强下底层工作人员...   \n",
       "1  #魔法万圣节# 在建行庆祝万圣节 各种暂停服务 没人的情况下等待二十分钟 后边的一个叔叔等待...   \n",
       "2        工商银行的服务真是稀烂！不是财大气粗吗？从工作人员的业务熟悉度到业务平台系统都是渣渣！   \n",
       "3               老牌长租公寓也摊事儿！雷军等明星投资人加持却也难逃一劫，年内已有5家爆雷   \n",
       "4                           不得不表扬下@招商银行信用卡 了，前几天在...   \n",
       "\n",
       "                                             content predict_label  \n",
       "0  24号没叫取了28号给我\\n26号后直接跳到了32号\\n@中国工商银行 麻烦请加强下底层工作...          消费服务  \n",
       "1  #魔法万圣节# 在建行庆祝万圣节 各种暂停服务 没人的情况下等待二十分钟 后边的一个叔叔等待...          消费服务  \n",
       "2        工商银行的服务真是稀烂！不是财大气粗吗？从工作人员的业务熟悉度到业务平台系统都是渣渣！          消费服务  \n",
       "3   (图片)\\n\\n(图片)\\n\\n长租公寓又“摊上事儿”了。\\n\\n上海老牌长租公寓  寓见...            行业  \n",
       "4   不得不表扬下\\n@招商银行信用卡\\n 了，前几天在苏格兰玩儿弄丢了卡，发现可以直接打开手机...          消费服务  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_additional['title'] = human_additional['title'].astype(str) \n",
    "human_additional['content'] = human_additional['content'].astype(str)\n",
    "data = {\"record\":human_additional.loc[:,['id', 'title' ,'content']].to_dict(orient = 'records')}\n",
    "url = \"http://47.93.77.19:6001/judge_correlation_yjh\"\n",
    "col_name = 'sec'\n",
    "parse_data, elapsed_time = get_server_res(data, url, col_name)\n",
    "parse_data.columns = ['id', 'predict_label']\n",
    "human_additional = pd.merge(human_additional, parse_data, on = 'id', how = 'left')\n",
    "human_additional['predict_label'] = human_additional['predict_label'].apply(lambda x:class_name_dict[x])\n",
    "human_additional.insert(5, 'label', '')\n",
    "print(human_additional['predict_label'].value_counts())\n",
    "human_additional.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:41:41.291540Z",
     "start_time": "2018-12-04T01:41:39.545440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbrc_result_class/result/补录_银监会（旧）_class_predict_mysql_20181203(0901-1203).xlsx\n",
      "消费服务      2366\n",
      "行业         290\n",
      "噪音         252\n",
      "资本市场       131\n",
      "监管         103\n",
      "公司内部管理     101\n",
      "产品销售        80\n",
      "其他相关报道      11\n",
      "Name: predict_label, dtype: int64\n",
      "\n",
      "predict_label  产品销售  公司内部管理  其他相关报道   噪音  消费服务   监管   行业  资本市场   All\n",
      "group_id                                                            \n",
      "博客                0       0       0    0     1    0    0     0     1\n",
      "微信                0       3       0    2     5    4   12     6    32\n",
      "微博               76       3       6  153  2282    4    9     4  2537\n",
      "新闻                2      86       4   64    23   61  165    63   468\n",
      "新闻客户端             0       2       0    2     0    4    1     2    11\n",
      "纸媒                0       5       1   25     7   30  103    56   227\n",
      "论坛                2       2       0    6    48    0    0     0    58\n",
      "All              80     101      11  252  2366  103  290   131  3334\n"
     ]
    }
   ],
   "source": [
    "fea_filename = 'cbrc_result_class/result/补录_银监会（旧）_class_predict_mysql_20181203(0901-1203).xlsx'\n",
    "print(fea_filename)\n",
    "\n",
    "sel_col = ['噪音', '消费服务', '公司内部管理', '监管',\n",
    "           '行业', '资本市场', '其他相关报道','产品销售','交通','环保']\n",
    "sel_data = human_additional[human_additional['predict_label'].isin(sel_col)]\n",
    "print(sel_data['predict_label'].value_counts())\n",
    "print()\n",
    "\n",
    "c_data = pd.DataFrame()\n",
    "with pd.ExcelWriter(fea_filename) as writer:\n",
    "    for label in sel_data['predict_label'].unique():\n",
    "        tmp_data = sel_data[sel_data['predict_label'] == label]\n",
    "        N = tmp_data.shape[0]            \n",
    "        save_data = tmp_data.sample(n = N, axis = 0, random_state=42)\n",
    "        save_data.to_excel(writer,label, index = False)\n",
    "        c_data = pd.concat([c_data, save_data], axis = 0)\n",
    "    print(c_data.pivot_table(index = ['group_id'], \n",
    "                                columns = ['predict_label'], \n",
    "                                values = 'title', aggfunc=len, \n",
    "                                fill_value=0, margins=True))      \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T01:41:42.656618Z",
     "start_time": "2018-12-04T01:41:41.428548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbrc_result_tendency/result/补录_银监会（旧）_tendency_predict_mysql_20181204(0901-1203).xlsx\n",
      "-1    2892\n",
      " 0     345\n",
      " 1      97\n",
      "Name: tendency, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "fea_filename = 'cbrc_result_tendency/result/补录_银监会（旧）_tendency_predict_mysql_20181204(0901-1203).xlsx'\n",
    "print(fea_filename)\n",
    "print(human_additional['tendency'].value_counts())\n",
    "\n",
    "with pd.ExcelWriter(fea_filename) as writer:\n",
    "    for tendency in human_additional['tendency'].unique():\n",
    "        sel_data = human_additional[human_additional['tendency'] == tendency]    \n",
    "        t_n = sel_data.shape[0]        \n",
    "        tmp_data = sel_data.sample(n = t_n, axis = 0, random_state=3)\n",
    "        tmp_data.to_excel(writer,str(tendency), index = False)           \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 本地模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 八分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T06:08:55.607050Z",
     "start_time": "2018-10-08T06:08:53.117234Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "pipeline_old = joblib.load( \"model/cbrc_8classifier_1015.pkl.z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T06:18:52.561354Z",
     "start_time": "2018-10-08T06:08:56.797702Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data['title_content'] = combined_data['title'].astype(str) + '。' + combined_data['content'].astype(str)\n",
    "title_content = pre_cor_cbrc.handle_contents(combined_data['title_content'].tolist())\n",
    "print(len(title_content))\n",
    "\n",
    "local_label = pipeline_old.predict(title_content)\n",
    "local_proba = pipeline_old.predict_proba(title_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T06:18:53.780509Z",
     "start_time": "2018-10-08T06:18:53.751505Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data['local_label'] = local_label\n",
    "combined_data['local_proba'] = local_proba.max(axis = 1)\n",
    "combined_data['local_label'] = combined_data['local_label'].apply(lambda x:class_name_dict[x])\n",
    "print(combined_data.shape)\n",
    "combined_data.iloc[:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线上线下一致性: mysql 与 local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T06:18:57.152437Z",
     "start_time": "2018-10-08T06:18:55.000164Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data['R_W'] = combined_data.apply(lambda x: 'Right' if x['local_label'] == x['predict_label'] else 'Wrong', axis = 1)\n",
    "print(combined_data[combined_data['R_W'] == 'Right'].shape[0]/combined_data.shape[0])\n",
    "print(combined_data['R_W'].value_counts())\n",
    "combined_data[combined_data['R_W'] == 'Wrong'].pivot_table(index = ['local_label'], columns = ['predict_label'], \n",
    "                                                            aggfunc = [len], values = ['urlhash'], \n",
    "                                                            fill_value = 0, margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线上线下一致性: online 与 local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T06:18:58.463103Z",
     "start_time": "2018-10-08T06:18:58.420598Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data['id'] = range(combined_data.shape[0])\n",
    "combined_data['title'] = combined_data['title'].astype(str) \n",
    "combined_data['content'] = combined_data['content'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T06:49:05.543073Z",
     "start_time": "2018-10-08T06:18:59.725264Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {\"record\":combined_data.loc[:,['id', 'title' ,'content']].to_dict(orient = 'records')}\n",
    "url = \"http://47.93.77.19:6001/judge_correlation_yjh\"\n",
    "col_name = 'sec'\n",
    "parse_data = get_server_res_yjh(data, url, col_name)\n",
    "parse_data.columns = ['id', 'online_label']\n",
    "parse_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T06:49:09.341056Z",
     "start_time": "2018-10-08T06:49:06.973255Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data = pd.merge(combined_data, parse_data, on  = 'id')\n",
    "print(combined_data.shape)\n",
    "combined_data['online_label'] = combined_data['online_label'].apply(lambda x:class_name_dict[x])\n",
    "combined_data['O_R_W'] = combined_data.apply(lambda x: 'Right' if x['local_label'] == x['online_label'] else 'Wrong', axis = 1)\n",
    "print(combined_data[combined_data['O_R_W'] == 'Right'].shape[0]/combined_data.shape[0])\n",
    "print(combined_data['O_R_W'].value_counts())\n",
    "combined_data[combined_data['O_R_W'] == 'Wrong'].pivot_table(index = ['local_label'], columns = ['online_label'], \n",
    "                                                            aggfunc = [len], values = ['urlhash'], \n",
    "                                                            fill_value = 0, margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线上线下一致性: online 与 mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T06:49:13.415073Z",
     "start_time": "2018-10-08T06:49:10.973263Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data['O_R_W'] = combined_data.apply(lambda x: 'Right' if x['predict_label'] == x['online_label'] else 'Wrong', axis = 1)\n",
    "print(combined_data[combined_data['O_R_W'] == 'Right'].shape[0]/combined_data.shape[0])\n",
    "print(combined_data['O_R_W'].value_counts())\n",
    "combined_data[combined_data['O_R_W'] == 'Wrong'].pivot_table(index = ['predict_label'], columns = ['online_label'], \n",
    "                                                            aggfunc = [len], values = ['urlhash'], \n",
    "                                                            fill_value = 0, margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 倾向性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T06:08:55.607050Z",
     "start_time": "2018-10-08T06:08:53.117234Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "pipeline_old = joblib.load( \"model/cbrc_8classifier_1015.pkl.z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T06:18:52.561354Z",
     "start_time": "2018-10-08T06:08:56.797702Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data['title_content'] = combined_data['title'].astype(str) + '。' + combined_data['content'].astype(str)\n",
    "title_content = pre_cor_cbrc.handle_contents(combined_data['title_content'].tolist())\n",
    "print(len(title_content))\n",
    "\n",
    "local_label = pipeline_old.predict(title_content)\n",
    "local_proba = pipeline_old.predict_proba(title_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T06:18:53.780509Z",
     "start_time": "2018-10-08T06:18:53.751505Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data['local_label'] = local_label\n",
    "combined_data['local_proba'] = local_proba.max(axis = 1)\n",
    "combined_data['local_label'] = combined_data['local_label'].apply(lambda x:class_name_dict[x])\n",
    "print(combined_data.shape)\n",
    "combined_data.iloc[:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线上线下一致性: mysql 与 local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T06:18:57.152437Z",
     "start_time": "2018-10-08T06:18:55.000164Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data['R_W'] = combined_data.apply(lambda x: 'Right' if x['local_label'] == x['predict_label'] else 'Wrong', axis = 1)\n",
    "print(combined_data[combined_data['R_W'] == 'Right'].shape[0]/combined_data.shape[0])\n",
    "print(combined_data['R_W'].value_counts())\n",
    "combined_data[combined_data['R_W'] == 'Wrong'].pivot_table(index = ['local_label'], columns = ['predict_label'], \n",
    "                                                            aggfunc = [len], values = ['urlhash'], \n",
    "                                                            fill_value = 0, margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线上线下一致性: online 与 local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T06:18:58.463103Z",
     "start_time": "2018-10-08T06:18:58.420598Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data['id'] = range(combined_data.shape[0])\n",
    "combined_data['title'] = combined_data['title'].astype(str) \n",
    "combined_data['content'] = combined_data['content'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T06:49:05.543073Z",
     "start_time": "2018-10-08T06:18:59.725264Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {\"record\":combined_data.loc[:,['id', 'title' ,'content']].to_dict(orient = 'records')}\n",
    "url = \"http://47.93.77.19:6001/judge_correlation_yjh\"\n",
    "col_name = 'sec'\n",
    "parse_data = get_server_res_yjh(data, url, col_name)\n",
    "parse_data.columns = ['id', 'online_label']\n",
    "parse_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T06:49:09.341056Z",
     "start_time": "2018-10-08T06:49:06.973255Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data = pd.merge(combined_data, parse_data, on  = 'id')\n",
    "print(combined_data.shape)\n",
    "combined_data['online_label'] = combined_data['online_label'].apply(lambda x:class_name_dict[x])\n",
    "combined_data['O_R_W'] = combined_data.apply(lambda x: 'Right' if x['local_label'] == x['online_label'] else 'Wrong', axis = 1)\n",
    "print(combined_data[combined_data['O_R_W'] == 'Right'].shape[0]/combined_data.shape[0])\n",
    "print(combined_data['O_R_W'].value_counts())\n",
    "combined_data[combined_data['O_R_W'] == 'Wrong'].pivot_table(index = ['local_label'], columns = ['online_label'], \n",
    "                                                            aggfunc = [len], values = ['urlhash'], \n",
    "                                                            fill_value = 0, margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线上线下一致性: online 与 mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T06:49:13.415073Z",
     "start_time": "2018-10-08T06:49:10.973263Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data['O_R_W'] = combined_data.apply(lambda x: 'Right' if x['predict_label'] == x['online_label'] else 'Wrong', axis = 1)\n",
    "print(combined_data[combined_data['O_R_W'] == 'Right'].shape[0]/combined_data.shape[0])\n",
    "print(combined_data['O_R_W'].value_counts())\n",
    "combined_data[combined_data['O_R_W'] == 'Wrong'].pivot_table(index = ['predict_label'], columns = ['online_label'], \n",
    "                                                            aggfunc = [len], values = ['urlhash'], \n",
    "                                                            fill_value = 0, margins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T03:51:49.646007Z",
     "start_time": "2018-09-11T03:51:48.860962Z"
    },
    "collapsed": true
   },
   "source": [
    "# 银行业与保险业--新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## mysql 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T01:40:04.473638Z",
     "start_time": "2018-12-03T01:39:53.574014Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = specific_func.get_engine('cbirc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T05:57:26.937896Z",
     "start_time": "2018-12-03T05:57:26.926895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018-09-02', '2018-09-03', '2018-09-04', '2018-09-05', '2018-09-06', '2018-09-07', '2018-09-08', '2018-09-09', '2018-09-10', '2018-09-11', '2018-09-12', '2018-09-13', '2018-09-14', '2018-09-15', '2018-09-16', '2018-09-17', '2018-09-18', '2018-09-19', '2018-09-20', '2018-09-21', '2018-09-22', '2018-09-23', '2018-09-24', '2018-09-25', '2018-09-26', '2018-09-27', '2018-09-28', '2018-09-29', '2018-09-30', '2018-10-01', '2018-10-02', '2018-10-03', '2018-10-04', '2018-10-05', '2018-10-06', '2018-10-07', '2018-10-08', '2018-10-09', '2018-10-10', '2018-10-11', '2018-10-12', '2018-10-13', '2018-10-14', '2018-10-15', '2018-10-16', '2018-10-17', '2018-10-18', '2018-10-19', '2018-10-20', '2018-10-21', '2018-10-22', '2018-10-23', '2018-10-24', '2018-10-25', '2018-10-26', '2018-10-27', '2018-10-28', '2018-10-29', '2018-10-30', '2018-10-31', '2018-11-01', '2018-11-02', '2018-11-03', '2018-11-04', '2018-11-05', '2018-11-06', '2018-11-07', '2018-11-08', '2018-11-09', '2018-11-10', '2018-11-11', '2018-11-12', '2018-11-13', '2018-11-14', '2018-11-15', '2018-11-16', '2018-11-17', '2018-11-18', '2018-11-19', '2018-11-20', '2018-11-21', '2018-11-22', '2018-11-23', '2018-11-24', '2018-11-25', '2018-11-26', '2018-11-27', '2018-11-28', '2018-11-29', '2018-11-30', '2018-12-01', '2018-12-02', '2018-12-03']\n"
     ]
    }
   ],
   "source": [
    "# day_select = '2018-09-09'\n",
    "day_list = get_day_list('2018-09-01', '2018-12-03')\n",
    "print(day_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 系统采集\n",
    "- gather_type 0-系统采集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:16:27.564606Z",
     "start_time": "2018-11-27T02:56:25.798869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取 中国人保 数据...\n",
      "\n",
      "-- day_select:  2018-11-21\n",
      "label 去重前： (25169, 10)\n",
      "label 去重后： (25169, 10)\n",
      "label 去空值后： (25169, 10)\n",
      "content 去重前： (25152, 2)\n",
      "content 去重后： (24705, 2)\n",
      "content 去空值后： (24705, 2)\n",
      "(24705, 11)\n",
      "                len                                                        \n",
      "              title                                                        \n",
      "predict_label    交通 产品销售 公司内部管理 其他相关报道     噪音 消费服务  环保  监管   行业 资本市场    All\n",
      "tendency type                                                              \n",
      "-1       中国人保  2037    3     46     14   5614   43   2   7   71  166   8003\n",
      "0        中国人保  2982   77    101    164  12715  129  22  48  215  249  16702\n",
      "All            5019   80    147    178  18329  172  24  55  286  415  24705\n",
      "\n",
      "-- day_select:  2018-11-22\n",
      "label 去重前： (9139, 10)\n",
      "label 去重后： (9139, 10)\n",
      "label 去空值后： (9139, 10)\n",
      "content 去重前： (9139, 2)\n",
      "content 去重后： (9067, 2)\n",
      "content 去空值后： (9067, 2)\n",
      "(9067, 11)\n",
      "                len                                                      \n",
      "              title                                                      \n",
      "predict_label    交通 产品销售 公司内部管理 其他相关报道    噪音 消费服务  环保  监管   行业 资本市场   All\n",
      "tendency type                                                            \n",
      "-1       中国人保  1797    2     18     10  1500   39   4  17   90   50  3527\n",
      "0        中国人保  1377   62     68     71  3544  114  27  15  138  124  5540\n",
      "All            3174   64     86     81  5044  153  31  32  228  174  9067\n",
      "\n",
      "-- day_select:  2018-11-23\n",
      "label 去重前： (8928, 10)\n",
      "label 去重后： (8927, 10)\n",
      "label 去空值后： (8927, 10)\n",
      "content 去重前： (8925, 2)\n",
      "content 去重后： (8711, 2)\n",
      "content 去空值后： (8711, 2)\n",
      "(8711, 11)\n",
      "                len                                                      \n",
      "              title                                                      \n",
      "predict_label    交通 产品销售 公司内部管理 其他相关报道    噪音 消费服务  环保  监管   行业 资本市场   All\n",
      "tendency type                                                            \n",
      "-1       中国人保  1294    1     49      4  1466   44   1  17   44  248  3168\n",
      "0        中国人保  1290   36     62     80  3345  104  10  22  129  465  5543\n",
      "All            2584   37    111     84  4811  148  11  39  173  713  8711\n",
      "\n",
      "-- day_select:  2018-11-24\n",
      "label 去重前： (5541, 10)\n",
      "label 去重后： (5541, 10)\n",
      "label 去空值后： (5541, 10)\n",
      "content 去重前： (5537, 2)\n",
      "content 去重后： (5266, 2)\n",
      "content 去空值后： (5266, 2)\n",
      "(5266, 11)\n",
      "                len                                                    \n",
      "              title                                                    \n",
      "predict_label    交通 产品销售 公司内部管理 其他相关报道    噪音 消费服务 环保  监管  行业 资本市场   All\n",
      "tendency type                                                          \n",
      "-1       中国人保   809    0     11      1  1059   23  2   4  22   64  1995\n",
      "0        中国人保   884   33     25     27  2030   42  6   8  57  159  3271\n",
      "All            1693   33     36     28  3089   65  8  12  79  223  5266\n",
      "\n",
      "-- day_select:  2018-11-25\n",
      "label 去重前： (3366, 10)\n",
      "label 去重后： (3366, 10)\n",
      "label 去空值后： (3366, 10)\n",
      "content 去重前： (3363, 2)\n",
      "content 去重后： (3312, 2)\n",
      "content 去空值后： (3312, 2)\n",
      "(3312, 11)\n",
      "                len                                                   \n",
      "              title                                                   \n",
      "predict_label    交通 产品销售 公司内部管理 其他相关报道    噪音 消费服务 环保 监管  行业 资本市场   All\n",
      "tendency type                                                         \n",
      "-1       中国人保   525    0     11      2   709   12  1  3  15   46  1324\n",
      "0        中国人保   438   20     14     21  1276   19  3  5  28  164  1988\n",
      "All             963   20     25     23  1985   31  4  8  43  210  3312\n"
     ]
    }
   ],
   "source": [
    "types = 5\n",
    "gather_types = '采集'\n",
    "print(\"获取 %s 数据...\"%(proj_name_dict[types]))\n",
    "for day_select in day_list:\n",
    "    print()\n",
    "    print('-- day_select: ', day_select)\n",
    "    \n",
    "    # 获取八分类\n",
    "    if types in [1,2]:\n",
    "        sql_label = '''\n",
    "        SELECT \n",
    "            t1.type, t1.urlhash, t3.title, t3.group_id, t3.publishtime,\n",
    "            t1.traffic_id, t2.sen as tendency, t2.gather_type\n",
    "        FROM\n",
    "            cbrc_circ.db_classify_traffic_docinfo t1\n",
    "                LEFT JOIN\n",
    "            cbrc_circ.db_docinfo_trade t2 ON t1.urlhash = t2.urlhash\n",
    "                LEFT JOIN\n",
    "            cbrc_circ.db_docinfo t3 ON t2.urlhash = t3.urlhash\n",
    "        WHERE\n",
    "            t3.publishtime >= '{0} 07:00:00'\n",
    "                AND t3.publishtime <= '{0} 16:00:00'\n",
    "                and t1.type = {1}\n",
    "                and t1.type = t2.type\n",
    "                and t2.gather_type = 0\n",
    "        group by t3.titlehash\n",
    "        '''.format(day_select, types)\n",
    "    elif types in [3,4,5]:\n",
    "        sql_label = '''\n",
    "        SELECT \n",
    "            t1.id, t1.type, t1.urlhash, t3.title, t3.group_id, t3.publishtime,\n",
    "            t1.traffic_id, t2.sen as tendency, t2.gather_type\n",
    "        FROM\n",
    "            cbrc_circ.db_classify_traffic_docinfo t1\n",
    "                LEFT JOIN\n",
    "            cbrc_circ.db_docinfo_trade t2 ON t1.urlhash = t2.urlhash\n",
    "                LEFT JOIN\n",
    "            cbrc_circ.db_docinfo t3 ON t2.urlhash = t3.urlhash\n",
    "        WHERE\n",
    "            t3.publishtime >= '{0} 00:00:00'\n",
    "                AND t3.publishtime <= '{0} 23:59:59'\n",
    "                and t1.type = {1}\n",
    "                and t1.type = t2.type\n",
    "                and t2.gather_type = 0\n",
    "        group by t3.titlehash\n",
    "        '''.format(day_select, types)        \n",
    "\n",
    "    cbirc_label = pd.read_sql(sql_label, engine)\n",
    "    cbirc_label['predict_label'] = cbirc_label['traffic_id'].apply(lambda x:class_name_dict[x])\n",
    "    cbirc_label['group_id'] = cbirc_label['group_id'].apply(lambda x:group_dict[str(x)])\n",
    "    cbirc_label['type'] = cbirc_label['type'].apply(lambda x:proj_name_dict[x])\n",
    "    cbirc_label['gather_type'] = cbirc_label['gather_type'].apply(lambda x:gather_type_name_dict[x])\n",
    "    print('label 去重前：', cbirc_label.shape)\n",
    "    cbirc_label = cbirc_label.drop_duplicates(subset = 'title')\n",
    "    print('label 去重后：', cbirc_label.shape)  \n",
    "    cbirc_label = cbirc_label.dropna(subset = ['title'], axis = 0)\n",
    "    print('label 去空值后：', cbirc_label.shape)  \n",
    "    \n",
    "    if cbirc_label['urlhash'].shape[0] != 0:\n",
    "        # 获取 content\n",
    "        url_l = cbirc_label['urlhash'].tolist()\n",
    "        if cbirc_label['urlhash'].shape[0] == 1:\n",
    "            url_l.append(url_l[0])\n",
    "        url_list = tuple(url_l)\n",
    "        sql_content = '''\n",
    "        SELECT \n",
    "            t1.urlhash, t1.text as content\n",
    "        FROM\n",
    "            cbrc_circ.db_docinfo_text t1\n",
    "        WHERE\n",
    "            t1.urlhash in {0}\n",
    "        '''.format(url_list)\n",
    "\n",
    "        cbirc_content = pd.read_sql(sql_content, engine)\n",
    "        print('content 去重前：', cbirc_content.shape)\n",
    "        cbirc_content = cbirc_content.drop_duplicates(subset = 'content')\n",
    "        print('content 去重后：', cbirc_content.shape)  \n",
    "        cbirc_content = cbirc_content.dropna(subset = ['content'], axis = 0)\n",
    "        print('content 去空值后：', cbirc_content.shape)  \n",
    "\n",
    "        cbirc_combined = pd.merge(cbirc_label, cbirc_content, on = 'urlhash', how = 'inner')\n",
    "        print(cbirc_combined.shape)\n",
    "        print(cbirc_combined.pivot_table(index = ['tendency', 'type'], columns = ['predict_label'], \n",
    "                                    aggfunc = [len], values = ['title'], \n",
    "                                    fill_value = 0, margins = True))    \n",
    "        cbirc_combined['label'] = ''\n",
    "        cbirc_combined = cbirc_combined[['id', 'gather_type', 'type', 'urlhash', 'predict_label', 'label', 'title', \n",
    "                                         'content', 'group_id', 'publishtime', 'tendency']]\n",
    "    #     fea_filename = 'cbirc_result/class/result/cbirc_class_predict_mysql_%s.xlsx'%day_select\n",
    "        fea_filename = 'cbirc_result/class/result/cbirc_class_predict_%s_types(%s)_%s.xlsx'%(gather_types, types, day_select)\n",
    "        cbirc_combined.to_excel(fea_filename, index = False)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T02:00:45.101792Z",
     "start_time": "2018-11-27T02:00:45.079791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gather_type</th>\n",
       "      <th>type</th>\n",
       "      <th>urlhash</th>\n",
       "      <th>predict_label</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>group_id</th>\n",
       "      <th>publishtime</th>\n",
       "      <th>tendency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, gather_type, type, urlhash, predict_label, label, title, content, group_id, publishtime, tendency]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combined_data[combined_data['predict_label'] == '交通'].to_excel('建行北分—交通.xlsx')\n",
    "cbirc_combined[cbirc_combined['predict_label'] == '交通']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 补录\n",
    "- gather_type 1-人工补录\n",
    "- gather_type 3-导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T06:01:58.047403Z",
     "start_time": "2018-12-03T06:01:49.252900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取 中国人保 数据...\n",
      "-- day_select:  2018-09-02\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-03\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-04\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-05\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-06\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-07\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-08\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-09\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-10\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-11\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-12\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-13\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-14\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-15\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-16\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-17\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-18\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-19\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-20\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-21\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-22\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-23\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-24\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-25\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-26\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-27\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-28\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-29\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-09-30\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-01\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-02\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-03\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-04\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-05\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-06\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-07\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-08\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-09\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-10\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-11\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-12\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-13\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-14\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-15\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-16\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-17\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-18\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-19\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-20\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-21\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-22\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-23\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-24\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-25\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-26\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-27\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-28\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-29\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-30\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-10-31\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-01\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-02\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-03\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-04\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-05\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-06\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-07\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-08\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-09\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-10\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-11\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-12\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-13\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-14\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-15\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-16\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-17\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-18\n",
      "label 去重前： (1, 9)\n",
      "label 去重后： (1, 9)\n",
      "label 去空值后： (1, 9)\n",
      "content 去重前： (1, 2)\n",
      "content 去重后： (1, 2)\n",
      "content 去空值后： (1, 2)\n",
      "(1, 10)\n",
      "                len    \n",
      "              title    \n",
      "predict_label    环保 All\n",
      "tendency type          \n",
      "-1       中国人保     1   1\n",
      "All               1   1\n",
      "-- day_select:  2018-11-19\n",
      "label 去重前： (6, 9)\n",
      "label 去重后： (6, 9)\n",
      "label 去空值后： (6, 9)\n",
      "content 去重前： (6, 2)\n",
      "content 去重后： (6, 2)\n",
      "content 去空值后： (6, 2)\n",
      "(6, 10)\n",
      "                len                        \n",
      "              title                        \n",
      "predict_label  产品销售 其他相关报道 消费服务 监管 资本市场 All\n",
      "tendency type                              \n",
      "-1       中国人保     0      0    0  1    0   1\n",
      "0        中国人保     1      1    1  1    1   5\n",
      "All               1      1    1  2    1   6\n",
      "-- day_select:  2018-11-20\n",
      "label 去重前： (5, 9)\n",
      "label 去重后： (5, 9)\n",
      "label 去空值后： (5, 9)\n",
      "content 去重前： (5, 2)\n",
      "content 去重后： (5, 2)\n",
      "content 去空值后： (5, 2)\n",
      "(5, 10)\n",
      "                len             \n",
      "              title             \n",
      "predict_label    噪音 环保 监管 行业 All\n",
      "tendency type                   \n",
      "-1       中国人保     2  0  0  0   2\n",
      "0        中国人保     0  1  1  1   3\n",
      "All               2  1  1  1   5\n",
      "-- day_select:  2018-11-21\n",
      "label 去重前： (6, 9)\n",
      "label 去重后： (6, 9)\n",
      "label 去空值后： (6, 9)\n",
      "content 去重前： (6, 2)\n",
      "content 去重后： (6, 2)\n",
      "content 去空值后： (6, 2)\n",
      "(6, 10)\n",
      "                len          \n",
      "              title          \n",
      "predict_label  产品销售 监管 行业 All\n",
      "tendency type                \n",
      "-1       中国人保     0  0  2   2\n",
      "0        中国人保     1  2  1   4\n",
      "All               1  2  3   6\n",
      "-- day_select:  2018-11-22\n",
      "label 去重前： (11, 9)\n",
      "label 去重后： (11, 9)\n",
      "label 去空值后： (11, 9)\n",
      "content 去重前： (11, 2)\n",
      "content 去重后： (11, 2)\n",
      "content 去空值后： (11, 2)\n",
      "(11, 10)\n",
      "                len                                \n",
      "              title                                \n",
      "predict_label    交通 公司内部管理 其他相关报道 消费服务 环保 监管 行业 All\n",
      "tendency type                                      \n",
      "-1       中国人保     0      0      0    0  3  0  1   4\n",
      "0        中国人保     1      1      1    1  0  1  2   7\n",
      "All               1      1      1    1  3  1  3  11\n",
      "-- day_select:  2018-11-23\n",
      "label 去重前： (8, 9)\n",
      "label 去重后： (8, 9)\n",
      "label 去空值后： (8, 9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content 去重前： (8, 2)\n",
      "content 去重后： (8, 2)\n",
      "content 去空值后： (8, 2)\n",
      "(8, 10)\n",
      "                len                 \n",
      "              title                 \n",
      "predict_label    交通 公司内部管理 环保 行业 All\n",
      "tendency type                       \n",
      "-1       中国人保     0      0  4  1   5\n",
      "0        中国人保     1      1  0  1   3\n",
      "All               1      1  4  2   8\n",
      "-- day_select:  2018-11-24\n",
      "label 去重前： (0, 9)\n",
      "label 去重后： (0, 9)\n",
      "label 去空值后： (0, 9)\n",
      "-- day_select:  2018-11-25\n",
      "label 去重前： (2, 9)\n",
      "label 去重后： (2, 9)\n",
      "label 去空值后： (2, 9)\n",
      "content 去重前： (2, 2)\n",
      "content 去重后： (2, 2)\n",
      "content 去空值后： (2, 2)\n",
      "(2, 10)\n",
      "                len       \n",
      "              title       \n",
      "predict_label    交通 环保 All\n",
      "tendency type             \n",
      "-1       中国人保     0  1   1\n",
      "0        中国人保     1  0   1\n",
      "All               1  1   2\n",
      "-- day_select:  2018-11-26\n",
      "label 去重前： (2, 9)\n",
      "label 去重后： (2, 9)\n",
      "label 去空值后： (2, 9)\n",
      "content 去重前： (2, 2)\n",
      "content 去重后： (2, 2)\n",
      "content 去空值后： (2, 2)\n",
      "(2, 10)\n",
      "                len       \n",
      "              title       \n",
      "predict_label    交通 行业 All\n",
      "tendency type             \n",
      "0        中国人保     1  1   2\n",
      "All               1  1   2\n",
      "-- day_select:  2018-11-27\n",
      "label 去重前： (7, 9)\n",
      "label 去重后： (7, 9)\n",
      "label 去空值后： (7, 9)\n",
      "content 去重前： (7, 2)\n",
      "content 去重后： (7, 2)\n",
      "content 去空值后： (7, 2)\n",
      "(7, 10)\n",
      "                len               \n",
      "              title               \n",
      "predict_label    交通 产品销售 环保 监管 All\n",
      "tendency type                     \n",
      "-1       中国人保     0    0  3  0   3\n",
      "0        中国人保     2    1  0  1   4\n",
      "All               2    1  3  1   7\n",
      "-- day_select:  2018-11-28\n",
      "label 去重前： (6, 9)\n",
      "label 去重后： (6, 9)\n",
      "label 去空值后： (6, 9)\n",
      "content 去重前： (6, 2)\n",
      "content 去重后： (6, 2)\n",
      "content 去空值后： (6, 2)\n",
      "(6, 10)\n",
      "                len             \n",
      "              title             \n",
      "predict_label    交通 环保 监管 行业 All\n",
      "tendency type                   \n",
      "-1       中国人保     0  2  1  0   3\n",
      "0        中国人保     1  0  1  1   3\n",
      "All               1  2  2  1   6\n",
      "-- day_select:  2018-11-29\n",
      "label 去重前： (8, 9)\n",
      "label 去重后： (8, 9)\n",
      "label 去空值后： (8, 9)\n",
      "content 去重前： (8, 2)\n",
      "content 去重后： (8, 2)\n",
      "content 去空值后： (8, 2)\n",
      "(8, 10)\n",
      "                len                  \n",
      "              title                  \n",
      "predict_label    噪音 消费服务 环保 监管 行业 All\n",
      "tendency type                        \n",
      "-1       中国人保     2    1  3  0  0   6\n",
      "0        中国人保     0    0  0  1  1   2\n",
      "All               2    1  3  1  1   8\n",
      "-- day_select:  2018-11-30\n",
      "label 去重前： (13, 9)\n",
      "label 去重后： (13, 9)\n",
      "label 去空值后： (13, 9)\n",
      "content 去重前： (13, 2)\n",
      "content 去重后： (13, 2)\n",
      "content 去空值后： (13, 2)\n",
      "(13, 10)\n",
      "                len                  \n",
      "              title                  \n",
      "predict_label  产品销售 噪音 消费服务 环保 行业 All\n",
      "tendency type                        \n",
      "-1       中国人保     0  5    1  2  0   8\n",
      "0        中国人保     1  1    0  0  3   5\n",
      "All               1  6    1  2  3  13\n",
      "-- day_select:  2018-12-01\n",
      "label 去重前： (3, 9)\n",
      "label 去重后： (3, 9)\n",
      "label 去空值后： (3, 9)\n",
      "content 去重前： (3, 2)\n",
      "content 去重后： (3, 2)\n",
      "content 去空值后： (3, 2)\n",
      "(3, 10)\n",
      "                 len          \n",
      "               title          \n",
      "predict_label 其他相关报道 监管 行业 All\n",
      "tendency type                 \n",
      "0        中国人保      1  1  1   3\n",
      "All                1  1  1   3\n",
      "-- day_select:  2018-12-02\n",
      "label 去重前： (3, 9)\n",
      "label 去重后： (3, 9)\n",
      "label 去空值后： (3, 9)\n",
      "content 去重前： (3, 2)\n",
      "content 去重后： (3, 2)\n",
      "content 去空值后： (3, 2)\n",
      "(3, 10)\n",
      "                len            \n",
      "              title            \n",
      "predict_label    交通 产品销售 行业 All\n",
      "tendency type                  \n",
      "0        中国人保     1    1  1   3\n",
      "All               1    1  1   3\n",
      "-- day_select:  2018-12-03\n",
      "label 去重前： (7, 9)\n",
      "label 去重后： (7, 9)\n",
      "label 去空值后： (7, 9)\n",
      "content 去重前： (7, 2)\n",
      "content 去重后： (7, 2)\n",
      "content 去空值后： (7, 2)\n",
      "(7, 10)\n",
      "                len                         \n",
      "              title                         \n",
      "predict_label  产品销售 公司内部管理 噪音 环保 监管 资本市场 All\n",
      "tendency type                               \n",
      "-1       中国人保     0      0  2  1  0    0   3\n",
      "0        中国人保     1      1  0  0  1    1   4\n",
      "All               1      1  2  1  1    1   7\n"
     ]
    }
   ],
   "source": [
    "types = 5\n",
    "gather_types = '补录'\n",
    "print(\"获取 %s 数据...\"%(proj_name_dict[types]))\n",
    "for day_select in day_list:\n",
    "    print('-- day_select: ', day_select)\n",
    "    \n",
    "    # 获取八分类\n",
    "    if types in [1,2]:\n",
    "        sql_label = '''\n",
    "        SELECT \n",
    "            t1.type, t1.urlhash, t3.title, t3.group_id, t3.publishtime,\n",
    "            t1.traffic_id, t2.sen as tendency, t2.gather_type\n",
    "        FROM\n",
    "            cbrc_circ.db_classify_traffic_docinfo t1\n",
    "                LEFT JOIN\n",
    "            cbrc_circ.db_docinfo_trade t2 ON t1.urlhash = t2.urlhash\n",
    "                LEFT JOIN\n",
    "            cbrc_circ.db_docinfo t3 ON t2.urlhash = t3.urlhash\n",
    "        WHERE\n",
    "            t3.publishtime >= '{0} 00:00:00'\n",
    "                AND t3.publishtime <= '{0} 23:59:59'\n",
    "                and t1.type = {1}\n",
    "                and t1.type = t2.type\n",
    "                and t2.gather_type in (1,3)\n",
    "        group by t3.titlehash\n",
    "        '''.format(day_select, types)\n",
    "    elif types in [3,4,5]:\n",
    "        sql_label = '''\n",
    "        SELECT \n",
    "            t1.type, t1.urlhash, t3.title, t3.group_id, t3.publishtime,\n",
    "            t1.traffic_id, t2.sen as tendency, t2.gather_type\n",
    "        FROM\n",
    "            cbrc_circ.db_classify_traffic_docinfo t1\n",
    "                LEFT JOIN\n",
    "            cbrc_circ.db_docinfo_trade t2 ON t1.urlhash = t2.urlhash\n",
    "                LEFT JOIN\n",
    "            cbrc_circ.db_docinfo t3 ON t2.urlhash = t3.urlhash\n",
    "        WHERE\n",
    "            t3.publishtime >= '{0} 00:00:00'\n",
    "                AND t3.publishtime <= '{0} 23:59:59'\n",
    "                and t1.type = {1}\n",
    "                and t1.type = t2.type\n",
    "                and t2.gather_type in (1,3)\n",
    "        group by t3.titlehash\n",
    "        '''.format(day_select, types)        \n",
    "\n",
    "    cbirc_label = pd.read_sql(sql_label, engine)\n",
    "    cbirc_label['predict_label'] = cbirc_label['traffic_id'].apply(lambda x:class_name_dict[x])\n",
    "    cbirc_label['group_id'] = cbirc_label['group_id'].apply(lambda x:group_dict[str(x)])\n",
    "    cbirc_label['type'] = cbirc_label['type'].apply(lambda x:proj_name_dict[x])\n",
    "    cbirc_label['gather_type'] = cbirc_label['gather_type'].apply(lambda x:gather_type_name_dict[x])\n",
    "    print('label 去重前：', cbirc_label.shape)\n",
    "    cbirc_label = cbirc_label.drop_duplicates(subset = 'title')\n",
    "    print('label 去重后：', cbirc_label.shape)  \n",
    "    cbirc_label = cbirc_label.dropna(subset = ['title'], axis = 0)\n",
    "    print('label 去空值后：', cbirc_label.shape)  \n",
    "        \n",
    "    if cbirc_label['urlhash'].shape[0] != 0:\n",
    "        # 获取 content\n",
    "        url_l = cbirc_label['urlhash'].tolist()\n",
    "        if cbirc_label['urlhash'].shape[0] == 1:\n",
    "            url_l.append(url_l[0])\n",
    "        url_list = tuple(url_l)\n",
    "        sql_content = '''\n",
    "        SELECT \n",
    "            t1.urlhash, t1.text as content\n",
    "        FROM\n",
    "            cbrc_circ.db_docinfo_text t1\n",
    "        WHERE\n",
    "            t1.urlhash in {0}\n",
    "        '''.format(url_list)\n",
    "        cbirc_content = pd.read_sql(sql_content, engine)\n",
    "        print('content 去重前：', cbirc_content.shape)\n",
    "        cbirc_content = cbirc_content.drop_duplicates(subset = 'content')\n",
    "        print('content 去重后：', cbirc_content.shape)  \n",
    "        cbirc_content = cbirc_content.dropna(subset = ['content'], axis = 0)\n",
    "        print('content 去空值后：', cbirc_content.shape)  \n",
    "\n",
    "        cbirc_combined = pd.merge(cbirc_label, cbirc_content, on = 'urlhash', how = 'inner')\n",
    "        print(cbirc_combined.shape)\n",
    "        print(cbirc_combined.pivot_table(index = ['tendency', 'type'], columns = ['predict_label'], \n",
    "                                    aggfunc = [len], values = ['title'], \n",
    "                                    fill_value = 0, margins = True))    \n",
    "        cbirc_combined['label'] = ''\n",
    "        cbirc_combined = cbirc_combined[['gather_type', 'type', 'urlhash', 'predict_label', 'label', 'title', \n",
    "                                         'content', 'group_id', 'publishtime', 'tendency']]\n",
    "    #     fea_filename = 'cbirc_result/class/result/cbirc_class_predict_mysql_%s.xlsx'%day_select\n",
    "        fea_filename = 'cbirc_result/class/result/cbirc_class_predict_%s_types(%s)_%s.xlsx'%(gather_types, types, day_select)\n",
    "        cbirc_combined.to_excel(fea_filename, index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 八分类数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 合并 & 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T02:54:33.085227Z",
     "start_time": "2018-12-03T02:54:33.081227Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# types = 3\n",
    "# gather_types = '采集'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T06:02:08.521002Z",
     "start_time": "2018-12-03T06:02:08.194983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbirc_result/class/result/cbirc_class_predict_补录_types(5)_2018-11-18.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_补录_types(5)_2018-11-19.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_补录_types(5)_2018-11-20.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_补录_types(5)_2018-11-21.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_补录_types(5)_2018-11-22.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_补录_types(5)_2018-11-23.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_补录_types(5)_2018-11-24.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_补录_types(5)_2018-11-25.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_补录_types(5)_2018-11-26.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_补录_types(5)_2018-11-27.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_补录_types(5)_2018-11-28.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_补录_types(5)_2018-11-29.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_补录_types(5)_2018-11-30.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_补录_types(5)_2018-12-01.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_补录_types(5)_2018-12-02.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_补录_types(5)_2018-12-03.xlsx\n",
      "(89, 10)\n",
      "                len                                                 \n",
      "              title                                                 \n",
      "predict_label    交通 产品销售 公司内部管理 其他相关报道  噪音 消费服务  环保  监管  行业 资本市场 All\n",
      "type                                                                \n",
      "中国人保              8    6      4      3  12    4  21  12  17    2  89\n",
      "All               8    6      4      3  12    4  21  12  17    2  89\n",
      "\n",
      "环保        21\n",
      "行业        17\n",
      "噪音        12\n",
      "监管        12\n",
      "交通         8\n",
      "产品销售       6\n",
      "公司内部管理     4\n",
      "消费服务       4\n",
      "其他相关报道     3\n",
      "资本市场       2\n",
      "Name: predict_label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gather_type</th>\n",
       "      <th>type</th>\n",
       "      <th>urlhash</th>\n",
       "      <th>predict_label</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>group_id</th>\n",
       "      <th>publishtime</th>\n",
       "      <th>tendency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>补录</td>\n",
       "      <td>中国人保</td>\n",
       "      <td>-1451164327749029888</td>\n",
       "      <td>环保</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11月18日21时40分新疆和田地区于田县发生3.0级地震</td>\n",
       "      <td>据中国地震台网测定，北京时间2018年11月18日21时40分在新疆和田地区于田县（北纬36...</td>\n",
       "      <td>新闻</td>\n",
       "      <td>2018-11-18 21:58:50</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>补录</td>\n",
       "      <td>中国人保</td>\n",
       "      <td>-6173404825726358528</td>\n",
       "      <td>监管</td>\n",
       "      <td>NaN</td>\n",
       "      <td>周亮：民营经济离场论调极其错误 银保监会对国有和民营经济一视同仁</td>\n",
       "      <td>11月19日，在第九届财新峰会上，中国银行保险监督管理委员会副主席周亮表示，改革开放40年中...</td>\n",
       "      <td>新闻</td>\n",
       "      <td>2018-11-19 11:09:19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gather_type  type              urlhash predict_label  label  \\\n",
       "0          补录  中国人保 -1451164327749029888            环保    NaN   \n",
       "0          补录  中国人保 -6173404825726358528            监管    NaN   \n",
       "\n",
       "                              title  \\\n",
       "0     11月18日21时40分新疆和田地区于田县发生3.0级地震   \n",
       "0  周亮：民营经济离场论调极其错误 银保监会对国有和民营经济一视同仁   \n",
       "\n",
       "                                             content group_id  \\\n",
       "0  据中国地震台网测定，北京时间2018年11月18日21时40分在新疆和田地区于田县（北纬36...       新闻   \n",
       "0  11月19日，在第九届财新峰会上，中国银行保险监督管理委员会副主席周亮表示，改革开放40年中...       新闻   \n",
       "\n",
       "          publishtime  tendency  \n",
       "0 2018-11-18 21:58:50        -1  \n",
       "0 2018-11-19 11:09:19         0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = pd.DataFrame()\n",
    "for day_select in day_list:\n",
    "#     tmp_data = pd.read_excel('cbirc_result/class/result/cbirc_class_predict_mysql_%s.xlsx'%day_select)\n",
    "    file_name = 'cbirc_result/class/result/cbirc_class_predict_%s_types(%s)_%s.xlsx'%(gather_types, types, day_select)\n",
    "    if os.path.isfile(file_name):\n",
    "        print(file_name)\n",
    "        tmp_data = pd.read_excel(file_name)\n",
    "        combined_data = pd.concat([combined_data, tmp_data], axis = 0)\n",
    "\n",
    "combined_data = combined_data[combined_data['predict_label'] != '补录']\n",
    "print(combined_data.shape)\n",
    "print(combined_data.pivot_table(index = ['type'], columns = ['predict_label'], \n",
    "                            aggfunc = [len], values = ['title'], \n",
    "                            fill_value = 0, margins = True)) \n",
    "print()\n",
    "# {1: '银监会', 2: '保监会', 3: '中国人寿', 4: '建行北分', 5: '中国人保'}\n",
    "# types = ['银监会', '建行北分']\n",
    "# types = [ '中国人寿', '中国人保'] # '保监会',\n",
    "# combined_data = combined_data[combined_data['type'].isin(types)]\n",
    "# print(combined_data.shape)  \n",
    "print(combined_data['predict_label'].value_counts())\n",
    "combined_data.iloc[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:37:30.427133Z",
     "start_time": "2018-11-26T06:37:30.419132Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combined_data = combined_data[['type', 'urlhash', 'local_label', 'label', 'title', 'content']]\n",
    "# combined_data.rename(columns = {'local_label':'predict_label'}, inplace = True)\n",
    "# combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T06:02:15.513402Z",
     "start_time": "2018-12-03T06:02:15.088377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbirc_result/class/result/补录_中国人保_class_predict_mysql_20181203(0902-1203).xlsx\n",
      "环保        21\n",
      "行业        17\n",
      "噪音        12\n",
      "监管        12\n",
      "交通         8\n",
      "产品销售       6\n",
      "公司内部管理     4\n",
      "消费服务       4\n",
      "其他相关报道     3\n",
      "资本市场       2\n",
      "Name: predict_label, dtype: int64\n",
      "\n",
      "predict_label  交通  产品销售  公司内部管理  其他相关报道  噪音  消费服务  环保  监管  行业  资本市场  All\n",
      "type                                                                    \n",
      "中国人保            8     6       4       3  12     4  21  12  17     2   89\n",
      "All             8     6       4       3  12     4  21  12  17     2   89\n"
     ]
    }
   ],
   "source": [
    "fea_filename = 'cbirc_result/class/result/%s_%s_class_predict_mysql_20181203(0902-1203).xlsx'%(gather_types, proj_name_dict[types])\n",
    "print(fea_filename)\n",
    "sel_col = ['噪音', '消费服务', '公司内部管理', '监管',\n",
    "           '行业', '资本市场', '其他相关报道','产品销售','交通','环保']\n",
    "# sel_col = ['公司内部管理', '监管', '行业', '产品销售']\n",
    "# sel_col = combined_data['predict_label'].unique().tolist()\n",
    "sel_data = combined_data[combined_data['predict_label'].isin(sel_col)]\n",
    "print(sel_data['predict_label'].value_counts())\n",
    "print()\n",
    "c_data = pd.DataFrame()\n",
    "with pd.ExcelWriter(fea_filename) as writer:\n",
    "    for label in sel_data['predict_label'].unique():\n",
    "        tmp_data = sel_data[sel_data['predict_label'] == label]\n",
    "        if gather_types == '补录':\n",
    "            N = tmp_data.shape[0]\n",
    "        else :\n",
    "            if tmp_data.shape[0] > 100:\n",
    "                N = 50\n",
    "            else :\n",
    "                N = tmp_data.shape[0]\n",
    "            if label in ['交通',]: # '环保'\n",
    "                N =  200 # tmp_data.shape[0]\n",
    "            \n",
    "        save_data = tmp_data.sample(n = N, axis = 0, random_state=42)\n",
    "        save_data.to_excel(writer,label, index = False)\n",
    "        c_data = pd.concat([c_data, save_data], axis = 0)\n",
    "    print(c_data.pivot_table(index = ['type'], \n",
    "                                columns = ['predict_label'], \n",
    "                                values = 'title', aggfunc=len, \n",
    "                                fill_value=0, margins=True))      \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 倾向性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 合并 & 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:37:07.197509Z",
     "start_time": "2018-11-27T03:36:56.627904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbirc_result/class/result/cbirc_class_predict_采集_types(5)_2018-11-21.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_采集_types(5)_2018-11-22.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_采集_types(5)_2018-11-23.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_采集_types(5)_2018-11-24.xlsx\n",
      "cbirc_result/class/result/cbirc_class_predict_采集_types(5)_2018-11-25.xlsx\n",
      "(51061, 11)\n",
      "            len              \n",
      "          title              \n",
      "tendency     -1      0    All\n",
      "type                         \n",
      "中国人保      18017  33044  51057\n",
      "All       18016  33041  51057\n",
      " 0    33044\n",
      "-1    18017\n",
      "Name: tendency, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gather_type</th>\n",
       "      <th>type</th>\n",
       "      <th>urlhash</th>\n",
       "      <th>predict_label</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>group_id</th>\n",
       "      <th>publishtime</th>\n",
       "      <th>tendency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9196833</td>\n",
       "      <td>系统采集</td>\n",
       "      <td>中国人保</td>\n",
       "      <td>7090836087712654336</td>\n",
       "      <td>噪音</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[看，我们是被执行人]执行通知书、报告财产令、执行告知书(11月12-14日)立案案件</td>\n",
       "      <td>根据《中华人民共和国民事诉讼法》第二百四十条“执行员接到申请执行书或者移交执行书，应当向被执...</td>\n",
       "      <td>微信</td>\n",
       "      <td>2018-11-21 00:01:14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9237521</td>\n",
       "      <td>系统采集</td>\n",
       "      <td>中国人保</td>\n",
       "      <td>4322856188218469888</td>\n",
       "      <td>噪音</td>\n",
       "      <td>NaN</td>\n",
       "      <td>【青 · 榜样】披星戴月风雨兼程，勠力同心攻坚克难</td>\n",
       "      <td>厉！害！啦！ 在向家坝电厂2018年度防汛总结暨2018-2019年度岁修动员会上，电气维修...</td>\n",
       "      <td>微信</td>\n",
       "      <td>2018-11-21 04:55:37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gather_type  type              urlhash predict_label  label  \\\n",
       "0  9196833        系统采集  中国人保  7090836087712654336            噪音    NaN   \n",
       "1  9237521        系统采集  中国人保  4322856188218469888            噪音    NaN   \n",
       "\n",
       "                                         title  \\\n",
       "0  [看，我们是被执行人]执行通知书、报告财产令、执行告知书(11月12-14日)立案案件   \n",
       "1                    【青 · 榜样】披星戴月风雨兼程，勠力同心攻坚克难   \n",
       "\n",
       "                                             content group_id  \\\n",
       "0  根据《中华人民共和国民事诉讼法》第二百四十条“执行员接到申请执行书或者移交执行书，应当向被执...       微信   \n",
       "1  厉！害！啦！ 在向家坝电厂2018年度防汛总结暨2018-2019年度岁修动员会上，电气维修...       微信   \n",
       "\n",
       "          publishtime  tendency  \n",
       "0 2018-11-21 00:01:14         0  \n",
       "1 2018-11-21 04:55:37         0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = pd.DataFrame()\n",
    "for day_select in day_list:\n",
    "#     tmp_data = pd.read_excel('cbirc_result/class/result/cbirc_class_predict_mysql_%s.xlsx'%day_select)\n",
    "    file_name = 'cbirc_result/class/result/cbirc_class_predict_%s_types(%s)_%s.xlsx'%(gather_types, types, day_select)\n",
    "    if os.path.isfile(file_name):\n",
    "        print(file_name)\n",
    "        tmp_data = pd.read_excel(file_name)\n",
    "        combined_data = pd.concat([combined_data, tmp_data], axis = 0)\n",
    "        \n",
    "# combined_data = combined_data[combined_data['predict_label'] != '补录']\n",
    "print(combined_data.shape)\n",
    "print(combined_data.pivot_table(index = ['type'], columns = ['tendency'], \n",
    "                            aggfunc = [len], values = ['title'], \n",
    "                            fill_value = 0, margins = True)) \n",
    "# print()\n",
    "# {1: '银监会', 2: '保监会', 3: '中国人寿', 4: '建行北分', 5: '中国人保'}\n",
    "# types = ['银监会', '建行北分']\n",
    "# types = [ '中国人保']# '保监会', '中国人寿',\n",
    "# combined_data = combined_data[combined_data['type'].isin(types)]\n",
    "# print(combined_data.shape)  \n",
    "\n",
    "print(combined_data['tendency'].value_counts())\n",
    "combined_data.iloc[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T03:37:17.905121Z",
     "start_time": "2018-11-27T03:37:16.798058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbirc_result/tendency/result/采集_中国人保_tendency_predict_mysql_20181126(1121-1125).xlsx\n",
      " 0    33044\n",
      "-1    18017\n",
      "Name: tendency, dtype: int64\n",
      "正负各 300 条，共 10 类， 每类各 230 条\n",
      "tendency: 0, predict_label: 噪音, size: (230, 11)\n",
      "tendency: 0, predict_label: 交通, size: (460, 11)\n",
      "tendency: 0, predict_label: 行业, size: (690, 11)\n",
      "tendency: 0, predict_label: 资本市场, size: (920, 11)\n",
      "tendency: 0, predict_label: 公司内部管理, size: (1150, 11)\n",
      "tendency: 0, predict_label: 监管, size: (1248, 11)\n",
      "tendency: 0, predict_label: 其他相关报道, size: (1478, 11)\n",
      "tendency: 0, predict_label: 产品销售, size: (1706, 11)\n",
      "tendency: 0, predict_label: 消费服务, size: (1936, 11)\n",
      "tendency: 0, predict_label: 环保, size: (2004, 11)\n",
      "predict_label  交通  产品销售  公司内部管理  其他相关报道  噪音  消费服务  环保  监管  行业  资本市场  All\n",
      "tendency type                                                           \n",
      "0        中国人保  27    35      29      31  45    36  14  16  28    39  300\n",
      "All            27    35      29      31  45    36  14  16  28    39  300\n",
      "\n",
      "tendency: -1, predict_label: 噪音, size: (230, 11)\n",
      "tendency: -1, predict_label: 交通, size: (460, 11)\n",
      "tendency: -1, predict_label: 行业, size: (690, 11)\n",
      "tendency: -1, predict_label: 资本市场, size: (920, 11)\n",
      "tendency: -1, predict_label: 公司内部管理, size: (1055, 11)\n",
      "tendency: -1, predict_label: 监管, size: (1103, 11)\n",
      "tendency: -1, predict_label: 其他相关报道, size: (1134, 11)\n",
      "tendency: -1, predict_label: 产品销售, size: (1140, 11)\n",
      "tendency: -1, predict_label: 消费服务, size: (1301, 11)\n",
      "tendency: -1, predict_label: 环保, size: (1311, 11)\n",
      "predict_label  交通  公司内部管理  其他相关报道  噪音  消费服务  环保  监管  行业  资本市场  All\n",
      "tendency type                                                     \n",
      "-1       中国人保  47      23       8  67    32   3  11  60    49  300\n",
      "All            47      23       8  67    32   3  11  60    49  300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fea_filename = 'cbirc_result/tendency/result/%s_%s_tendency_predict_mysql_20181126(1121-1125).xlsx'%(gather_types, \n",
    "                                                                                                     proj_name_dict[types])\n",
    "print(fea_filename)\n",
    "print(combined_data['tendency'].value_counts())\n",
    "\n",
    "N = 300 # 每类 N 条数据\n",
    "class_n = int(combined_data['predict_label'].unique().shape[0])\n",
    "n = int(N / class_n) + 200\n",
    "\n",
    "print('正负各 %s 条，共 %s 类， 每类各 %s 条'%(N, class_n, n))\n",
    "with pd.ExcelWriter(fea_filename) as writer:\n",
    "    for tendency in combined_data['tendency'].unique():\n",
    "        tmp_data = pd.DataFrame()\n",
    "        sel_data = combined_data[combined_data['tendency'] == tendency]        \n",
    "        for predict_label in combined_data['predict_label'].unique():\n",
    "            label_data = sel_data[sel_data['predict_label'] == predict_label]\n",
    "            if label_data.shape[0] > n:\n",
    "                sel_label_data = label_data.sample(n = n, axis = 0, random_state=3)\n",
    "            else :\n",
    "                sel_label_data = label_data\n",
    "            tmp_data = pd.concat([tmp_data, sel_label_data], axis = 0)        \n",
    "            print('tendency: %s, predict_label: %s, size: %s'%(tendency, predict_label, tmp_data.shape))\n",
    "\n",
    "        if gather_types == '补录':\n",
    "            t_n = tmp_data.shape[0]\n",
    "        else :            \n",
    "            if tmp_data.shape[0] > N:\n",
    "                t_n = N\n",
    "            else :\n",
    "                t_n = tmp_data.shape[0]\n",
    "        \n",
    "        tmp_data = tmp_data.sample(n = t_n, axis = 0, random_state=3)\n",
    "        tmp_data.to_excel(writer,str(tendency), index = False)        \n",
    "        print(tmp_data.pivot_table(index = ['tendency', 'type'], \n",
    "                                    columns = ['predict_label'], \n",
    "                                    values = 'title', aggfunc=len, \n",
    "                                    fill_value=0, margins=True))    \n",
    "        print()\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 本地模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 八分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CBRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T07:57:33.168863Z",
     "start_time": "2018-11-15T07:57:33.161863Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "pipeline_old = joblib.load( \"model/cbrc_8classifier_1015.pkl.z\")\n",
    "\n",
    "url = 'http://47.93.183.157:6001/judge_correlation_b'\n",
    "col_name = 'cor'\n",
    "types = 1\n",
    "\n",
    "combined_data['title_content'] = combined_data['title'].astype(str) + '。' + combined_data['content'].astype(str)\n",
    "title_content = pre_cor_cbrc.handle_contents(combined_data['title_content'].tolist())\n",
    "print(len(title_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CIRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:23:19.978490Z",
     "start_time": "2018-11-26T06:23:09.913914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "pipeline_old = joblib.load( \"model/circ_8classifier_1113.pkl.z\")\n",
    "# pipeline_old = joblib.load( \"model/circ_picc_10classifier_1118.pkl.z\")\n",
    "\n",
    "url = 'http://47.93.183.157:10000/judge_correlation_i'\n",
    "col_name = 'cor'\n",
    "types = 5\n",
    "\n",
    "combined_data['title_content'] = combined_data['title'].astype(str) + '。' + combined_data['content'].astype(str)\n",
    "title_content = pre_cor_circ.handle_contents(combined_data['title_content'].tolist())\n",
    "print(len(title_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:23:21.615583Z",
     "start_time": "2018-11-26T06:23:21.128556Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local_label = pipeline_old.predict(title_content)\n",
    "local_proba = pipeline_old.predict_proba(title_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:23:22.492634Z",
     "start_time": "2018-11-26T06:23:22.454631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gather_type</th>\n",
       "      <th>type</th>\n",
       "      <th>urlhash</th>\n",
       "      <th>predict_label</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>group_id</th>\n",
       "      <th>publishtime</th>\n",
       "      <th>tendency</th>\n",
       "      <th>title_content</th>\n",
       "      <th>local_label</th>\n",
       "      <th>local_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>补录</td>\n",
       "      <td>中国人保</td>\n",
       "      <td>-1451164327749029888</td>\n",
       "      <td>环保</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11月18日21时40分新疆和田地区于田县发生3.0级地震</td>\n",
       "      <td>据中国地震台网测定，北京时间2018年11月18日21时40分在新疆和田地区于田县（北纬36...</td>\n",
       "      <td>新闻</td>\n",
       "      <td>2018-11-18 21:58:50</td>\n",
       "      <td>-1</td>\n",
       "      <td>11月18日21时40分新疆和田地区于田县发生3.0级地震。据中国地震台网测定，北京时间20...</td>\n",
       "      <td>噪音</td>\n",
       "      <td>0.605084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>补录</td>\n",
       "      <td>中国人保</td>\n",
       "      <td>-6173404825726358528</td>\n",
       "      <td>监管</td>\n",
       "      <td>NaN</td>\n",
       "      <td>周亮：民营经济离场论调极其错误 银保监会对国有和民营经济一视同仁</td>\n",
       "      <td>11月19日，在第九届财新峰会上，中国银行保险监督管理委员会副主席周亮表示，改革开放40年中...</td>\n",
       "      <td>新闻</td>\n",
       "      <td>2018-11-19 11:09:19</td>\n",
       "      <td>0</td>\n",
       "      <td>周亮：民营经济离场论调极其错误 银保监会对国有和民营经济一视同仁。11月19日，在第九届财新...</td>\n",
       "      <td>监管</td>\n",
       "      <td>0.915518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gather_type  type              urlhash predict_label  label  \\\n",
       "0          补录  中国人保 -1451164327749029888            环保    NaN   \n",
       "0          补录  中国人保 -6173404825726358528            监管    NaN   \n",
       "\n",
       "                              title  \\\n",
       "0     11月18日21时40分新疆和田地区于田县发生3.0级地震   \n",
       "0  周亮：民营经济离场论调极其错误 银保监会对国有和民营经济一视同仁   \n",
       "\n",
       "                                             content group_id  \\\n",
       "0  据中国地震台网测定，北京时间2018年11月18日21时40分在新疆和田地区于田县（北纬36...       新闻   \n",
       "0  11月19日，在第九届财新峰会上，中国银行保险监督管理委员会副主席周亮表示，改革开放40年中...       新闻   \n",
       "\n",
       "          publishtime  tendency  \\\n",
       "0 2018-11-18 21:58:50        -1   \n",
       "0 2018-11-19 11:09:19         0   \n",
       "\n",
       "                                       title_content local_label  local_proba  \n",
       "0  11月18日21时40分新疆和田地区于田县发生3.0级地震。据中国地震台网测定，北京时间20...          噪音     0.605084  \n",
       "0  周亮：民营经济离场论调极其错误 银保监会对国有和民营经济一视同仁。11月19日，在第九届财新...          监管     0.915518  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['local_label'] = local_label\n",
    "combined_data['local_proba'] = local_proba.max(axis = 1)\n",
    "combined_data['local_label'] = combined_data['local_label'].apply(lambda x:class_name_dict[x])\n",
    "print(combined_data.shape)\n",
    "combined_data.iloc[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:23:25.590811Z",
     "start_time": "2018-11-26T06:23:25.577810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "噪音        13\n",
       "行业        12\n",
       "公司内部管理     5\n",
       "消费服务       5\n",
       "其他相关报道     4\n",
       "监管         3\n",
       "资本市场       1\n",
       "Name: local_label, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['local_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线上线下一致性: mysql 与 local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:23:27.156900Z",
     "start_time": "2018-11-26T06:23:27.056895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46511627906976744\n",
      "Wrong    23\n",
      "Right    20\n",
      "Name: R_W, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"7\" halign=\"left\">len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"7\" halign=\"left\">urlhash</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict_label</th>\n",
       "      <th>交通</th>\n",
       "      <th>产品销售</th>\n",
       "      <th>公司内部管理</th>\n",
       "      <th>环保</th>\n",
       "      <th>监管</th>\n",
       "      <th>行业</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>公司内部管理</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>其他相关报道</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>噪音</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>消费服务</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>行业</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  len                          \n",
       "              urlhash                          \n",
       "predict_label      交通 产品销售 公司内部管理  环保 监管 行业 All\n",
       "local_label                                    \n",
       "公司内部管理              1    1      0   0  0  1   3\n",
       "其他相关报道              1    1      0   0  0  0   2\n",
       "噪音                  1    0      0   9  0  1  11\n",
       "消费服务                1    0      1   1  0  0   3\n",
       "行业                  0    0      0   0  4  0   4\n",
       "All                 4    2      1  10  4  2  23"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['R_W'] = combined_data.apply(lambda x: 'Right' if x['local_label'] == x['predict_label'] else 'Wrong', axis = 1)\n",
    "print(combined_data[combined_data['R_W'] == 'Right'].shape[0]/combined_data.shape[0])\n",
    "print(combined_data['R_W'].value_counts())\n",
    "combined_data[combined_data['R_W'] == 'Wrong'].pivot_table(index = ['local_label'], columns = ['predict_label'], \n",
    "                                                            aggfunc = [len], values = ['urlhash'], \n",
    "                                                            fill_value = 0, margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线上线下一致性: online 与 local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:23:40.100641Z",
     "start_time": "2018-11-26T06:23:40.093640Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data['id'] = range(combined_data.shape[0])\n",
    "combined_data['title'] = combined_data['title'].astype(str) \n",
    "combined_data['content'] = combined_data['content'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:27:05.589394Z",
     "start_time": "2018-11-26T06:27:04.737345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time:  0.00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>online_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  online_label\n",
       "0   0             8\n",
       "1   1             1\n",
       "2   2             2\n",
       "3   3             7\n",
       "4   4             6"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"types\":types,\"record\":combined_data.loc[:,['id', 'title' ,'content']].to_dict(orient = 'records')}\n",
    "# url = \"http://47.93.77.19:6001/judge_correlation_yjh\"\n",
    "# col_name = 'sec'\n",
    "\n",
    "# parse_data = get_server_res_yjh(data, url, col_name)\n",
    "parse_data, elapsed_time = get_server_res(data, url, col_name)\n",
    "print('elapsed_time: ', elapsed_time)\n",
    "parse_data.columns = ['id', 'online_label']\n",
    "parse_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:27:10.826694Z",
     "start_time": "2018-11-26T06:27:10.746689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 16)\n",
      "0.7674418604651163\n",
      "Right    33\n",
      "Wrong    10\n",
      "Name: O_R_W, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">urlhash</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>online_label</th>\n",
       "      <th>交通</th>\n",
       "      <th>公司内部管理</th>\n",
       "      <th>噪音</th>\n",
       "      <th>监管</th>\n",
       "      <th>行业</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>公司内部管理</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>其他相关报道</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>噪音</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>消费服务</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>行业</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 len                    \n",
       "             urlhash                    \n",
       "online_label      交通 公司内部管理 噪音 监管 行业 All\n",
       "local_label                             \n",
       "公司内部管理             0      0  2  1  0   3\n",
       "其他相关报道             0      0  1  0  0   1\n",
       "噪音                 2      0  0  0  1   3\n",
       "消费服务               1      1  0  0  0   2\n",
       "行业                 0      0  0  1  0   1\n",
       "All                3      1  3  2  1  10"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = pd.merge(combined_data, parse_data, on  = 'id')\n",
    "print(combined_data.shape)\n",
    "combined_data['online_label'] = combined_data['online_label'].apply(lambda x:class_name_dict[x])\n",
    "combined_data['O_R_W'] = combined_data.apply(lambda x: 'Right' if x['local_label'] == x['online_label'] else 'Wrong', axis = 1)\n",
    "print(combined_data[combined_data['O_R_W'] == 'Right'].shape[0]/combined_data.shape[0])\n",
    "print(combined_data['O_R_W'].value_counts())\n",
    "combined_data[combined_data['O_R_W'] == 'Wrong'].pivot_table(index = ['local_label'], columns = ['online_label'], \n",
    "                                                            aggfunc = [len], values = ['urlhash'], \n",
    "                                                            fill_value = 0, margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线上线下一致性: online 与 mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:27:18.387126Z",
     "start_time": "2018-11-26T06:27:18.352124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5348837209302325\n",
      "Right    23\n",
      "Wrong    20\n",
      "Name: O_R_W, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "combined_data['O_R_W'] = combined_data.apply(lambda x: 'Right' if x['predict_label'] == x['online_label'] else 'Wrong', axis = 1)\n",
    "print(combined_data[combined_data['O_R_W'] == 'Right'].shape[0]/combined_data.shape[0])\n",
    "print(combined_data['O_R_W'].value_counts())\n",
    "# combined_data[combined_data['O_R_W'] == 'Wrong'].pivot_table(index = ['predict_label'], \n",
    "#                                                              columns = ['online_label'], \n",
    "#                                                              aggfunc = [len], values = ['urlhash'], \n",
    "#                                                              fill_value = 0, margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 倾向性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T08:37:47.541957Z",
     "start_time": "2018-11-15T08:37:47.521956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>urlhash</th>\n",
       "      <th>predict_label</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>group_id</th>\n",
       "      <th>publishtime</th>\n",
       "      <th>tendency</th>\n",
       "      <th>title_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10724</th>\n",
       "      <td>中国人保</td>\n",
       "      <td>4823901446525329408</td>\n",
       "      <td>噪音</td>\n",
       "      <td>NaN</td>\n",
       "      <td>因祸得福！CDR基金惊现大动作</td>\n",
       "      <td>渐渐被市场遗忘CDR基金，最近又曝出新动向。\\n\\n11月7日晚间，中国人保A股IPO网下初...</td>\n",
       "      <td>新闻客户端</td>\n",
       "      <td>2018-11-11 12:28:47</td>\n",
       "      <td>-1</td>\n",
       "      <td>因祸得福！CDR基金惊现大动作。渐渐被市场遗忘CDR基金，最近又曝出新动向。\\n\\n11月7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4469</th>\n",
       "      <td>中国人保</td>\n",
       "      <td>2875199957075597824</td>\n",
       "      <td>噪音</td>\n",
       "      <td>NaN</td>\n",
       "      <td>【招聘】中国人民财产保险股份有限公司珠海市分公司2019年校招</td>\n",
       "      <td>一 公司简介 （一）中国人民财产保险股份有限公司简介 中国人民财产保险股份有限公司（PICC...</td>\n",
       "      <td>微信</td>\n",
       "      <td>2018-11-13 13:29:47</td>\n",
       "      <td>0</td>\n",
       "      <td>【招聘】中国人民财产保险股份有限公司珠海市分公司2019年校招。一 公司简介 （一）中国人民...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type              urlhash predict_label  label  \\\n",
       "10724  中国人保  4823901446525329408            噪音    NaN   \n",
       "4469   中国人保  2875199957075597824            噪音    NaN   \n",
       "\n",
       "                                 title  \\\n",
       "10724                  因祸得福！CDR基金惊现大动作   \n",
       "4469   【招聘】中国人民财产保险股份有限公司珠海市分公司2019年校招   \n",
       "\n",
       "                                                 content group_id  \\\n",
       "10724  渐渐被市场遗忘CDR基金，最近又曝出新动向。\\n\\n11月7日晚间，中国人保A股IPO网下初...    新闻客户端   \n",
       "4469   一 公司简介 （一）中国人民财产保险股份有限公司简介 中国人民财产保险股份有限公司（PICC...       微信   \n",
       "\n",
       "              publishtime  tendency  \\\n",
       "10724 2018-11-11 12:28:47        -1   \n",
       "4469  2018-11-13 13:29:47         0   \n",
       "\n",
       "                                           title_content  \n",
       "10724  因祸得福！CDR基金惊现大动作。渐渐被市场遗忘CDR基金，最近又曝出新动向。\\n\\n11月7...  \n",
       "4469   【招聘】中国人民财产保险股份有限公司珠海市分公司2019年校招。一 公司简介 （一）中国人民...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.iloc[:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CBRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "pipeline_old = joblib.load( \"model/cbrc_tendency_pipeline_20181114.pkl.z\")\n",
    "\n",
    "url = 'http://47.93.183.157:6001/tendency_analysis_b'\n",
    "col_name = 'tendency'\n",
    "types = 1\n",
    "\n",
    "combined_data['title_content'] = combined_data['title'].astype(str) + '。' + combined_data['content'].astype(str)\n",
    "title_content = pre_cor_cbrc.handle_contents(combined_data['title_content'].tolist())\n",
    "print(len(title_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CIRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:31:59.882227Z",
     "start_time": "2018-11-26T06:31:59.087181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "pipeline_old = joblib.load( \"model/circ_chapter_tendency_1113.pkl.z\")\n",
    "\n",
    "url = 'http://47.93.183.157:10000/tendency_analysis_i'\n",
    "col_name = 'tendency'\n",
    "types = 5\n",
    "\n",
    "combined_data['title_content'] = combined_data['title'].astype(str) + '。' + combined_data['content'].astype(str)\n",
    "title_content = pre_cor_circ.handle_contents(combined_data['title_content'].tolist())\n",
    "print(len(title_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:32:00.498262Z",
     "start_time": "2018-11-26T06:32:00.410257Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local_label = pipeline_old.predict(title_content)\n",
    "local_proba = pipeline_old.predict_proba(title_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:32:01.197302Z",
     "start_time": "2018-11-26T06:32:01.164300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gather_type</th>\n",
       "      <th>type</th>\n",
       "      <th>urlhash</th>\n",
       "      <th>predict_label</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>group_id</th>\n",
       "      <th>publishtime</th>\n",
       "      <th>tendency</th>\n",
       "      <th>title_content</th>\n",
       "      <th>local_label</th>\n",
       "      <th>local_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>补录</td>\n",
       "      <td>中国人保</td>\n",
       "      <td>-1451164327749029888</td>\n",
       "      <td>环保</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11月18日21时40分新疆和田地区于田县发生3.0级地震</td>\n",
       "      <td>据中国地震台网测定，北京时间2018年11月18日21时40分在新疆和田地区于田县（北纬36...</td>\n",
       "      <td>新闻</td>\n",
       "      <td>2018-11-18 21:58:50</td>\n",
       "      <td>-1</td>\n",
       "      <td>11月18日21时40分新疆和田地区于田县发生3.0级地震。据中国地震台网测定，北京时间20...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>补录</td>\n",
       "      <td>中国人保</td>\n",
       "      <td>-6173404825726358528</td>\n",
       "      <td>监管</td>\n",
       "      <td>NaN</td>\n",
       "      <td>周亮：民营经济离场论调极其错误 银保监会对国有和民营经济一视同仁</td>\n",
       "      <td>11月19日，在第九届财新峰会上，中国银行保险监督管理委员会副主席周亮表示，改革开放40年中...</td>\n",
       "      <td>新闻</td>\n",
       "      <td>2018-11-19 11:09:19</td>\n",
       "      <td>0</td>\n",
       "      <td>周亮：民营经济离场论调极其错误 银保监会对国有和民营经济一视同仁。11月19日，在第九届财新...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gather_type  type              urlhash predict_label  label  \\\n",
       "0          补录  中国人保 -1451164327749029888            环保    NaN   \n",
       "0          补录  中国人保 -6173404825726358528            监管    NaN   \n",
       "\n",
       "                              title  \\\n",
       "0     11月18日21时40分新疆和田地区于田县发生3.0级地震   \n",
       "0  周亮：民营经济离场论调极其错误 银保监会对国有和民营经济一视同仁   \n",
       "\n",
       "                                             content group_id  \\\n",
       "0  据中国地震台网测定，北京时间2018年11月18日21时40分在新疆和田地区于田县（北纬36...       新闻   \n",
       "0  11月19日，在第九届财新峰会上，中国银行保险监督管理委员会副主席周亮表示，改革开放40年中...       新闻   \n",
       "\n",
       "          publishtime  tendency  \\\n",
       "0 2018-11-18 21:58:50        -1   \n",
       "0 2018-11-19 11:09:19         0   \n",
       "\n",
       "                                       title_content  local_label  local_proba  \n",
       "0  11月18日21时40分新疆和田地区于田县发生3.0级地震。据中国地震台网测定，北京时间20...           -1          1.0  \n",
       "0  周亮：民营经济离场论调极其错误 银保监会对国有和民营经济一视同仁。11月19日，在第九届财新...            0          1.0  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['local_label'] = local_label\n",
    "combined_data['local_proba'] = local_proba.max(axis = 1)\n",
    "# combined_data['local_label'] = combined_data['local_label'].apply(lambda x:class_name_dict[x])\n",
    "print(combined_data.shape)\n",
    "combined_data.iloc[:2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线上线下一致性: mysql 与 local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:32:02.856397Z",
     "start_time": "2018-11-26T06:32:02.793393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.813953488372093\n",
      "Right    35\n",
      "Wrong     8\n",
      "Name: R_W, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">urlhash</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tendency</th>\n",
       "      <th>0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                len    \n",
       "            urlhash    \n",
       "tendency          0 All\n",
       "local_label            \n",
       "-1                8   8\n",
       "All               8   8"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['R_W'] = combined_data.apply(lambda x: 'Right' if x['local_label'] == x['tendency'] else 'Wrong', axis = 1)\n",
    "print(combined_data[combined_data['R_W'] == 'Right'].shape[0]/combined_data.shape[0])\n",
    "print(combined_data['R_W'].value_counts())\n",
    "combined_data[combined_data['R_W'] == 'Wrong'].pivot_table(index = ['local_label'], columns = ['tendency'], \n",
    "                                                            aggfunc = [len], values = ['urlhash'], \n",
    "                                                            fill_value = 0, margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线上线下一致性: online 与 local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:32:06.366597Z",
     "start_time": "2018-11-26T06:32:06.350597Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data['id'] = range(combined_data.shape[0])\n",
    "combined_data['title'] = combined_data['title'].astype(str) \n",
    "combined_data['content'] = combined_data['content'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:32:09.767792Z",
     "start_time": "2018-11-26T06:32:07.151642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed_time:  2.00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>online_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  online_label\n",
       "0   0            -1\n",
       "1   1             0\n",
       "2   2            -1\n",
       "3   3             0\n",
       "4   4             0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"types\":types, \"record\":combined_data.loc[:,['id', 'title' ,'content']].to_dict(orient = 'records')}\n",
    "# url = \"http://47.93.77.19:6001/judge_correlation_yjh\"\n",
    "# col_name = 'sec'\n",
    "\n",
    "# parse_data = get_server_res_yjh(data, url, col_name)\n",
    "parse_data, elapsed_time = get_server_res(data, url, col_name)\n",
    "print('elapsed_time: ', elapsed_time)\n",
    "parse_data.columns = ['id', 'online_label']\n",
    "parse_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:32:10.181816Z",
     "start_time": "2018-11-26T06:32:10.176815Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combined_data.head()\n",
    "# combined_data.iloc[:2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:32:10.700845Z",
     "start_time": "2018-11-26T06:32:10.623841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 16)\n",
      "0.9069767441860465\n",
      "Right    39\n",
      "Wrong     4\n",
      "Name: O_R_W, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">urlhash</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>online_label</th>\n",
       "      <th>0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>local_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 len    \n",
       "             urlhash    \n",
       "online_label       0 All\n",
       "local_label             \n",
       "-1                 4   4\n",
       "All                4   4"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = pd.merge(combined_data, parse_data, on  = 'id')\n",
    "print(combined_data.shape)\n",
    "# combined_data['online_label'] = combined_data['online_label'].apply(lambda x:class_name_dict[x])\n",
    "combined_data['O_R_W'] = combined_data.apply(lambda x: 'Right' if x['local_label'] == x['online_label'] else 'Wrong', axis = 1)\n",
    "print(combined_data[combined_data['O_R_W'] == 'Right'].shape[0]/combined_data.shape[0])\n",
    "print(combined_data['O_R_W'].value_counts())\n",
    "combined_data[combined_data['O_R_W'] == 'Wrong'].pivot_table(index = ['local_label'], columns = ['online_label'], \n",
    "                                                            aggfunc = [len], values = ['urlhash'], \n",
    "                                                            fill_value = 0, margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线上线下一致性: online 与 mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-26T06:32:14.542065Z",
     "start_time": "2018-11-26T06:32:14.512063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9069767441860465\n",
      "Right    39\n",
      "Wrong     4\n",
      "Name: O_R_W, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "combined_data['O_R_W'] = combined_data.apply(lambda x: 'Right' if x['tendency'] == x['online_label'] else 'Wrong', axis = 1)\n",
    "print(combined_data[combined_data['O_R_W'] == 'Right'].shape[0]/combined_data.shape[0])\n",
    "print(combined_data['O_R_W'].value_counts())\n",
    "# combined_data[combined_data['O_R_W'] == 'Wrong'].pivot_table(index = ['predict_label'], columns = ['online_label'], \n",
    "#                                                             aggfunc = [len], values = ['urlhash'], \n",
    "#                                                             fill_value = 0, margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存本文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T09:02:47.846195Z",
     "start_time": "2018-09-11T09:02:44.835Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    import datetime as dt\n",
    "    \n",
    "    def output_HTML(read_file, output_file):\n",
    "        from nbconvert import HTMLExporter\n",
    "        import codecs\n",
    "        import nbformat\n",
    "        exporter = HTMLExporter()\n",
    "        # read_file is '.ipynb', output_file is '.html'\n",
    "        output_notebook = nbformat.read(read_file, as_version=4)\n",
    "        output, resources = exporter.from_notebook_node(output_notebook)\n",
    "        codecs.open(output_file, 'w', encoding='utf-8').write(output)\n",
    "\n",
    "    html_file_folder = 'html_files'\n",
    "    if not os.path.exists(html_file_folder):\n",
    "        os.makedirs(html_file_folder)\n",
    "\n",
    "    today = dt.datetime.now().strftime('%Y%m%d')\n",
    "    current_file = 'circ_cor_model_2_train.ipynb'\n",
    "    output_file = 'html_files\\%s_%s.html'%(os.path.splitext(current_file)[0], today)\n",
    "    output_HTML(current_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本文件说明\n",
    "- 统计分析\n",
    "> - 八分类模型数据：噪音与非噪音\n",
    "> - 补录和预警数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T10:50:08.741670Z",
     "start_time": "2018-11-18T10:50:07.412594Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import requests,json\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T10:50:08.756671Z",
     "start_time": "2018-11-18T10:50:08.743670Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from toolkits.setup.date_time import get_day_list\n",
    "from toolkits.setup import specific_func\n",
    "specific_func.set_ch_pd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一些函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T10:50:08.861677Z",
     "start_time": "2018-11-18T10:50:08.759671Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_cor(count_data, day_thing, title):\n",
    "    fig = plt.figure(figsize = (15,6))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    rects = count_data[['al_cor', 'al_uncor']].plot(kind = 'bar', ax = ax1, alpha=0.5, stacked=True)\n",
    "    ax1.set_ylabel('num', fontsize = 16)\n",
    "    ax1.set_title(title, fontsize = 20)\n",
    "    ax1.legend(['al-cor', 'al-uncor'], loc='upper left')\n",
    "\n",
    "    ax2 = ax1.twinx()  # this is the important function\n",
    "    count_data[['al_cor_rate', 'al_uncor_rate']].plot(x = count_data['publishtime'],\n",
    "                                              kind = 'line', ax = ax2, marker = 'D')\n",
    "    ax2.set_ylabel('rate', fontsize = 16)\n",
    "    ax2.set_xlabel('publishtime', fontsize = 16)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.legend(['al-cor-rate', 'al-uncor-rate'], loc='upper center')\n",
    "\n",
    "    y_list = [0.65, 0.75, 0.85, 0.95]\n",
    "    m = 0\n",
    "    for [d, t] in day_thing:    \n",
    "        if d in count_data['publishtime'].tolist():\n",
    "            x = count_data['publishtime'].tolist().index(d)\n",
    "            ax2.axvline(x=x, ymin = y_list[m] - 0.1, ymax = y_list[m] + 0.1, \n",
    "                        color='k', linestyle = \"--\", alpha = 0.75)\n",
    "            ax2.text(x - 0.25, y_list[m], t, va='center', fontsize = 12)\n",
    "            if m == 3: \n",
    "                m = 0\n",
    "            else :\n",
    "                m += 1\n",
    "\n",
    "    plt.grid(True, linestyle = \"--\", color = \"r\", alpha = 0.3) \n",
    "    plt.show()\n",
    "\n",
    "    print(count_data.sort_values(by = 'publishtime', ascending = False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T10:50:08.974683Z",
     "start_time": "2018-11-18T10:50:08.865677Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_tend(tend_count, day_thing, title):\n",
    "    tend_counts = tend_count.set_index([\"tendency\", 'publishtime']).unstack('tendency')\n",
    "    tend_counts.columns = ['neg', 'pos']\n",
    "    tend_counts['sum'] = tend_counts.sum(axis = 1)\n",
    "    tend_counts['neg_rate'] =  tend_counts['neg'] / tend_counts['sum']\n",
    "    tend_counts['pos_rate'] =  tend_counts['pos'] / tend_counts['sum']\n",
    "    tend_counts = tend_counts.reset_index('publishtime')\n",
    "\n",
    "    tend_counts = tend_counts.sort_values(by = 'publishtime')\n",
    "    fig = plt.figure(figsize = (15,6))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    tend_counts[['neg', 'pos']].plot(kind = 'bar', ax = ax1, alpha=0.5, stacked=True)\n",
    "    ax1.set_ylabel('N', fontsize = 16)\n",
    "    ax1.set_title(title, fontsize = 20)\n",
    "    ax1.legend(['neg N', 'pos N'], loc='upper left')\n",
    "\n",
    "    ax2 = ax1.twinx()  # this is the important function\n",
    "    tend_counts[['neg_rate', 'pos_rate']].plot(x = tend_counts['publishtime'],\n",
    "                                             kind = 'line', ax = ax2, marker = 'D')\n",
    "    ax2.set_ylabel('rate', fontsize = 16)\n",
    "    ax2.set_xlabel('publishtime', fontsize = 16)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.legend(loc='upper center')\n",
    "    y_list = [0.65, 0.75, 0.85, 0.95]\n",
    "    m = 0\n",
    "    for [d, t] in day_thing:    \n",
    "        if d in tend_counts['publishtime'].tolist():\n",
    "            x = tend_counts['publishtime'].tolist().index(d)\n",
    "            ax2.axvline(x=x, ymin = y_list[m] - 0.1, ymax = y_list[m] + 0.1, \n",
    "                        color='k', linestyle = \"--\", alpha = 0.75)\n",
    "            ax2.text(x - 0.25, y_list[m], t, va='center', fontsize = 12)\n",
    "            if m == 3: \n",
    "                m = 0\n",
    "            else :\n",
    "                m += 1\n",
    "\n",
    "    plt.grid(True, linestyle = \"--\", color = \"r\", alpha = 0.3) \n",
    "    plt.show()\n",
    "\n",
    "    print(tend_counts.sort_values(by = 'publishtime', ascending = False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T10:50:09.066688Z",
     "start_time": "2018-11-18T10:50:08.978683Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_server_res(data, url):\n",
    "    '''\n",
    "    服务器接口测试程序\n",
    "    传入 dict, 传出 DataFrame\n",
    "    '''\n",
    "    # data = {'record':[{'id':0,'title':'ss','content':'zzz'},]}\n",
    "    # data = {\"record\":marked_human_data.iloc[:5,:3].to_dict(orient = 'records')}\n",
    "    # url \"http://47.93.77.19:10000/correlation_negative\"\n",
    "    headers={'content-type':'application/json'}\n",
    "    result = requests.post(url,\n",
    "                      data = json.dumps(data),\n",
    "                      headers=headers, allow_redirects=True)\n",
    "    # print(result.text)\n",
    "    json_data = json.loads(result.text)\n",
    "    parse_data = []\n",
    "    elapsed_time = json_data['elapsed_time']\n",
    "    for i in range(len(json_data['docs'])):\n",
    "        parse_data.append([json_data['docs'][i]['id'],\n",
    "                          json_data['docs'][i]['cor']])\n",
    "    parse_data = pd.DataFrame(parse_data, columns = ['id', 'cor'])    \n",
    "    return parse_data, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T10:50:09.174694Z",
     "start_time": "2018-11-18T10:50:09.070689Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_server_res_yjh(data, url, col_name):\n",
    "    '''\n",
    "    服务器接口测试程序\n",
    "    传入 dict, 传出 DataFrame\n",
    "    '''\n",
    "    # data = {'record':[{'id':0,'title':'ss','content':'zzz'},]}\n",
    "    # data = {\"record\":marked_human_data.iloc[:5,:3].to_dict(orient = 'records')}\n",
    "    # url \"http://47.93.77.19:10000/correlation_negative\"\n",
    "    headers={'content-type':'application/json'}\n",
    "    result = requests.post(url,\n",
    "                      data = json.dumps(data),\n",
    "                      headers=headers, allow_redirects=True)\n",
    "    # print(result.text)\n",
    "    json_data = json.loads(result.text)\n",
    "    parse_data = []\n",
    "#     elapsed_time = json_data['elapsed_time']\n",
    "    for i in range(len(json_data['docs'])):\n",
    "        parse_data.append([json_data['docs'][i]['id'],\n",
    "                          json_data['docs'][i][col_name]])\n",
    "    parse_data = pd.DataFrame(parse_data, columns = ['id', col_name])    \n",
    "    return parse_data #, elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T10:50:09.265700Z",
     "start_time": "2018-11-18T10:50:09.179695Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_period_data_for_training(human_additional, warning, url, folder, filename, flag):\n",
    "    combined_data = pd.concat([human_additional, warning])\n",
    "    print('去重前', combined_data.shape)\n",
    "    combined_data = combined_data.drop_duplicates(subset = 'id')\n",
    "    print('去重后', combined_data.shape)\n",
    "\n",
    "    # predict\n",
    "    data = {\"record\":combined_data.loc[:,['id', 'title' ,'content']].to_dict(orient = 'records')}\n",
    "    if flag == 'circ':\n",
    "        parse_data, elapsed_time = get_server_res(data, url)\n",
    "    elif flag == 'cbrc':\n",
    "        col_name = 'sec'\n",
    "        parse_data = get_server_res_yjh(data, url, col_name)\n",
    "        \n",
    "    print(parse_data.shape)\n",
    "    # parse_data.head()  \n",
    "\n",
    "    parse_data.columns = ['id', 'predict_label']\n",
    "    parse_data['predict_label'] = parse_data['predict_label'].apply(lambda x:class_name_dict[x])\n",
    "    parse_data['label'] = ''\n",
    "    # parse_data['cor'] = parse_data['predict_label'].apply(lambda x:1 if x in ['监管', '行业', '经营管理', '消费服务'] else 0)\n",
    "    # parse_data['all_cor'] = parse_data['predict_label'].apply(lambda x:1 if x != '噪音' else 0)\n",
    "    print(parse_data.shape)\n",
    "    # parse_data.head()\n",
    "\n",
    "    combined_data = pd.merge(combined_data, parse_data, on  = 'id')\n",
    "    print(combined_data.head())\n",
    "\n",
    "    file_path = '%s/result/%s'%(folder, filename)\n",
    "    combined_data[['id', 'predict_label', \n",
    "                   'label', 'title', 'content']].to_excel(file_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T10:50:09.403708Z",
     "start_time": "2018-11-18T10:50:09.270700Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_class_data(class_count):\n",
    "    class_count['c'] = class_count['publishtime'] + class_count['classify']\n",
    "    class_count.index = range(class_count.shape[0])\n",
    "    combined_count = {}\n",
    "    for index in class_count.index:\n",
    "        c = class_count.loc[index, 'c']\n",
    "        if c not in combined_count:\n",
    "            combined_count[c] = {}\n",
    "            combined_count[c]['count'] = class_count.loc[index, 'count']\n",
    "        else :\n",
    "            combined_count[c]['count'] = combined_count[c]['count'] + class_count.loc[index, 'count']\n",
    "\n",
    "        combined_count[c]['publishtime'] = class_count.loc[index, 'publishtime']\n",
    "        combined_count[c]['classify'] = class_count.loc[index, 'classify']\n",
    "\n",
    "    class_count = pd.DataFrame().from_dict(combined_count, orient = 'index')\n",
    "    class_count.index = range(class_count.shape[0])    \n",
    "\n",
    "    cor_class = class_count.set_index(['publishtime', 'classify']).unstack()#.reset_index('publishtime')\n",
    "    cor_class['总量'] = cor_class['count'].sum(axis = 1)\n",
    "    cor_class_1 = cor_class.copy()\n",
    "    cor_class_1['非噪音'] = cor_class_1['总量'] - cor_class_1['count', '噪音']\n",
    "    cor_class_1['非噪音-比例'] = cor_class_1['非噪音'] / cor_class_1['总量']\n",
    "    cor_class_1['噪音-比例'] = cor_class_1['count', '噪音'] / cor_class_1['总量']\n",
    "    # cor_class_1.sort_index(ascending = False).head()    \n",
    "    \n",
    "    for k in cor_class['count'].columns.tolist():\n",
    "        cor_class['rate', k] = cor_class['count', k] / cor_class['总量']\n",
    "#     cor_class.sort_index(ascending = False).head()\n",
    "\n",
    "    count_data_7 = cor_class_1[['总量',  '非噪音', '非噪音-比例', '噪音-比例']]\n",
    "    count_data_7.insert(2, '噪音', cor_class_1['count', '噪音'])\n",
    "    count_data_7.columns = ['sum', 'al_cor', 'al_uncor', 'al_cor_rate', 'al_uncor_rate']\n",
    "    count_data_7 = count_data_7.reset_index()\n",
    "\n",
    "    cor_list = ['监管', '行业', '公司内部管理', '消费服务']\n",
    "    count_data_4 = cor_class_1['count'][cor_list].sum(axis = 1).reset_index()\n",
    "    ss = cor_class_1.reset_index()\n",
    "    count_data_4 = pd.merge(count_data_4, ss[['总量', 'publishtime']], on = 'publishtime')\n",
    "    count_data_4.columns = ['publishtime', 'al_cor', 'sum']\n",
    "    count_data_4['al_uncor'] = count_data_4['sum'] - count_data_4['al_cor']\n",
    "    count_data_4['al_cor_rate'] = count_data_4['al_cor'] / count_data_4['sum']\n",
    "    count_data_4['al_uncor_rate'] = count_data_4['al_uncor'] / count_data_4['sum']\n",
    "\n",
    "    return cor_class_1, cor_class, count_data_7, count_data_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T10:50:09.519714Z",
     "start_time": "2018-11-18T10:50:09.407708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今天是： 2018-11-18\n",
      "昨天是： 2018-11-17\n",
      "统计的是昨天的数据，即 2018-11-17 的数据\n",
      "start_day： 2018-10-18\n",
      "end_day： 2018-11-18\n"
     ]
    }
   ],
   "source": [
    "today = datetime.datetime.now()\n",
    "today_str = today.strftime(\"%Y-%m-%d\")\n",
    "yesterday = today - datetime.timedelta(days=1)\n",
    "yesterday_str = yesterday.strftime(\"%Y-%m-%d\")\n",
    "# data_folder = r'D:\\XH\\OneDrive\\网智天元\\4 银保监会\\cbirc_获取用于人工判断数据\\%s'% yesterday_str\n",
    "# if not os.path.exists(data_folder):\n",
    "#     os.makedirs(data_folder)\n",
    "\n",
    "print('今天是：',today.strftime(\"%Y-%m-%d\"))\n",
    "print('昨天是：',yesterday_str)\n",
    "print('统计的是昨天的数据，即 %s 的数据'%yesterday_str)\n",
    "# print('文件存储位置: ', data_folder)\n",
    "\n",
    "start_day = today - datetime.timedelta(days=31) # 30 天\n",
    "start_day = start_day.strftime(\"%Y-%m-%d\") # '2018-08-12'  # 含\n",
    "end_day = today_str # yesterday_str    # 含\n",
    "print('start_day：',start_day)\n",
    "print('end_day：',end_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T10:50:09.640721Z",
     "start_time": "2018-11-18T10:50:09.524715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '补录',\n",
       " 1: '监管',\n",
       " 2: '行业',\n",
       " 3: '产品销售',\n",
       " 4: '资本市场',\n",
       " 5: '公司内部管理',\n",
       " 6: '消费服务',\n",
       " 7: '其他相关报道',\n",
       " 8: '噪音'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dic={'补录':0,'监管':1,'行业':2,'产品销售':3,'资本市场':4,'公司内部管理':5,'消费服务':6,'其他相关报道':7,'噪音':8}\n",
    "class_name_dict = {v: k for k, v in label_dic.items()}\n",
    "class_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T10:50:09.729726Z",
     "start_time": "2018-11-18T10:50:09.644721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': '新闻',\n",
       " '11': '微信',\n",
       " '13': '新闻客户端',\n",
       " '15': '推特',\n",
       " '2': '论坛',\n",
       " '3': '博客',\n",
       " '4': '微博',\n",
       " '5': '纸媒',\n",
       " '6': '视频',\n",
       " '7': '外媒',\n",
       " '8': '广播',\n",
       " '9': '电视'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = '1-新闻，2-论坛，3-博客，4-微博，5-纸媒，6-视频，7-外媒，8-广播，9-电视，11-微信，13-新闻客户端，15-推特'\n",
    "group_dict = dict([x.split('-') for x in group.split('，')])\n",
    "group_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T10:50:09.826732Z",
     "start_time": "2018-11-18T10:50:09.733726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '银监会', 2: '保监会', 3: '中国人寿', 4: '建行北分', 5: '中国人保'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_dic={'银监会':1,'保监会':2,'中国人寿':3,'建行北分':4,'中国人保':5}\n",
    "proj_name_dict = {v: k for k, v in proj_dic.items()}\n",
    "proj_name_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保险业--旧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特殊时间点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:23:52.878481Z",
     "start_time": "2018-11-12T01:23:42.022860Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = specific_func.get_engine('circ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:23:52.913483Z",
     "start_time": "2018-11-12T01:23:52.889482Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "circ_day_thing = [['2018-05-31', '上线倾向性模型'], \n",
    "             ['2018-06-12', '更新倾向性模型'], \n",
    "             ['2018-06-13', '更新倾向性模型'], \n",
    "             ['2018-06-15', '更新相关性模型'], \n",
    "             ['2018-06-19', '修复bug'], \n",
    "             ['2018-06-24', '更新相关性模型'],\n",
    "             ['2018-06-24', '上线预警模型'], \n",
    "             ['2018-06-25', '更新相关性模型（加入交集数据作为噪音）']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 八分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:24:04.314135Z",
     "start_time": "2018-11-12T01:23:52.917483Z"
    }
   },
   "outputs": [],
   "source": [
    "# 相关数据\n",
    "sql_circ_cor = \"select date_format(t1.publishtime,'%%Y-%%m-%%d') as publishtime, t1.classify, \\\n",
    "                            count(t1.id) as count \\\n",
    "                            from wise_web_docinfo t1 \\\n",
    "                                where (date_format(publishtime, '%%Y-%%m-%%d') >= '{0}' and \\\n",
    "                                      date_format(publishtime, '%%Y-%%m-%%d') <= '{1}') \\\n",
    "                                group by date_format(t1.publishtime,'%%Y-%%m-%%d'), t1.classify \\\n",
    "                                order by date_format(t1.publishtime,'%%Y-%%m-%%d') desc\".format(start_day, end_day) \n",
    "\n",
    "circ_cor_count = pd.read_sql(sql_circ_cor, engine)\n",
    "circ_cor_count['classify'] = circ_cor_count['classify'].apply(lambda x:class_name_dict[x])\n",
    "circ_cor_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:32:01.024402Z",
     "start_time": "2018-11-12T01:24:04.327136Z"
    }
   },
   "outputs": [],
   "source": [
    "# 不相关数据\n",
    "sql_circ_uncor = \"select date_format(t1.publishtime,'%%Y-%%m-%%d') as publishtime,t1.classify, count(t1.id) as count \\\n",
    "                            from wise_web_docinfo_uncorr t1 \\\n",
    "                                where (date_format(t1.publishtime, '%%Y-%%m-%%d') >= '{0}' and \\\n",
    "                                      date_format(t1.publishtime, '%%Y-%%m-%%d') <= '{1}') \\\n",
    "                                group by t1.classify, date_format(t1.publishtime,'%%Y-%%m-%%d') \\\n",
    "                                order by date_format(t1.publishtime,'%%Y-%%m-%%d') desc\".format(start_day, end_day) \n",
    "\n",
    "circ_uncor_count = pd.read_sql(sql_circ_uncor, engine)\n",
    "circ_uncor_count['classify'] = circ_uncor_count['classify'].apply(lambda x:class_name_dict[x])\n",
    "circ_uncor_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 补录数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:32:01.640437Z",
     "start_time": "2018-11-12T01:32:01.032402Z"
    }
   },
   "outputs": [],
   "source": [
    "# 补录\n",
    "apend = circ_cor_count[circ_cor_count['classify'] == '补录'][['publishtime', 'count']]\n",
    "apend.columns = ['publishtime', '补录']\n",
    "apend = apend.sort_values(by = 'publishtime', ascending = True)\n",
    "apend.plot(kind = 'bar', x = 'publishtime', y = '补录', figsize=(15,6), \n",
    "           title = '补录数据-每天', grid = True)\n",
    "apend.sort_values(by = 'publishtime', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:32:02.012458Z",
     "start_time": "2018-11-12T01:32:01.643437Z"
    }
   },
   "outputs": [],
   "source": [
    "class_count = pd.concat([circ_cor_count, circ_uncor_count])\n",
    "cor_class_1, cor_class, count_data_7, count_data_4 = get_class_data(class_count)\n",
    "cor_class_1.sort_index(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:32:02.371479Z",
     "start_time": "2018-11-12T01:32:02.015458Z"
    }
   },
   "outputs": [],
   "source": [
    "cor_class['rate'].reset_index().fillna(0).plot(x = 'publishtime', figsize = (15,6))\n",
    "cor_class.sort_index(ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:32:02.974513Z",
     "start_time": "2018-11-12T01:32:02.376479Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_cor(count_data_7, circ_day_thing, \"CIRC 8-class cor&uncor:7-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:32:03.474542Z",
     "start_time": "2018-11-12T01:32:02.977513Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_cor(count_data_4, circ_day_thing, \"CIRC 8-class cor&uncor:4-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 倾向性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:32:30.612094Z",
     "start_time": "2018-11-12T01:32:03.479542Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_tend = \"select date_format(t1.publishtime,'%%Y-%%m-%%d') as publishtime, t1.tendency, \\\n",
    "                            count(t1.id) as count \\\n",
    "                            from wise_web_docinfo t1 \\\n",
    "                                where (date_format(publishtime, '%%Y-%%m-%%d') >= '{0}' and \\\n",
    "                                      date_format(publishtime, '%%Y-%%m-%%d') <= '{1}') \\\n",
    "                                group by date_format(t1.publishtime,'%%Y-%%m-%%d'), t1.tendency \\\n",
    "                                order by date_format(t1.publishtime,'%%Y-%%m-%%d') desc\".format(start_day, end_day) \n",
    "\n",
    "tend_count = pd.read_sql(sql_tend, engine)\n",
    "tend_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:32:31.164125Z",
     "start_time": "2018-11-12T01:32:30.617094Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_tend(tend_count, circ_day_thing, \"CIRC - tendency \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### group_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:32:31.178126Z",
     "start_time": "2018-11-12T01:32:31.166126Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sql_tend_group = \"select date_format(t1.publishtime,'%%Y-%%m-%%d') as publishtime, \\\n",
    "#                             t1.tendency, t1.group_id, count(t1.id) as cor_count \\\n",
    "#                             from wise_web_docinfo t1 \\\n",
    "#                                 where (date_format(t1.publishtime, '%%Y-%%m-%%d') >= '{0}' and \\\n",
    "#                                       date_format(t1.publishtime, '%%Y-%%m-%%d') <= '{1}') \\\n",
    "#                                 group by date_format(t1.publishtime,'%%Y-%%m-%%d'), t1.tendency, t1.group_id \\\n",
    "#                                 order by date_format(t1.publishtime,'%%Y-%%m-%%d') desc\".format(start_day, end_day) \n",
    "\n",
    "# tend_group_count = pd.read_sql(sql_tend_group, engine)\n",
    "# tend_group_count['group_id'] = tend_group_count['group_id'].apply(lambda x: group_dict[str(x)])\n",
    "# tend_group_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 补录和预警"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一周数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:32:31.375138Z",
     "start_time": "2018-11-12T01:32:31.188127Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_start_day = '2018-10-27'\n",
    "add_end_day = '2018-11-02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:32:47.063035Z",
     "start_time": "2018-11-12T01:32:31.385138Z"
    }
   },
   "outputs": [],
   "source": [
    "# 人工补录\n",
    "sql_human_additional = \"select t1.id, t1.group_id, date_format(t1.publishtime,'%%Y-%%m-%%d') as publishtime,  \\\n",
    "                            t1.gather_type, t1.submited, t1.title, t2.center as content\\\n",
    "                            from wise_web_docinfo t1, wise_web_docinfo_center t2 \\\n",
    "                                where (date_format(publishtime, '%%Y-%%m-%%d') >= '{0}' and \\\n",
    "                                      date_format(publishtime, '%%Y-%%m-%%d') <= '{1}') and \\\n",
    "                                      t1.id = t2.doc_id and \\\n",
    "                                      t1.gather_type = 1 \".format(add_start_day, add_end_day) \n",
    "\n",
    "human_additional = pd.read_sql(sql_human_additional, engine)\n",
    "print(human_additional.shape)\n",
    "# human_additional.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:32:58.772705Z",
     "start_time": "2018-11-12T01:32:47.067035Z"
    }
   },
   "outputs": [],
   "source": [
    "# 预警数据\n",
    "sql_warning =  \"select t1.id, t1.group_id, date_format(t1.publishtime,'%%Y-%%m-%%d') as publishtime,  \\\n",
    "                            t1.gather_type, t1.submited, t1.title, t2.center as content\\\n",
    "                            from wise_web_docinfo t1, wise_web_docinfo_center t2 \\\n",
    "                                where (date_format(publishtime, '%%Y-%%m-%%d') >= '{0}' and \\\n",
    "                                      date_format(publishtime, '%%Y-%%m-%%d') <= '{1}') and \\\n",
    "                                      t1.id = t2.doc_id and \\\n",
    "                                      t1.submited = 1 \".format(add_start_day, add_end_day) \n",
    "\n",
    "warning = pd.read_sql(sql_warning, engine)\n",
    "print(warning.shape)\n",
    "# warning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:32:58.895712Z",
     "start_time": "2018-11-12T01:32:58.782705Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_data = pd.concat([human_additional, warning])\n",
    "print('去重前', combined_data.shape)\n",
    "combined_data = combined_data.drop_duplicates(subset = 'id')\n",
    "print('去重后', combined_data.shape)\n",
    "\n",
    "combined_data['group_id'] = combined_data['group_id'].apply(lambda x:group_dict[str(x)])\n",
    "combined_data['gather_type'] = combined_data['gather_type'].replace(1, '人工补录').replace(2, '人工修改')\n",
    "combined_data['submited'] = combined_data['submited'].replace(0, '不预警').replace(1, '预警')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:33:03.361967Z",
     "start_time": "2018-11-12T01:32:58.898712Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "data = {\"record\":combined_data.loc[:,['id', 'title' ,'content']].to_dict(orient = 'records')}\n",
    "# url = \"http://192.168.0.104:11000/judge_correlation_i\"\n",
    "url = \"http://47.93.77.19:10000/judge_correlation_i\"\n",
    "parse_data, elapsed_time = get_server_res(data, url)\n",
    "# parse_data.head()  \n",
    "\n",
    "parse_data.columns = ['id', 'predict_label']\n",
    "parse_data['predict_label'] = parse_data['predict_label'].apply(lambda x:class_name_dict[x])\n",
    "parse_data['label'] = ''\n",
    "parse_data['cor'] = parse_data['predict_label'].apply(lambda x:1 if x in ['监管', '行业', '经营管理', '消费服务'] else 0)\n",
    "parse_data['all_cor'] = parse_data['predict_label'].apply(lambda x:1 if x != '噪音' else 0)\n",
    "parse_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:33:03.447972Z",
     "start_time": "2018-11-12T01:33:03.363967Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data = pd.merge(combined_data, parse_data, on  = 'id')\n",
    "stat = combined_data.groupby(['group_id', 'gather_type', 'submited'])['id'].count().reset_index()\n",
    "\n",
    "# 补录\n",
    "stat_a = combined_data.groupby(['group_id', 'gather_type'])['id'].count().reset_index()\n",
    "stat_a = stat_a[stat_a['gather_type'] == '人工补录']\n",
    "\n",
    "# 补录且预警\n",
    "stat_a_w = combined_data[combined_data['submited'] == '预警'].groupby(['group_id', 'gather_type'])['id'].count().reset_index()\n",
    "stat_a_w = stat_a_w[stat_a_w['gather_type'] == '人工补录']\n",
    "\n",
    "# 预警\n",
    "stat_w = combined_data.groupby(['group_id', 'submited'])['id'].count().reset_index()\n",
    "stat_w = stat_w[stat_w['submited'] == '预警']\n",
    "\n",
    "# 补录-过算法\n",
    "stat_a_cor = combined_data[combined_data['gather_type'] == '人工补录'].groupby(['group_id', 'cor'])['id'].count().reset_index()\n",
    "stat_a_cor = stat_a_cor[stat_a_cor['cor'] == 1]\n",
    "\n",
    "# 补录且预警-过算法\n",
    "stat_a_w_cor = combined_data[(combined_data['submited'] == '预警') & \\\n",
    "                             (combined_data['gather_type'] == '人工补录')\\\n",
    "                            ].groupby(['group_id', 'cor'])['id'].count().reset_index()\n",
    "stat_a_w_cor = stat_a_w_cor[stat_a_w_cor['cor'] == 1]\n",
    "\n",
    "# 补录-过算法\n",
    "stat_a_cor_7 = combined_data[combined_data['gather_type'] == '人工补录'].groupby(['group_id', 'all_cor'])['id'].count().reset_index()\n",
    "stat_a_cor_7 = stat_a_cor_7[stat_a_cor_7['all_cor'] == 1]\n",
    "\n",
    "# 补录且预警-过算法\n",
    "stat_a_w_cor_7 = combined_data[(combined_data['submited'] == '预警') & \\\n",
    "                             (combined_data['gather_type'] == '人工补录')\\\n",
    "                            ].groupby(['group_id', 'all_cor'])['id'].count().reset_index()\n",
    "stat_a_w_cor_7 = stat_a_w_cor_7[stat_a_w_cor_7['all_cor'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:33:03.482974Z",
     "start_time": "2018-11-12T01:33:03.449972Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stat_a = stat_a[['group_id', 'id']]\n",
    "stat_a.columns = ['来源', '补录']\n",
    "stat_a_w = stat_a_w[['group_id', 'id']]\n",
    "stat_a_w.columns = ['来源', '补录且预警']\n",
    "stat_w = stat_w[['group_id', 'id']]\n",
    "stat_w.columns = ['来源', '预警数量']\n",
    "stat_a_cor = stat_a_cor[['group_id', 'id']]\n",
    "stat_a_cor.columns = ['来源', '补录&过算法(4类)']\n",
    "stat_a_w_cor = stat_a_w_cor[['group_id', 'id']]\n",
    "stat_a_w_cor.columns = ['来源', '补录且预警&过算法(4类)']\n",
    "stat_a_cor_7 = stat_a_cor_7[['group_id', 'id']]\n",
    "stat_a_cor_7.columns = ['来源', '补录&过算法(7类)']\n",
    "stat_a_w_cor_7 = stat_a_w_cor_7[['group_id', 'id']]\n",
    "stat_a_w_cor_7.columns = ['来源', '补录且预警&过算法(7类)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:33:03.662984Z",
     "start_time": "2018-11-12T01:33:03.484974Z"
    }
   },
   "outputs": [],
   "source": [
    "stat = pd.merge(stat_a, stat_w, on = '来源', how = 'outer')\n",
    "stat = pd.merge(stat, stat_a_w, on = '来源', how = 'outer')\n",
    "# stat = pd.merge(stat, stat_a_cor, on = '来源', how = 'outer')\n",
    "# stat = pd.merge(stat, stat_a_w_cor, on = '来源', how = 'outer')\n",
    "stat = pd.merge(stat, stat_a_cor_7, on = '来源', how = 'outer')\n",
    "stat = pd.merge(stat, stat_a_w_cor_7, on = '来源', how = 'outer')\n",
    "stat = stat.set_index('来源').stack().unstack(0)\n",
    "stat['总量'] =  stat.sum(axis = 1)\n",
    "stat.loc['补录且预警 / 预警-比例'] = stat.loc['补录且预警'] / stat.loc['预警数量'] \n",
    "stat.loc['补录且预警 / 预警-比例'] = stat.loc['补录且预警 / 预警-比例'].apply(lambda x: '{:.0f}%'.format(x*100))\n",
    "stat.loc['补录且预警 / 补录-比例'] = stat.loc['补录且预警'] / stat.loc['补录'] \n",
    "stat.loc['补录且预警 / 补录-比例'] = stat.loc['补录且预警 / 补录-比例'].apply(lambda x: '{:.0f}%'.format(x*100))\n",
    "# stat.loc['补录&过算法(4类) / 补录-比例'] = stat.loc['补录&过算法(4类)'] / stat.loc['补录'] \n",
    "# stat.loc['补录&过算法(4类) / 补录-比例'] = stat.loc['补录&过算法(4类) / 补录-比例'].apply(lambda x: '{:.0f}%'.format(x*100))\n",
    "# stat.loc['补录且预警&过算法(4类) / 预警-比例'] = stat.loc['补录且预警&过算法(4类)'] / stat.loc['预警数量'] \n",
    "# stat.loc['补录且预警&过算法(4类) / 预警-比例'] = stat.loc['补录且预警&过算法(4类) / 预警-比例'].apply(lambda x: '{:.0f}%'.format(x*100))\n",
    "stat.loc['补录&过算法(7类) / 补录-比例'] = stat.loc['补录&过算法(7类)'] / stat.loc['补录'] \n",
    "stat.loc['补录&过算法(7类) / 补录-比例'] = stat.loc['补录&过算法(7类) / 补录-比例'].apply(lambda x: '{:.0f}%'.format(x*100))\n",
    "stat.loc['补录且预警&过算法(7类) / 补录且预警-比例'] = stat.loc['补录且预警&过算法(7类)'] / stat.loc['补录且预警'] \n",
    "stat.loc['补录且预警&过算法(7类) / 补录且预警-比例'] = stat.loc['补录且预警&过算法(7类) / 补录且预警-比例'].apply(lambda x: '{:.0f}%'.format(x*100))\n",
    "stat.index.name = '保监会：{0} 到 {1}'.format(add_start_day, add_end_day)\n",
    "stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出一段时间补录数据用于训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:33:03.683986Z",
     "start_time": "2018-11-12T01:33:03.665984Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 人工补录\n",
    "sql_human_additional = \"select t1.id, t1.group_id, date_format(t1.publishtime,'%%Y-%%m-%%d') as publishtime,  \\\n",
    "                            t1.gather_type, t1.submited, t1.title, t2.center as content\\\n",
    "                            from wise_web_docinfo t1, wise_web_docinfo_center t2 \\\n",
    "                                where (date_format(publishtime, '%%Y-%%m-%%d') >= '{0}' and \\\n",
    "                                      date_format(publishtime, '%%Y-%%m-%%d') <= '{1}') and \\\n",
    "                                      t1.id = t2.doc_id and \\\n",
    "                                      t1.gather_type = 1 \".format('2018-08-20', '2018-09-16') \n",
    "\n",
    "# human_additional = pd.read_sql(sql_human_additional, engine)\n",
    "# print(human_additional.shape)\n",
    "# human_additional.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:33:03.797992Z",
     "start_time": "2018-11-12T01:33:03.687986Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 预警数据\n",
    "sql_warning =  \"select t1.id, t1.group_id, date_format(t1.publishtime,'%%Y-%%m-%%d') as publishtime,  \\\n",
    "                            t1.gather_type, t1.submited, t1.title, t2.center as content\\\n",
    "                            from wise_web_docinfo t1, wise_web_docinfo_center t2 \\\n",
    "                                where (date_format(publishtime, '%%Y-%%m-%%d') >= '{0}' and \\\n",
    "                                      date_format(publishtime, '%%Y-%%m-%%d') <= '{1}') and \\\n",
    "                                      t1.id = t2.doc_id and \\\n",
    "                                      t1.submited = 1 \".format('2018-08-20', '2018-09-16') \n",
    "\n",
    "# warning = pd.read_sql(sql_warning, engine)\n",
    "# print(warning.shape)\n",
    "# warning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:33:03.886997Z",
     "start_time": "2018-11-12T01:33:03.806993Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    # url = \"http://192.168.0.104:11000/judge_correlation_i\"\n",
    "    url = \"http://47.93.77.19:10000/judge_correlation_i\"\n",
    "    folder = 'circ_result_class'\n",
    "    filename = 'circ_add&warning_20180917(0820-0916).xlsx'\n",
    "    get_period_data_for_training(human_additional, warning, url, folder, filename, 'circ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 银行业--旧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特殊时间点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:33:04.033005Z",
     "start_time": "2018-11-12T01:33:03.889997Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = specific_func.get_engine('cbrc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:33:04.049006Z",
     "start_time": "2018-11-12T01:33:04.037006Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cbrc_day_thing = [['2018-05-02', '相关性模型'], \n",
    "             ['2018-06-01', '更新相关性模型'], \n",
    "             ['2018-06-12', '更新相关性模型'], \n",
    "             ['2018-06-12', '上线倾向性模型']\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 八分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:34:30.282939Z",
     "start_time": "2018-11-12T01:33:04.053007Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_cbrc = \"select date_format(t1.publishtime,'%%Y-%%m-%%d') as publishtime, \\\n",
    "                        t2.traffic_id as classify, count(t1.id) as count \\\n",
    "                            from wise_web_docinfo_basic t1, wise_web_classify_traffic_docinfo t2 \\\n",
    "                                where (date_format(t1.publishtime, '%%Y-%%m-%%d') >= '{0}' and \\\n",
    "                                      date_format(t1.publishtime, '%%Y-%%m-%%d') <= '{1}') and \\\n",
    "                                      t2.base_id=t1.id \\\n",
    "                                group by date_format(t1.publishtime,'%%Y-%%m-%%d'), t2.traffic_id \\\n",
    "                                order by date_format(t1.publishtime,'%%Y-%%m-%%d') desc\".format(start_day, end_day) \n",
    "\n",
    "cbrc_count = pd.read_sql(sql_cbrc, engine)\n",
    "cbrc_count['classify'] = cbrc_count['classify'].apply(lambda x:class_name_dict[x])\n",
    "cbrc_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:34:30.366944Z",
     "start_time": "2018-11-12T01:34:30.286939Z"
    }
   },
   "outputs": [],
   "source": [
    "class_count = cbrc_count\n",
    "cor_class_1, cor_class, count_data_7, count_data_4 = get_class_data(class_count)\n",
    "cor_class_1.sort_index(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:34:30.757966Z",
     "start_time": "2018-11-12T01:34:30.373944Z"
    }
   },
   "outputs": [],
   "source": [
    "cor_class['rate'].reset_index().fillna(0).plot(x = 'publishtime', figsize = (15,6))\n",
    "cor_class.sort_index(ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T06:21:17.584594Z",
     "start_time": "2018-09-18T06:21:17.570593Z"
    }
   },
   "source": [
    "### 总体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:34:31.472007Z",
     "start_time": "2018-11-12T01:34:30.761966Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_cor(count_data_7, cbrc_day_thing, \"CBRC 8-class cor&uncor:7-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:34:31.973035Z",
     "start_time": "2018-11-12T01:34:31.480007Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_cor(count_data_4, cbrc_day_thing, \"CBRC 8-class cor&uncor:4-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 倾向性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:40:20.246753Z",
     "start_time": "2018-11-12T01:34:31.976036Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_tend = \"select date_format(t1.publishtime,'%%Y-%%m-%%d') as publishtime, t1.sen as tendency, count(t1.id) as cor_count \\\n",
    "                            from elint_web_docinfo t1 \\\n",
    "                                where (date_format(t1.publishtime, '%%Y-%%m-%%d') >= '{0}' and \\\n",
    "                                      date_format(t1.publishtime, '%%Y-%%m-%%d') <= '{1}') \\\n",
    "                                group by date_format(t1.publishtime,'%%Y-%%m-%%d'), t1.sen \\\n",
    "                                order by date_format(t1.publishtime,'%%Y-%%m-%%d') desc\".format(start_day, end_day) \n",
    "\n",
    "tend_count = pd.read_sql(sql_tend, engine)\n",
    "tend_count = tend_count[tend_count['tendency'] != 1]\n",
    "tend_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:40:20.788784Z",
     "start_time": "2018-11-12T01:40:20.273754Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_tend(tend_count, cbrc_day_thing, \"CBRC - tendency \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 补录和预警"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 补录数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:40:21.715837Z",
     "start_time": "2018-11-12T01:40:20.790784Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_human_additional = \"select date_format(t1.publishtime,'%%Y-%%m-%%d') as publishtime,  \\\n",
    "                            t1.gather_type, count(t1.id) as count \\\n",
    "                            from elint_web_docinfo t1 \\\n",
    "                                where (date_format(publishtime, '%%Y-%%m-%%d') >= '{0}' and \\\n",
    "                                      date_format(publishtime, '%%Y-%%m-%%d') <= '{1}') and \\\n",
    "                                      t1.gather_type = 1 \\\n",
    "                                group by date_format(t1.publishtime,'%%Y-%%m-%%d') \\\n",
    "                                order by date_format(t1.publishtime,'%%Y-%%m-%%d') desc\".format(start_day, end_day) \n",
    "\n",
    "human_additional_count = pd.read_sql(sql_human_additional, engine)\n",
    "human_additional_count.sort_values(by = 'publishtime', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:40:22.311871Z",
     "start_time": "2018-11-12T01:40:21.720837Z"
    }
   },
   "outputs": [],
   "source": [
    "human_additional_count = human_additional_count.sort_values(by = 'publishtime')\n",
    "fig = plt.figure(figsize = (15,6))\n",
    "ax1 = fig.add_subplot(111)\n",
    "human_additional_count.plot(x = 'publishtime', y = 'count', kind = 'bar', figsize = (15, 6), ax = ax1)\n",
    "ax1.set_ylabel('数据量', fontsize = 16)\n",
    "ax1.set_title(\"（银监会）人工补录\", fontsize = 20)\n",
    "\n",
    "ax2 = ax1.twinx()  # this is the important function\n",
    "ax2.set_ylim(0, 1)\n",
    "y_list = [0.65, 0.75, 0.85, 0.95]\n",
    "m = 0\n",
    "for [d, t] in cbrc_day_thing:    \n",
    "    if d in human_additional_count['publishtime'].tolist():\n",
    "        x = human_additional_count['publishtime'].tolist().index(d)\n",
    "        ax2.axvline(x=x, ymin = y_list[m] - 0.1, ymax = y_list[m] + 0.1, \n",
    "                    color='k', linestyle = \"--\", alpha = 0.75)\n",
    "        ax2.text(x - 0.25, y_list[m], t, va='center', fontsize = 12)\n",
    "        if m == 3: \n",
    "            m = 0\n",
    "        else :\n",
    "            m += 1\n",
    "        \n",
    "plt.grid(True, linestyle = \"--\", color = \"r\", alpha = 0.3) \n",
    "plt.show()\n",
    "\n",
    "human_additional_count.sort_values(by = 'publishtime', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一周数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:40:22.319871Z",
     "start_time": "2018-11-12T01:40:22.313871Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_start_day = '2018-10-27'\n",
    "add_end_day = '2018-11-02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:40:23.223923Z",
     "start_time": "2018-11-12T01:40:22.323872Z"
    }
   },
   "outputs": [],
   "source": [
    "# 人工补录\n",
    "sql_human_additional = \"select t1.id, t1.group_id, date_format(t1.publishtime,'%%Y-%%m-%%d') as publishtime,  \\\n",
    "                            t1.gather_type, t1.sec, t1.title, t2.text as content\\\n",
    "                            from elint_web_docinfo t1, wise_web_docinfo_text t2\\\n",
    "                                where (date_format(publishtime, '%%Y-%%m-%%d') >= '{0}' and \\\n",
    "                                      date_format(publishtime, '%%Y-%%m-%%d') <= '{1}') and \\\n",
    "                                      t1.id = t2.doc_id and \\\n",
    "                                      t1.gather_type = 1 \".format(add_start_day, add_end_day) \n",
    "\n",
    "human_additional = pd.read_sql(sql_human_additional, engine)\n",
    "print(human_additional.shape)\n",
    "# human_additional.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:40:29.936307Z",
     "start_time": "2018-11-12T01:40:23.228923Z"
    }
   },
   "outputs": [],
   "source": [
    "# 预警数据\n",
    "sql_warning =  \"select t1.id, t1.group_id, date_format(t1.publishtime,'%%Y-%%m-%%d') as publishtime,  \\\n",
    "                            t1.gather_type, t1.sec, t1.title, t2.text as content\\\n",
    "                            from elint_web_docinfo t1, wise_web_docinfo_text t2\\\n",
    "                                where (date_format(publishtime, '%%Y-%%m-%%d') >= '{0}' and \\\n",
    "                                      date_format(publishtime, '%%Y-%%m-%%d') <= '{1}') and \\\n",
    "                                      t1.id = t2.doc_id and \\\n",
    "                                      t1.sec in (7,8,9) \".format(add_start_day, add_end_day)  \n",
    "\n",
    "warning = pd.read_sql(sql_warning, engine)\n",
    "print(warning.shape)\n",
    "# warning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:40:30.041313Z",
     "start_time": "2018-11-12T01:40:29.943308Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_data = pd.concat([human_additional, warning])\n",
    "print('去重前', combined_data.shape)\n",
    "combined_data = combined_data.drop_duplicates(subset = 'id')\n",
    "print('去重后', combined_data.shape)\n",
    "\n",
    "combined_data['group_id'] = combined_data['group_id'].apply(lambda x:group_dict[str(x)])\n",
    "combined_data['gather_type'] = combined_data['gather_type'].replace(0, '系统采集').replace(1, '人工补录').replace(2, '人工修改')\n",
    "combined_data['submited'] = combined_data['sec'].apply(lambda x: '预警' if x in [7,8,9] else '不预警')\n",
    "# combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:40:30.057314Z",
     "start_time": "2018-11-12T01:40:30.044313Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_data.groupby(['gather_type', 'group_id', 'submited'])['id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:40:37.359732Z",
     "start_time": "2018-11-12T01:40:30.061314Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "data = {\"record\":combined_data.loc[:,['id', 'title' ,'content']].to_dict(orient = 'records')}\n",
    "# url = \"http://192.168.0.104:11000/judge_correlation_yjh\"\n",
    "url = \"http://47.93.77.19:6001/judge_correlation_yjh\"\n",
    "parse_data = get_server_res_yjh(data, url, 'sec')\n",
    "# parse_data.head()  \n",
    "\n",
    "parse_data.columns = ['id', 'predict_label']\n",
    "parse_data['predict_label'] = parse_data['predict_label'].apply(lambda x:class_name_dict[x])\n",
    "parse_data['label'] = ''\n",
    "parse_data['cor'] = parse_data['predict_label'].apply(lambda x:1 if x in ['监管', '行业', '经营管理', '消费服务'] else 0)\n",
    "parse_data['all_cor'] = parse_data['predict_label'].apply(lambda x:1 if x != '噪音' else 0)\n",
    "parse_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:40:37.456737Z",
     "start_time": "2018-11-12T01:40:37.363732Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_data = pd.merge(combined_data, parse_data, on  = 'id')\n",
    "stat = combined_data.groupby(['group_id', 'gather_type', 'submited'])['id'].count().reset_index()\n",
    "\n",
    "# 补录\n",
    "stat_a = combined_data.groupby(['group_id', 'gather_type'])['id'].count().reset_index()\n",
    "stat_a = stat_a[stat_a['gather_type'] == '人工补录']\n",
    "\n",
    "# 补录且预警\n",
    "stat_a_w = combined_data[combined_data['submited'] == '预警'].groupby(['group_id', 'gather_type'])['id'].count().reset_index()\n",
    "stat_a_w = stat_a_w[stat_a_w['gather_type'] == '人工补录']\n",
    "\n",
    "# 预警\n",
    "stat_w = combined_data.groupby(['group_id', 'submited'])['id'].count().reset_index()\n",
    "stat_w = stat_w[stat_w['submited'] == '预警']\n",
    "\n",
    "# 补录-过算法\n",
    "stat_a_cor = combined_data[combined_data['gather_type'] == '人工补录'].groupby(['group_id', 'cor'])['id'].count().reset_index()\n",
    "stat_a_cor = stat_a_cor[stat_a_cor['cor'] == 1]\n",
    "\n",
    "# 补录且预警-过算法\n",
    "stat_a_w_cor = combined_data[(combined_data['submited'] == '预警') & \\\n",
    "                             (combined_data['gather_type'] == '人工补录')\\\n",
    "                            ].groupby(['group_id', 'cor'])['id'].count().reset_index()\n",
    "stat_a_w_cor = stat_a_w_cor[stat_a_w_cor['cor'] == 1]\n",
    "\n",
    "# 补录-过算法\n",
    "stat_a_cor_7 = combined_data[combined_data['gather_type'] == '人工补录'].groupby(['group_id', 'all_cor'])['id'].count().reset_index()\n",
    "stat_a_cor_7 = stat_a_cor_7[stat_a_cor_7['all_cor'] == 1]\n",
    "\n",
    "# 补录且预警-过算法\n",
    "stat_a_w_cor_7 = combined_data[(combined_data['submited'] == '预警') & \\\n",
    "                             (combined_data['gather_type'] == '人工补录')\\\n",
    "                            ].groupby(['group_id', 'all_cor'])['id'].count().reset_index()\n",
    "stat_a_w_cor_7 = stat_a_w_cor_7[stat_a_w_cor_7['all_cor'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:40:37.514741Z",
     "start_time": "2018-11-12T01:40:37.458737Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stat_a = stat_a[['group_id', 'id']]\n",
    "stat_a.columns = ['来源', '补录']\n",
    "stat_a_w = stat_a_w[['group_id', 'id']]\n",
    "stat_a_w.columns = ['来源', '补录且预警']\n",
    "stat_w = stat_w[['group_id', 'id']]\n",
    "stat_w.columns = ['来源', '预警数量']\n",
    "stat_a_cor = stat_a_cor[['group_id', 'id']]\n",
    "stat_a_cor.columns = ['来源', '补录&过算法(4类)']\n",
    "stat_a_w_cor = stat_a_w_cor[['group_id', 'id']]\n",
    "stat_a_w_cor.columns = ['来源', '补录且预警&过算法(4类)']\n",
    "stat_a_cor_7 = stat_a_cor_7[['group_id', 'id']]\n",
    "stat_a_cor_7.columns = ['来源', '补录&过算法(7类)']\n",
    "stat_a_w_cor_7 = stat_a_w_cor_7[['group_id', 'id']]\n",
    "stat_a_w_cor_7.columns = ['来源', '补录且预警&过算法(7类)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:40:37.622747Z",
     "start_time": "2018-11-12T01:40:37.516741Z"
    }
   },
   "outputs": [],
   "source": [
    "stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:40:37.772755Z",
     "start_time": "2018-11-12T01:40:37.630747Z"
    }
   },
   "outputs": [],
   "source": [
    "stat = pd.merge(stat_a, stat_w, on = '来源', how = 'outer')\n",
    "stat = pd.merge(stat, stat_a_w, on = '来源', how = 'outer')\n",
    "stat = pd.merge(stat, stat_a_cor, on = '来源')\n",
    "stat = pd.merge(stat, stat_a_w_cor, on = '来源')\n",
    "stat = pd.merge(stat, stat_a_cor_7, on = '来源', how = 'outer')\n",
    "stat = pd.merge(stat, stat_a_w_cor_7, on = '来源', how = 'outer')\n",
    "stat = stat.set_index('来源').stack().unstack(0)\n",
    "stat = stat.fillna(0)\n",
    "stat['总量'] =  stat.sum(axis = 1)\n",
    "stat.loc['补录且预警 / 预警-比例'] = stat.loc['补录且预警'] / stat.loc['预警数量'] \n",
    "stat.loc['补录且预警 / 预警-比例'] = stat.loc['补录且预警 / 预警-比例'].apply(lambda x: '{:.0f}%'.format(x*100))\n",
    "# stat.loc['补录且预警 / 补录-比例'] = stat.loc['补录且预警'] / stat.loc['补录'] \n",
    "# stat.loc['补录且预警 / 补录-比例'] = stat.loc['补录且预警 / 补录-比例'].apply(lambda x: '{:.0f}%'.format(x*100))\n",
    "# stat.loc['补录&过算法(4类) / 补录-比例'] = stat.loc['补录&过算法(4类)'] / stat.loc['补录'] \n",
    "# stat.loc['补录&过算法(4类) / 补录-比例'] = stat.loc['补录&过算法(4类) / 补录-比例'].apply(lambda x: '{:.0f}%'.format(x*100))\n",
    "# stat.loc['补录且预警&过算法(4类) / 预警-比例'] = stat.loc['补录且预警&过算法(4类)'] / stat.loc['预警数量'] \n",
    "# stat.loc['补录且预警&过算法(4类) / 预警-比例'] = stat.loc['补录且预警&过算法(4类) / 预警-比例'].apply(lambda x: '{:.0f}%'.format(x*100))\n",
    "# stat.loc['补录&过算法(7类) / 补录-比例'] = stat.loc['补录&过算法(7类)'] / stat.loc['补录'] \n",
    "# stat.loc['补录&过算法(7类) / 补录-比例'] = stat.loc['补录&过算法(7类) / 补录-比例'].apply(lambda x: '{:.0f}%'.format(x*100))\n",
    "# stat.loc['补录且预警&过算法(7类) / 补录且预警-比例'] = stat.loc['补录且预警&过算法(7类)'] / stat.loc['补录且预警'] \n",
    "# stat.loc['补录且预警&过算法(7类) / 补录且预警-比例'] = stat.loc['补录且预警&过算法(7类) / 补录且预警-比例'].apply(lambda x: '{:.0f}%'.format(x*100))\n",
    "stat.index.name = '保监会：{0} 到 {1}'.format(add_start_day, add_end_day)\n",
    "stat.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出一段时间补录数据用于训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:40:37.851760Z",
     "start_time": "2018-11-12T01:40:37.779756Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 人工补录\n",
    "sql_human_additional = \"select t1.id, t1.group_id, date_format(t1.publishtime,'%%Y-%%m-%%d') as publishtime,  \\\n",
    "                            t1.gather_type, t1.sec, t1.title, t2.text as content\\\n",
    "                            from elint_web_docinfo t1, wise_web_docinfo_text t2\\\n",
    "                                where (date_format(publishtime, '%%Y-%%m-%%d') >= '{0}' and \\\n",
    "                                      date_format(publishtime, '%%Y-%%m-%%d') <= '{1}') and \\\n",
    "                                      t1.id = t2.doc_id and \\\n",
    "                                      t1.gather_type = 1 \".format('2018-08-20', '2018-09-16') \n",
    "\n",
    "# human_additional = pd.read_sql(sql_human_additional, engine)\n",
    "# print(human_additional.shape)\n",
    "# human_additional.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:40:37.918764Z",
     "start_time": "2018-11-12T01:40:37.855760Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 预警数据\n",
    "sql_warning =  \"select t1.id, t1.group_id, date_format(t1.publishtime,'%%Y-%%m-%%d') as publishtime,  \\\n",
    "                            t1.gather_type, t1.sec, t1.title, t2.text as content\\\n",
    "                            from elint_web_docinfo t1, wise_web_docinfo_text t2\\\n",
    "                                where (date_format(publishtime, '%%Y-%%m-%%d') >= '{0}' and \\\n",
    "                                      date_format(publishtime, '%%Y-%%m-%%d') <= '{1}') and \\\n",
    "                                      t1.id = t2.doc_id and \\\n",
    "                                      t1.sec in (7,8,9) \".format('2018-08-20', '2018-09-16') \n",
    "\n",
    "# warning = pd.read_sql(sql_warning, engine)\n",
    "# print(warning.shape)\n",
    "# warning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-12T01:40:38.025770Z",
     "start_time": "2018-11-12T01:40:37.922764Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 0:\n",
    "    # url = \"http://192.168.0.104:11000/judge_correlation_yjh\"\n",
    "    url = \"http://47.93.77.19:6001/judge_correlation_yjh\"\n",
    "    folder = 'cbrc_result_class'\n",
    "    filename = 'cbrc_add&warning_20180917(0820-0916).xlsx'\n",
    "    get_period_data_for_training(human_additional, warning, url, folder, filename, 'cbrc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 银保监会--新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特殊时间点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T10:50:24.224555Z",
     "start_time": "2018-11-18T10:50:14.017972Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = specific_func.get_engine('cbirc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T10:50:24.281559Z",
     "start_time": "2018-11-18T10:50:24.272558Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cbirc_day_thing = [['2018-05-02', '相关性模型'], \n",
    "             ['2018-06-01', '更新相关性模型'], \n",
    "             ['2018-06-12', '更新相关性模型'], \n",
    "             ['2018-06-12', '上线倾向性模型']\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T10:50:24.370564Z",
     "start_time": "2018-11-18T10:50:24.313560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_day： 2018-11-10\n",
      "end_day： 2018-11-17\n"
     ]
    }
   ],
   "source": [
    "start_day = today - datetime.timedelta(days=8) # 30 天\n",
    "start_day = start_day.strftime(\"%Y-%m-%d\") # '2018-08-12'  # 含\n",
    "end_day = yesterday_str    # 含\n",
    "print('start_day：',start_day)\n",
    "print('end_day：',end_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-18T10:03:23.194Z"
    }
   },
   "outputs": [],
   "source": [
    "cbirc_count_all = pd.DataFrame()\n",
    "for t in range(1, len(proj_name_dict) + 1):\n",
    "    t0 = time.time()\n",
    "    print('获取 %s 的数据 -------'%(proj_name_dict[t]))\n",
    "    sql_cbirc = '''\n",
    "    SELECT \n",
    "        DATE_FORMAT(t3.publishtime, '%%Y-%%m-%%d') AS publishtime,\n",
    "        t2.type,\n",
    "        t1.traffic_id AS classify,\n",
    "        t2.sen as tendency, \n",
    "        COUNT(t1.id) AS count\n",
    "    FROM\n",
    "        cbrc_circ.db_classify_traffic_docinfo t1\n",
    "            LEFT JOIN\n",
    "        cbrc_circ.db_docinfo_trade t2 ON t1.urlhash = t2.urlhash\n",
    "            LEFT JOIN\n",
    "        cbrc_circ.db_docinfo t3 ON t2.urlhash = t3.urlhash\n",
    "    WHERE\n",
    "        date_format(t3.publishtime, '%%Y-%%m-%%d') >= '{0}'\n",
    "            AND date_format(t3.publishtime, '%%Y-%%m-%%d') <= '{1}'\n",
    "            and t2.type = {2}\n",
    "    GROUP BY DATE_FORMAT(t3.publishtime, '%%Y-%%m-%%d') , t2.type , t1.traffic_id, t2.sen\n",
    "    '''.format(start_day, end_day, t)\n",
    "\n",
    "    cbirc_count_type = pd.read_sql(sql_cbirc, engine)\n",
    "    cbirc_count_all = pd.concat([cbirc_count_all, cbirc_count_type], axis = 0)\n",
    "    print('    耗时：%s s'%(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-18T10:52:28.854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取 中国人保 的数据 -------\n"
     ]
    }
   ],
   "source": [
    "# cbirc_count_all = pd.DataFrame()\n",
    "t = 5\n",
    "t0 = time.time()\n",
    "print('获取 %s 的数据 -------'%(proj_name_dict[t]))\n",
    "sql_cbirc = '''\n",
    "SELECT \n",
    "    DATE_FORMAT(t3.publishtime, '%%Y-%%m-%%d') AS publishtime,\n",
    "    t2.type,\n",
    "    t1.traffic_id AS classify,\n",
    "    t2.sen as tendency, \n",
    "    COUNT(t1.id) AS count\n",
    "FROM\n",
    "    cbrc_circ.db_classify_traffic_docinfo t1\n",
    "        LEFT JOIN\n",
    "    cbrc_circ.db_docinfo_trade t2 ON t1.urlhash = t2.urlhash\n",
    "        LEFT JOIN\n",
    "    cbrc_circ.db_docinfo t3 ON t2.urlhash = t3.urlhash\n",
    "WHERE\n",
    "    date_format(t3.publishtime, '%%Y-%%m-%%d') >= '{0}'\n",
    "        AND date_format(t3.publishtime, '%%Y-%%m-%%d') <= '{1}'\n",
    "        and t2.type = {2}\n",
    "GROUP BY DATE_FORMAT(t3.publishtime, '%%Y-%%m-%%d') , t2.type , t1.traffic_id, t2.sen\n",
    "'''.format(start_day, end_day, t)\n",
    "\n",
    "cbirc_count_type = pd.read_sql(sql_cbirc, engine)\n",
    "cbirc_count_all = pd.concat([cbirc_count_all, cbirc_count_type], axis = 0)\n",
    "print('    耗时：%s s'%(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T10:52:15.660929Z",
     "start_time": "2018-11-18T10:52:15.632927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    耗时：106.597097158432 s\n",
      "(120, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publishtime</th>\n",
       "      <th>type</th>\n",
       "      <th>classify</th>\n",
       "      <th>tendency</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-10</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publishtime  type  classify  tendency  count\n",
       "0  2018-11-10     5         1         0     17\n",
       "1  2018-11-10     5         2        -1      1\n",
       "2  2018-11-10     5         2         0     32\n",
       "3  2018-11-10     5         3         0      6\n",
       "4  2018-11-10     5         4         0     21"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbirc_count_all = pd.concat([cbirc_count_all, cbirc_count_type], axis = 0)\n",
    "print('    耗时：%s s'%(time.time() - t0))\n",
    "print(cbirc_count_all.shape)\n",
    "cbirc_count_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 八分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 八分类数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-16T05:41:44.470760Z",
     "start_time": "2018-11-16T03:41:53.511Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cbirc_count = cbirc_count_all.groupby(['publishtime', 'type', 'classify'])['count'].sum()\n",
    "cbirc_count = cbirc_count.reset_index(['publishtime', 'type', 'classify'])\n",
    "cbirc_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T09:06:14.399584Z",
     "start_time": "2018-11-15T09:06:14.353582Z"
    }
   },
   "outputs": [],
   "source": [
    "cbirc_count['classify'] = cbirc_count['classify'].apply(lambda x:class_name_dict[int(x)])\n",
    "cbirc_count['type'] = cbirc_count['type'].apply(lambda x:proj_name_dict[int(x)])\n",
    "print(cbirc_count.shape)\n",
    "print(cbirc_count.info(memory_usage = 'deep'))\n",
    "# cbirc_count.head()\n",
    "\n",
    "print(cbirc_count['count'].sum())\n",
    "cbirc_count.pivot_table(index = ['publishtime'], columns = ['type'], \n",
    "                        aggfunc = [np.sum], values = ['count'], \n",
    "                        fill_value = 0, margins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T07:30:57.181578Z",
     "start_time": "2018-11-15T07:30:57.169577Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sql_cbirc = '''\n",
    "# SELECT \n",
    "#     DATE_FORMAT(t3.publishtime, '%%Y-%%m-%%d') AS publishtime,\n",
    "#     t2.type,\n",
    "#     t1.traffic_id AS classify,\n",
    "#     COUNT(t1.id) AS count\n",
    "# FROM\n",
    "#     cbrc_circ.db_classify_traffic_docinfo t1\n",
    "#         LEFT JOIN\n",
    "#     cbrc_circ.db_docinfo_trade t2 ON t1.urlhash = t2.urlhash\n",
    "#         LEFT JOIN\n",
    "#     cbrc_circ.db_docinfo t3 ON t2.urlhash = t3.urlhash\n",
    "# WHERE\n",
    "#     date_format(t3.publishtime, '%%Y-%%m-%%d') >= '{0}'\n",
    "#         AND date_format(t3.publishtime, '%%Y-%%m-%%d') <= '{1}'\n",
    "# GROUP BY DATE_FORMAT(t3.publishtime, '%%Y-%%m-%%d') , t2.type , t1.traffic_id\n",
    "# '''.format(start_day, end_day)\n",
    "\n",
    "# cbirc_count = pd.read_sql(sql_cbirc, engine)\n",
    "# cbirc_count['classify'] = cbirc_count['classify'].apply(lambda x:class_name_dict[x])\n",
    "# print(cbirc_count.shape)\n",
    "# print(cbirc_count.info(memory_usage = 'deep'))\n",
    "# cbirc_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 银监会"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T07:29:00.468902Z",
     "start_time": "2018-11-15T07:28:59.661856Z"
    }
   },
   "outputs": [],
   "source": [
    "class_count = cbirc_count[cbirc_count['type'] == 1].drop('type', axis = 1)\n",
    "cor_class_1, cor_class, count_data_7, count_data_4 = get_class_data(class_count)\n",
    "cor_class_1.sort_index(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T07:29:03.364068Z",
     "start_time": "2018-11-15T07:29:01.397956Z"
    }
   },
   "outputs": [],
   "source": [
    "cor_class['rate'].reset_index().fillna(0).plot(x = 'publishtime', figsize = (15,6))\n",
    "cor_class.sort_index(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T07:29:03.932100Z",
     "start_time": "2018-11-15T07:29:03.478074Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_cor(count_data_7, cbirc_day_thing, \"CBRC 8-class cor&uncor:7-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T07:29:04.774149Z",
     "start_time": "2018-11-15T07:29:04.416128Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_cor(count_data_4, cbirc_day_thing, \"CBRC 8-class cor&uncor:4-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保监会"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T03:39:30.833324Z",
     "start_time": "2018-11-15T01:43:04.437Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_count = cbirc_count[cbirc_count['type'] == 2].drop('type', axis = 1)\n",
    "cor_class_1, cor_class, count_data_7, count_data_4 = get_class_data(class_count)\n",
    "cor_class_1.sort_index(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T03:39:30.836324Z",
     "start_time": "2018-11-15T01:43:04.443Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cor_class['rate'].reset_index().fillna(0).plot(x = 'publishtime', figsize = (15,6))\n",
    "cor_class.sort_index(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T03:39:30.839325Z",
     "start_time": "2018-11-15T01:43:04.449Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_cor(count_data_7, cbirc_day_thing, \"CIRC 8-class cor&uncor:7-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T03:39:30.843325Z",
     "start_time": "2018-11-15T01:43:04.453Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_cor(count_data_4, cbirc_day_thing, \"CIRC 8-class cor&uncor:4-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 中国人寿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T08:06:23.694208Z",
     "start_time": "2018-11-15T08:06:23.604202Z"
    }
   },
   "outputs": [],
   "source": [
    "class_count = cbirc_count[cbirc_count['type'] == '中国人寿'].drop('type', axis = 1)\n",
    "cor_class_1, cor_class, count_data_7, count_data_4 = get_class_data(class_count)\n",
    "cor_class_1.sort_index(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T08:06:27.361417Z",
     "start_time": "2018-11-15T08:06:27.000397Z"
    }
   },
   "outputs": [],
   "source": [
    "cor_class['rate'].reset_index().fillna(0).plot(x = 'publishtime', figsize = (15,6))\n",
    "cor_class.sort_index(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T08:06:28.291470Z",
     "start_time": "2018-11-15T08:06:27.929450Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_cor(count_data_7, cbirc_day_thing, \"CLIC 8-class cor&uncor:7-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T08:06:29.564543Z",
     "start_time": "2018-11-15T08:06:29.239525Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_cor(count_data_4, cbirc_day_thing, \"CLIC 8-class cor&uncor:4-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建行北分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T03:39:30.857326Z",
     "start_time": "2018-11-15T01:43:04.482Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_count = cbirc_count[cbirc_count['type'] == 4].drop('type', axis = 1)\n",
    "cor_class_1, cor_class, count_data_7, count_data_4 = get_class_data(class_count)\n",
    "cor_class_1.sort_index(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T03:39:30.859326Z",
     "start_time": "2018-11-15T01:43:04.487Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cor_class['rate'].reset_index().fillna(0).plot(x = 'publishtime', figsize = (15,6))\n",
    "cor_class.sort_index(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T03:39:30.863326Z",
     "start_time": "2018-11-15T01:43:04.492Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_cor(count_data_7, cbirc_day_thing, \"CCB 8-class cor&uncor:7-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T03:39:30.866326Z",
     "start_time": "2018-11-15T01:43:04.498Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_cor(count_data_4, cbirc_day_thing, \"CCB 8-class cor&uncor:4-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 中国人保"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T03:39:30.867326Z",
     "start_time": "2018-11-15T01:43:04.504Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_count = cbirc_count[cbirc_count['type'] == 5].drop('type', axis = 1)\n",
    "cor_class_1, cor_class, count_data_7, count_data_4 = get_class_data(class_count)\n",
    "cor_class_1.sort_index(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T03:39:30.869326Z",
     "start_time": "2018-11-15T01:43:04.509Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cor_class['rate'].reset_index().fillna(0).plot(x = 'publishtime', figsize = (15,6))\n",
    "cor_class.sort_index(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T03:39:30.871326Z",
     "start_time": "2018-11-15T01:43:04.515Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_cor(count_data_7, cbirc_day_thing, \"PICC 8-class cor&uncor:7-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T03:39:30.876327Z",
     "start_time": "2018-11-15T01:43:04.522Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_cor(count_data_4, cbirc_day_thing, \"PICC 8-class cor&uncor:4-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 倾向性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 倾向性数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T08:16:27.272730Z",
     "start_time": "2018-11-15T08:16:27.243729Z"
    }
   },
   "outputs": [],
   "source": [
    "tend_count = cbirc_count_all.groupby(['publishtime', 'type', 'tendency'])['count'].sum()\n",
    "tend_count = tend_count.reset_index(['publishtime', 'type', 'tendency'])\n",
    "tend_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T08:17:22.034862Z",
     "start_time": "2018-11-15T08:17:21.990860Z"
    }
   },
   "outputs": [],
   "source": [
    "tend_count['type'] = tend_count['type'].apply(lambda x:proj_name_dict[int(x)])\n",
    "print(tend_count.shape)\n",
    "print(tend_count.info(memory_usage = 'deep'))\n",
    "# tend_count.head()\n",
    "\n",
    "print(tend_count['count'].sum())\n",
    "tend_count.pivot_table(index = ['publishtime'], columns = ['type'], \n",
    "                        aggfunc = [np.sum], values = ['count'], \n",
    "                        fill_value = 0, margins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T03:39:30.878327Z",
     "start_time": "2018-11-15T01:43:04.530Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sql_tend = \"select date_format(t2.publishtime,'%%Y-%%m-%%d') as publishtime, t1.type, \\\n",
    "#                     t1.sen as tendency, count(t1.id) as cor_count \\\n",
    "#                             from db_docinfo_trade t1, db_docinfo t2 \\\n",
    "#                                 where (date_format(t2.publishtime, '%%Y-%%m-%%d') >= '{0}' and \\\n",
    "#                                       date_format(t2.publishtime, '%%Y-%%m-%%d') <= '{1}') and \\\n",
    "#                                       t1.urlhash = t2.urlhash \\\n",
    "#                                 group by date_format(t2.publishtime,'%%Y-%%m-%%d'), t1.type, t1.sen \\\n",
    "#                                 order by date_format(t2.publishtime,'%%Y-%%m-%%d') desc\".format(start_day, end_day) \n",
    "\n",
    "# tend_count = pd.read_sql(sql_tend, engine)\n",
    "# tend_count = tend_count[tend_count['tendency'] != 1]\n",
    "# print(tend_count.shape)\n",
    "# print(tend_count.info(memory_usage = 'deep'))\n",
    "# tend_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 银监会"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T03:39:30.881327Z",
     "start_time": "2018-11-15T01:43:04.543Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_tend(tend_count[tend_count['type'] == 1].drop('type', axis = 1), cbirc_day_thing, \"CBRC - tendency \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保监会"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T03:39:30.884327Z",
     "start_time": "2018-11-15T01:43:04.550Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_tend(tend_count[tend_count['type'] == 2].drop('type', axis = 1), cbirc_day_thing, \"CIRC - tendency \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 中国人寿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T08:17:56.141813Z",
     "start_time": "2018-11-15T08:17:55.821795Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_tend(tend_count[tend_count['type'] == '中国人寿'].drop('type', axis = 1), cbirc_day_thing, \"CLIC - tendency \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建行北分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T03:39:30.888327Z",
     "start_time": "2018-11-15T01:43:04.566Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_tend(tend_count[tend_count['type'] == 4].drop('type', axis = 1), cbirc_day_thing, \"CCB - tendency \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 中国人保"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-15T03:39:30.894328Z",
     "start_time": "2018-11-15T01:43:04.574Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_tend(tend_count[tend_count['type'] == 5].drop('type', axis = 1), cbirc_day_thing, \"PICC - tendency \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 补录和预警"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
